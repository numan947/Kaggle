{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL IMPORTS FOR A NEW NOTEBOOK\n",
    "\n",
    "import os, sys, random, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import itertools as it\n",
    "import scipy\n",
    "import glob\n",
    "import matplotlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.optim import Optimizer\n",
    "import torchvision.transforms.transforms as txf\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn import model_selection as ms\n",
    "\n",
    "import torch_utils\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "import time\n",
    "\n",
    "import torchtext\n",
    "from torchtext import data, datasets\n",
    "import spacy\n",
    "\n",
    "\n",
    "font = {'size'   : 20}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 947\n",
    "torch_utils.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_de = spacy.load(\"de\")\n",
    "spacy_en = spacy.load(\"en\")\n",
    "\n",
    "def tokenize_de(txt):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(txt)]\n",
    "def tokenize_en(txt):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(txt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = data.Field(tokenize=tokenize_de, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True, batch_first=True)\n",
    "TRG = data.Field(tokenize=tokenize_en, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = datasets.Multi30k.splits(exts=(\".de\",\".en\"), fields=(SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForwardLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, pff_dim, dropout):\n",
    "        super(PositionwiseFeedForwardLayer, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(hid_dim, pff_dim)\n",
    "        self.fc2 = nn.Linear(pff_dim, hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x -- batch_size X seq_len X hid_dim\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        # x -- batch_size X seq_len X pff_dim\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
    "        super(SelfAttentionLayer, self).__init__()\n",
    "        \n",
    "        assert hid_dim% n_heads == 0, \"hidden dimension must be divisible into n_heads\"\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = hid_dim//n_heads\n",
    "        \n",
    "        # for projection of the keys, values and queries\n",
    "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.fc_final = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        # query -- batch_size X query_len X hid_dim\n",
    "        # key -- batch_size X key_len X hid_dim\n",
    "        # value -- batch_size X value_len X hid_dim\n",
    "        batch_size = query.shape[0]\n",
    "        \n",
    "        # projections\n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "        \n",
    "        \n",
    "        # split into heads, basically we're dividing hid_dim into n_heads*head_dim\n",
    "        # we need all of these vectors to be of , batch_size X n_heads X seq_len X head_dim, so permute\n",
    "        \n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        \n",
    "        # now calculate energy/overlap between K and Q, Q*K/dk\n",
    "        energy = torch.matmul(Q, K.permute(0,1,3,2))/self.scale\n",
    "        \n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask==0, -1e10)\n",
    "        \n",
    "        attention = self.dropout(torch.softmax(energy, dim=-1))\n",
    "        # attention -- batch_size X n_heads X query_len X key_len\n",
    "        x = torch.matmul(attention, V)\n",
    "        # x --  batch_size X n_heads X query_len X head_dim\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        x = x.view(batch_size, -1, self.hid_dim)\n",
    "        # concatenated n_heads\n",
    "        \n",
    "        return self.fc_final(x), attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pff_dim, self_attention_layer, position_wise_feedforward_layer, dropout, device):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention = self_attention_layer(hid_dim, n_heads, dropout, device)\n",
    "        self.positionwise_feedforward = position_wise_feedforward_layer(hid_dim, pff_dim, dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, src, src_mask):\n",
    "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
    "        src = self.layer_norm(src+self.dropout(_src))\n",
    "        src = self.layer_norm(src+self.dropout(self.positionwise_feedforward(src)))\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, encoder_layer, self_attention_layer, positionwise_ff_layer, dropout, device):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
    "        self.pos_embedding = torch_utils.PositionalEncoding(hid_dim, dropout)\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "            encoder_layer(hid_dim, n_heads, pf_dim, self_attention_layer, positionwise_ff_layer, dropout, device)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "    \n",
    "    def forward(self, src, src_mask):\n",
    "        batch_size, src_len = src.shape\n",
    "        src_tok = self.tok_embedding(src) * self.scale\n",
    "        src = self.pos_embedding(src_tok)\n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask)\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, self_attention_layer, positionwise_feedforward_layer, dropout, device):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention = self_attention_layer(hid_dim, n_heads, dropout, device)\n",
    "        self.encoder_attention = self_attention_layer(hid_dim, n_heads, dropout, device)\n",
    "        self.positionwise_ffn = positionwise_feedforward_layer(hid_dim, pf_dim, dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
    "        trg = self.layer_norm(trg+self.dropout(_trg))\n",
    "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
    "        trg = self.layer_norm(trg+self.dropout(_trg))\n",
    "        trg = self.layer_norm(trg+self.dropout(self.positionwise_ffn(trg)))\n",
    "        \n",
    "        return trg, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hid_dim, n_layers, n_heads, pf_dim, decoder_layer, self_attention_layer, positionwise_feedforward_layer, dropout, device):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
    "        \n",
    "        self.pos_embedding = torch_utils.PositionalEncoding(hid_dim, dropout)\n",
    "        \n",
    "        self.layers = nn.ModuleList([decoder_layer(hid_dim, n_heads, pf_dim, self_attention_layer, positionwise_feedforward_layer, dropout, device)])\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "    \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        batch_size, trg_len = trg.shape\n",
    "        trg_embed = self.tok_embedding(trg)*self.scale\n",
    "        trg = self.pos_embedding(trg_embed)\n",
    "        for layer in self.layers:\n",
    "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
    "        output = self.fc_out(trg)\n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, trg_sos_idx, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.trg_sos_idx = trg_sos_idx\n",
    "        self.device = device\n",
    "    \n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = (src!=self.src_pad_idx).unsqueeze(dim=1).unsqueeze(dim=2)\n",
    "        # src_mask -- batch_size X 1 X 1 X src_len\n",
    "        return src_mask\n",
    "    def make_trg_mask(self, trg):\n",
    "        trg_pad_mask = (trg!=self.trg_pad_idx).unsqueeze(dim=1).unsqueeze(dim=3)\n",
    "        # trg_pad_mask --  batch_size X 1 X trg_len X 1\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        return trg_mask\n",
    "    \n",
    "    def forward(self, src, trg):\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        \n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        \n",
    "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if hasattr(m, \"weight\") and m.weight.dim()>1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    el = 0\n",
    "    for batch in tqdm(iterator):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output, _ = model(src, trg[:,:-1])\n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trg = trg[:, 1:].contiguous().view(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        el+=loss.item()\n",
    "    \n",
    "    return el/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    el = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(iterator):\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output, _ = model(src, trg[:,:-1])\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:, 1:].contiguous().view(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            el+=loss.item()\n",
    "    \n",
    "    return el/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_DIM = len(SRC.vocab)\n",
    "OUT_DIM = len(TRG.vocab)\n",
    "HID_DIM = 256\n",
    "ENC_LAYERS = 3\n",
    "DEC_LAYERS = 3\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 512\n",
    "DEC_PF_DIM = 512\n",
    "ENC_DROPOUT = 0.15\n",
    "DEC_DROPOUT = 0.15\n",
    "\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "TRG_SOS_IDX = TRG.vocab.stoi[TRG.init_token]\n",
    "\n",
    "\n",
    "enc = Encoder(INP_DIM, HID_DIM, ENC_LAYERS, ENC_HEADS, ENC_PF_DIM, EncoderLayer, SelfAttentionLayer, PositionwiseFeedForwardLayer, ENC_DROPOUT, device)\n",
    "dec = Decoder(OUT_DIM, HID_DIM, DEC_LAYERS, DEC_HEADS, DEC_PF_DIM, DecoderLayer, SelfAttentionLayer, PositionwiseFeedForwardLayer, DEC_DROPOUT, device)\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX,TRG_PAD_IDX, TRG_SOS_IDX, device).to(device).apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL PARAMS = 7403525\n"
     ]
    }
   ],
   "source": [
    "print(f\"TOTAL PARAMS = {torch_utils.count_model_params(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)\n",
    "optimizer = torch_utils.RAdam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3376759cb0942228ea4b0766c19c4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=227), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a20c277ab14915b6d8e0cb72cc2737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found better solution (inf --> 75.665609).  Saving model ...\n",
      "\n",
      "\n",
      "EPOCH 1 Completed, Time Taken: 0:00:12.269908\n",
      "\tTrain Loss \t6.22600696\n",
      "\tValid Loss \t4.32632375\n",
      "\t\tTPL : \t\t505.73204\n",
      "\t\tVPL : \t\t75.66561\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf21a674954446ab239daf52912230c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=227), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29860329009b40a38ff6bc203779a67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found better solution (75.665609 --> 28.065509).  Saving model ...\n",
      "\n",
      "\n",
      "EPOCH 2 Completed, Time Taken: 0:00:12.110225\n",
      "\tTrain Loss \t3.97044868\n",
      "\tValid Loss \t3.33454138\n",
      "\t\tTPL : \t\t53.00831\n",
      "\t\tVPL : \t\t28.06551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b370fa8fd334981a6c283a0126a619f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=227), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78daf1ba51b41bab835749805a4b5cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found better solution (28.065509 --> 14.944775).  Saving model ...\n",
      "\n",
      "\n",
      "EPOCH 3 Completed, Time Taken: 0:00:12.509177\n",
      "\tTrain Loss \t3.2455308\n",
      "\tValid Loss \t2.70436174\n",
      "\t\tTPL : \t\t25.67533\n",
      "\t\tVPL : \t\t14.94477\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3347276d7934a9eabe174ff7ee4a4b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=227), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be0c8bfec684d198f7477384a2bd52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found better solution (14.944775 --> 10.191247).  Saving model ...\n",
      "\n",
      "\n",
      "EPOCH 4 Completed, Time Taken: 0:00:11.838966\n",
      "\tTrain Loss \t2.74037308\n",
      "\tValid Loss \t2.32152918\n",
      "\t\tTPL : \t\t15.49276\n",
      "\t\tVPL : \t\t10.19125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f187e53be35040429bd4a62f6d79aede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=227), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac98d65238e4f5ab778df64722a6763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found better solution (10.191247 --> 7.982975).  Saving model ...\n",
      "\n",
      "\n",
      "EPOCH 5 Completed, Time Taken: 0:00:11.829717\n",
      "\tTrain Loss \t2.37884255\n",
      "\tValid Loss \t2.07731114\n",
      "\t\tTPL : \t\t10.79240\n",
      "\t\tVPL : \t\t7.98297\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ffefca0aa04b77a10a3a1eddc94a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=227), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab8dd5fb935455e97ecdf9d787c9e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found better solution (7.982975 --> 6.774808).  Saving model ...\n",
      "\n",
      "\n",
      "EPOCH 6 Completed, Time Taken: 0:00:11.729448\n",
      "\tTrain Loss \t2.10597416\n",
      "\tValid Loss \t1.91321108\n",
      "\t\tTPL : \t\t8.21510\n",
      "\t\tVPL : \t\t6.77481\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50bb1fef7add4ed28c65582bbfbdb59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=227), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa974b5e264545a3a982850dca74e935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found better solution (6.774808 --> 6.038275).  Saving model ...\n",
      "\n",
      "\n",
      "EPOCH 7 Completed, Time Taken: 0:00:12.088450\n",
      "\tTrain Loss \t1.892443\n",
      "\tValid Loss \t1.79811844\n",
      "\t\tTPL : \t\t6.63556\n",
      "\t\tVPL : \t\t6.03828\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6f2ee1e4164a73a25508860daa160c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=227), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafad47288b4465ab69f44a65d8e995c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found better solution (6.038275 --> 5.581215).  Saving model ...\n",
      "\n",
      "\n",
      "EPOCH 8 Completed, Time Taken: 0:00:12.055277\n",
      "\tTrain Loss \t1.72003912\n",
      "\tValid Loss \t1.71940653\n",
      "\t\tTPL : \t\t5.58475\n",
      "\t\tVPL : \t\t5.58122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82b9adbe8874405bcdc04b9192b4c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=227), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b1a1e40b734525bcbf0e5d0e29aefd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found better solution (5.581215 --> 5.305896).  Saving model ...\n",
      "\n",
      "\n",
      "EPOCH 9 Completed, Time Taken: 0:00:11.700305\n",
      "\tTrain Loss \t1.57769993\n",
      "\tValid Loss \t1.66881858\n",
      "\t\tTPL : \t\t4.84380\n",
      "\t\tVPL : \t\t5.30590\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0670854c532f4a0cba8c41d8eec79aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=227), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eebde5ac2754ec3896b81827e5a0b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found better solution (5.305896 --> 5.133511).  Saving model ...\n",
      "\n",
      "\n",
      "EPOCH 10 Completed, Time Taken: 0:00:11.627280\n",
      "\tTrain Loss \t1.45890912\n",
      "\tValid Loss \t1.63578977\n",
      "\t\tTPL : \t\t4.30126\n",
      "\t\tVPL : \t\t5.13351\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a52737349264c939a72a5f22d5b4ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=227), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a49ef9a394546f387be1b5a61caf89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found better solution (5.133511 --> 4.955053).  Saving model ...\n",
      "\n",
      "\n",
      "EPOCH 11 Completed, Time Taken: 0:00:12.433437\n",
      "\tTrain Loss \t1.35543368\n",
      "\tValid Loss \t1.60040787\n",
      "\t\tTPL : \t\t3.87844\n",
      "\t\tVPL : \t\t4.95505\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd52807aeec42b09b4952b7965c8175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=227), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37c150a6a1d46f491cd96d1526c39af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found better solution (4.955053 --> 4.915455).  Saving model ...\n",
      "\n",
      "\n",
      "EPOCH 12 Completed, Time Taken: 0:00:11.172405\n",
      "\tTrain Loss \t1.26334918\n",
      "\tValid Loss \t1.59238429\n",
      "\t\tTPL : \t\t3.53725\n",
      "\t\tVPL : \t\t4.91545\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b5132e756844b88bc089a7d5d506af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=227), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9d72f76aef4bf7b04bab109c5930f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "\n",
      "EPOCH 13 Completed, Time Taken: 0:00:11.754394\n",
      "\tTrain Loss \t1.1882219\n",
      "\tValid Loss \t1.59650153\n",
      "\t\tTPL : \t\t3.28124\n",
      "\t\tVPL : \t\t4.93573\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d634027815e14f11a2faa9907b3d6129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=227), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_EPOCHS = 30\n",
    "CLIP = 1\n",
    "history = pd.DataFrame()\n",
    "best_model = \"ATTN_IS_ALL_YOU_NEED.pt\"\n",
    "ea = torch_utils.EarlyStopping(patience=5, verbose=True, save_model_name=best_model)\n",
    "\n",
    "for e in range(N_EPOCHS):\n",
    "    st = time.time()\n",
    "    tl = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    vl = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    TPL = np.exp(tl)\n",
    "    VPL = np.exp(vl)\n",
    "    ea(VPL, model)\n",
    "    \n",
    "    torch_utils.print_epoch_stat(e, time.time()-st, history, tl, valid_loss=vl)\n",
    "    \n",
    "    print(f\"\\t\\tTPL : \\t\\t{TPL:0.5f}\")\n",
    "    print(f\"\\t\\tVPL : \\t\\t{VPL:0.5f}\")\n",
    "    \n",
    "    if ea.early_stop:\n",
    "        print(\"STOPPING EARLY!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = history[\"train_loss\"].plot()\n",
    "history[\"valid_loss\"].plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "print(f\"Possibly overfitted model: Loss = {test_loss:0.5f} | PPL = {np.exp(test_loss):0.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(best_model, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "print(f\"Best model: Loss = {test_loss:0.5f} | PPL = {np.exp(test_loss):0.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
    "    \n",
    "    model.eval()\n",
    "        \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('de')\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "        \n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "    \n",
    "    src_mask = model.make_src_mask(src_tensor)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        enc_src = model.encoder(src_tensor, src_mask)\n",
    "\n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "\n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "        trg_mask = model.make_trg_mask(trg_tensor)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        \n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "    \n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:], attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import ticker\n",
    "def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 4, n_cols = 2):\n",
    "    \n",
    "    assert n_rows * n_cols == n_heads\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,25))\n",
    "    \n",
    "    for i in range(n_heads):\n",
    "        \n",
    "        ax = fig.add_subplot(n_rows, n_cols, i+1)\n",
    "        \n",
    "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
    "\n",
    "        cax = ax.matshow(_attention, cmap='bone')\n",
    "\n",
    "        ax.tick_params(labelsize=12)\n",
    "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
    "                           rotation=45)\n",
    "        ax.set_yticklabels(['']+translation)\n",
    "\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_idx = 5\n",
    "src = vars(train_data.examples[example_idx])[\"src\"]\n",
    "trg = vars(train_data.examples[example_idx])[\"trg\"]\n",
    "print(f\"SRC == {src}\")\n",
    "print(f\"TRG == {trg}\")\n",
    "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "print(f\"TRNSLATED == {translation}\")\n",
    "display_attention(src, translation, attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_idx = 6\n",
    "src = vars(valid_data.examples[example_idx])[\"src\"]\n",
    "trg = vars(valid_data.examples[example_idx])[\"trg\"]\n",
    "print(f\"SRC == {src}\")\n",
    "print(f\"TRG == {trg}\")\n",
    "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "print(f\"TRNSLATED == {translation}\")\n",
    "display_attention(src, translation, attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_idx = 10\n",
    "src = vars(test_data.examples[example_idx])[\"src\"]\n",
    "trg = vars(test_data.examples[example_idx])[\"trg\"]\n",
    "print(f\"SRC == {src}\")\n",
    "print(f\"TRG == {trg}\")\n",
    "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "print(f\"TRNSLATED == {translation}\")\n",
    "display_attention(src, translation, attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n",
    "    \n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "    \n",
    "    for datum in tqdm(data):\n",
    "        \n",
    "        src = vars(datum)['src']\n",
    "        trg = vars(datum)['trg']\n",
    "        \n",
    "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
    "        \n",
    "        #cut off <eos> token\n",
    "        pred_trg = pred_trg[:-1]\n",
    "        \n",
    "        pred_trgs.append(pred_trg)\n",
    "        trgs.append([trg])\n",
    "        \n",
    "    return torch_utils.bleu_score(pred_trgs, trgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100.0*calculate_bleu(test_data, SRC, TRG, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
