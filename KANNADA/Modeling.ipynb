{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "np.random.seed(947)\n",
    "torch.manual_seed(947)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5',\n",
       "       'pixel6', 'pixel7', 'pixel8',\n",
       "       ...\n",
       "       'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n",
       "       'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n",
       "      dtype='object', length=785)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"./train.csv\")\n",
    "test_data = pd.read_csv(\"./test.csv\")\n",
    "dig_mnist_data = pd.read_csv(\"./Dig-MNIST.csv\")\n",
    "sample_submission = pd.read_csv(\"./sample_submission.csv\")\n",
    "\n",
    "train_data = pd.concat([train_data, dig_mnist_data])\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set = train_test_split(train_data, random_state=947, test_size=0.3)\n",
    "\n",
    "def convert_dataset(data):\n",
    "    images, labels = [], []\n",
    "    for idx, row in data.iterrows():\n",
    "        labels.append([int(row[0])])\n",
    "        images.append(1.0*row[1:].values.astype(np.float)/255.0)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = convert_dataset(train_set)\n",
    "valid_images, valid_labels = convert_dataset(valid_set)\n",
    "test_images, test_labels = convert_dataset(test_data)\n",
    "dig_images, dig_labels = convert_dataset(dig_mnist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_train_images = torch.stack([torch.Tensor(i.reshape(28,28)) for i in train_images])\n",
    "tensor_train_labels = torch.stack([torch.LongTensor(i) for i in train_labels])\n",
    "\n",
    "tensor_valid_images = torch.stack([torch.Tensor(i.reshape(28,28)) for i in valid_images])\n",
    "tensor_valid_labels = torch.stack([torch.LongTensor(i) for i in valid_labels])\n",
    "\n",
    "tensor_test_images = torch.stack([torch.Tensor(i.reshape(28,28)) for i in test_images])\n",
    "tensor_test_indice = torch.stack([torch.Tensor(i) for i in test_labels])\n",
    "\n",
    "tensor_dig_images = torch.stack([torch.Tensor(i.reshape(28,28)) for i in dig_images])\n",
    "tensor_dig_labels = torch.stack([torch.Tensor(i) for i in dig_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code credit: https://stackoverflow.com/questions/55588201/pytorch-transforms-on-tensordataset/55593757\n",
    "class CustomTensorDataset(data.Dataset):\n",
    "    \"\"\"TensorDataset with support of transforms.\n",
    "    \"\"\"\n",
    "    def __init__(self, tensors, transform=None):\n",
    "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
    "        self.tensors = tensors\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.tensors[0][index]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        y = self.tensors[1][index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tensors[0].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Coding Credit: https://github.com/Bjarten/early-stopping-pytorch\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, track=\"min\", patience=7, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            track (str): What to track, possible value: min, max (e.g. min validation loss, max validation accuracy (%))\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.track = track\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_best = -np.Inf\n",
    "        if self.track==\"min\":\n",
    "            self.val_best = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, current_score, model):\n",
    "\n",
    "        score = -current_score\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(current_score, model)\n",
    "        elif ((score < self.best_score + self.delta) and self.track==\"min\") or ((score>self.best_score+self.delta) and self.track==\"max\"):\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(current_score, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, new_best, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Found better solution ({self.val_best:.6f} --> {new_best:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_best = new_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "txf = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomTensorDataset((tensor_train_images.view(-1,28,28), tensor_train_labels.reshape(-1).long()), transform=txf)\n",
    "valid_dataset = CustomTensorDataset((tensor_valid_images.view(-1,28,28), tensor_valid_labels.reshape(-1).long()), transform=txf)\n",
    "test_dataset = CustomTensorDataset((tensor_test_images.view(-1,28,28), tensor_test_indice.reshape(-1).long()), transform=txf)\n",
    "dig_dataset = CustomTensorDataset((tensor_dig_images.view(-1,28,28), tensor_dig_labels.reshape(-1).long()), transform=txf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=3)\n",
    "validloader = data.DataLoader(valid_dataset, batch_size=128, num_workers=3)\n",
    "testloader = data.DataLoader(test_dataset, batch_size=1, num_workers=3)\n",
    "digloader = data.DataLoader(dig_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(model, criterion, device, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device).long()\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    ## validation/test, so reduction = \"sum\"\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(interval, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    train_loss=0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device).long()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        loss = F.nll_loss(output, target)\n",
    "        train_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    \n",
    "    train_loss/=len(train_loader)\n",
    "    print('\\nTrain Set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        train_loss, correct, len(train_loader.dataset),\n",
    "        100. * correct / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 512)\n",
    "        self.fc11 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn11 = nn.BatchNorm1d(256)\n",
    "        self.cbn1 = nn.BatchNorm2d(20)\n",
    "        self.cbn2 = nn.BatchNorm2d(50)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.cbn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.cbn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.fc2(F.relu(self.fc11(x)))\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EPOCHS = 20\n",
    "\n",
    "# model = BasicNet().to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "# for epoch in range(1, EPOCHS+ 1):\n",
    "#     curT = time.time()\n",
    "#     print(\"Epoch: {} Learning Rate:  {:0.4f}\".format(epoch, scheduler.get_lr()[0]))\n",
    "#     train(100, model, device, trainloader, optimizer, epoch)\n",
    "#     test(model, device, validloader)\n",
    "#     print(\"Time Taken: {}\\n\\n\".format(time.time()-curT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(LeNet,self).__init__()\n",
    "            self.features=nn.Sequential(\n",
    "                nn.Conv2d(1,64,3,padding=1),      \n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.LeakyReLU(),\n",
    "                \n",
    "                nn.Conv2d(64,64,3,padding=1),        \n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.LeakyReLU(),\n",
    "                \n",
    "                nn.Conv2d(64,128,3,padding=1),       \n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.LeakyReLU(),\n",
    "                \n",
    "                nn.Conv2d(128,128,3,padding=1),       \n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.LeakyReLU(),\n",
    "                \n",
    "                nn.MaxPool2d(2,2),         \n",
    "                nn.Dropout(p=0.25),\n",
    "                \n",
    "                nn.Conv2d(128,256,3,padding=1),        \n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.LeakyReLU(),\n",
    "                \n",
    "                nn.Conv2d(256,256,3,padding=1),        \n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.LeakyReLU(),\n",
    "                \n",
    "                nn.MaxPool2d(2,2),        \n",
    "                nn.Dropout(p=0.25),\n",
    "                \n",
    "                nn.Conv2d(256,512,3,padding=1),\n",
    "                nn.BatchNorm2d(512),\n",
    "                nn.LeakyReLU(),\n",
    "                \n",
    "                nn.Conv2d(512,512,3,padding=1),\n",
    "                nn.BatchNorm2d(512),\n",
    "                nn.LeakyReLU(),\n",
    "                \n",
    "                nn.MaxPool2d(2,2),        \n",
    "                nn.Dropout(p=0.25),\n",
    "            )\n",
    "            \n",
    "            self.classify=nn.Sequential(\n",
    "                nn.Linear(512*3*3,1024),\n",
    "                nn.BatchNorm1d(1024),\n",
    "                nn.Linear(1024, 512),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.Linear(512,10),\n",
    "                nn.LogSoftmax(dim=1)\n",
    "            )\n",
    "        def forward(self,input):\n",
    "            x=self.features(input)\n",
    "            x=x.view(x.size(0),-1)\n",
    "            x=self.classify(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EPOCHS = 50\n",
    "# PRINT_INTERVAL = 100\n",
    "\n",
    "# early_stopping = EarlyStopping(patience=15, verbose=True, delta=0.00001)\n",
    "# model = LeNet().to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "# scheduler = StepLR(optimizer,step_size=7, gamma=0.7)\n",
    "\n",
    "\n",
    "# for epoch in range(1, EPOCHS+ 1):\n",
    "#     curT = time.time()\n",
    "#     print(\"Epoch: {} Learning Rate:  {:0.4f}\".format(epoch, scheduler.get_lr()[0]))\n",
    "#     train(PRINT_INTERVAL, model, device, trainloader, optimizer, epoch)\n",
    "#     val_loss = test(model, device, validloader)\n",
    "#     print(\"Time Taken: {}\\n\\n\".format(time.time()-curT))\n",
    "#     scheduler.step()\n",
    "#     early_stopping(val_loss, model)\n",
    "    \n",
    "#     if early_stopping.early_stop:\n",
    "#         break\n",
    "# #     if args.save_model:\n",
    "# #         torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"checkpoint.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def train_classifier(model, optimizer, criterion, current_epoch, train_loader, device=\"cpu\", print_interval=10):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    \n",
    "    train_correct = 0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        train_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        train_loss+= (loss.item() * len(data))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % print_interval == 0:\n",
    "            print(\n",
    "                'Train Epoch: {} [{}/{} ({:.3f}%)]\\tLoss: {:.7f}'.format(\n",
    "                    current_epoch, batch_idx * len(data), len(train_loader.dataset),100. * batch_idx / len(train_loader), loss.item()\n",
    "                    )\n",
    "                )\n",
    "    ## This is training, so reduction = mean, i.e. loss.item() already gives the mean of the batch\n",
    "    train_loss/=len(train_loader.dataset)\n",
    "    train_accuracy = 100. * train_correct / len(train_loader.dataset)\n",
    "    print('Train Set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        train_loss, train_correct, len(train_loader.dataset), train_accuracy\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return train_loss, train_accuracy\n",
    "    \n",
    "    \n",
    "def test_classifier(model, criterion, device, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device).long()\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    ## validation/test, so reduction = \"sum\"\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),test_accuracy\n",
    "        )\n",
    "    )\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Coding Credit: https://github.com/Bjarten/early-stopping-pytorch\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, track=\"min\", patience=7, verbose=False, delta=0, checkpt_name=\"checkpoint.pt\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            track (str): What to track, possible value: min, max (e.g. min validation loss, max validation accuracy (%))\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.checkpt_name = checkpt_name\n",
    "        self.track = track\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_best = -np.Inf\n",
    "        if self.track==\"min\":\n",
    "            self.val_best = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, current_score, model):\n",
    "\n",
    "        score = -current_score\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(current_score, model)\n",
    "        elif ((score < self.best_score + self.delta) and self.track==\"min\") or ((score>self.best_score+self.delta) and self.track==\"max\"):\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(current_score, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, new_best, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Found better solution ({self.val_best:.6f} --> {new_best:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), checkpt_name)\n",
    "        self.val_best = new_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config example:\n",
    "VGG11 = [64,'M',128,'M',256,256,'M',512,512,'M',512,512,'M']\n",
    "VGG13 = [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
    "VGG16 =  [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
    "VGG19 = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n",
    "\n",
    "def vgg_block(config, in_channels):\n",
    "    layers = []\n",
    "    for x in config:\n",
    "        if x == 'M':\n",
    "            layers.append(nn.MaxPool2d(2,2))\n",
    "        else:\n",
    "            layers.append(nn.Conv2d(in_channels, x,3,padding=1))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            in_channels = x\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class VGGNet(nn.Module):\n",
    "    def __init__(self, vgg_config, in_channel, num_classes):\n",
    "        super(VGGNet, self).__init__()\n",
    "        self.vgg = vgg_block(vgg_config, in_channel)\n",
    "        self.adjustor = nn.AdaptiveAvgPool2d((6,6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512*6*6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.vgg(x)\n",
    "        x = self.adjustor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Learning Rate:  0.0001\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tgt_vocab_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-9fe050561dd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcurT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: {} Learning Rate:  {:0.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabelSmoothingLoss2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLabelSmoothingLoss2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time Taken: {}\\n\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcurT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-100-d48f10a87409>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, label_smoothing, n_classes, ignore_index)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLabelSmoothingLoss2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0msmoothing_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_smoothing\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtgt_vocab_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mone_hot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tgt_vocab_size' is not defined"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "PRINT_INTERVAL = 100\n",
    "\n",
    "\n",
    "model = VGGNet(VGG13, 1, 10).to(device)\n",
    "\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.000050)\n",
    "scheduler = StepLR(optimizer,step_size=EPOCHS//5, gamma=0.1)\n",
    "# early_stopping = EarlyStopping(track=\"max\",patience=15, verbose=True, delta=0.00001>)\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS+ 1):\n",
    "    curT = time.time()\n",
    "    print(\"Epoch: {} Learning Rate:  {:0.4f}\".format(epoch, scheduler.get_lr()[0]))\n",
    "    train_classifier(model, optimizer, LabelSmoothingLoss2(0.2, 10), epoch, trainloader, device, print_interval=100)\n",
    "    val_loss, val_acc = test_classifier(model,LabelSmoothingLoss2(0.2,10), device, validloader)\n",
    "    print(\"Time Taken: {}\\n\\n\".format(time.time()-curT))\n",
    "    scheduler.step()\n",
    "#     early_stopping(val_acc, model)\n",
    "    \n",
    "#     if early_stopping.early_stop:\n",
    "#         break\n",
    "\n",
    "torch.save(model.state_dict(), \"model_\"+str(EPOCHS)+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Learning Rate:  0.0001\n",
      "Train Epoch: 1 [0/49168 (0.000%)]\tLoss: 2.3026793\n",
      "Train Epoch: 1 [12800/49168 (25.974%)]\tLoss: 0.6682453\n",
      "Train Epoch: 1 [25600/49168 (51.948%)]\tLoss: 0.2432615\n",
      "Train Epoch: 1 [38400/49168 (77.922%)]\tLoss: 0.1384182\n",
      "Train Set: Average loss: 0.6713, Accuracy: 37029/49168 (75%)\n",
      "\n",
      "Test set: Average loss: 0.4541, Accuracy: 18470/21072 (88%)\n",
      "\n",
      "Time Taken: 28.499454259872437\n",
      "\n",
      "\n",
      "Epoch: 2 Learning Rate:  0.0001\n",
      "Train Epoch: 2 [0/49168 (0.000%)]\tLoss: 0.3095499\n",
      "Train Epoch: 2 [12800/49168 (25.974%)]\tLoss: 0.0835821\n",
      "Train Epoch: 2 [25600/49168 (51.948%)]\tLoss: 0.0469626\n",
      "Train Epoch: 2 [38400/49168 (77.922%)]\tLoss: 0.0495041\n",
      "Train Set: Average loss: 0.1130, Accuracy: 47583/49168 (97%)\n",
      "\n",
      "Test set: Average loss: 0.0974, Accuracy: 20474/21072 (97%)\n",
      "\n",
      "Time Taken: 28.851056337356567\n",
      "\n",
      "\n",
      "Epoch: 3 Learning Rate:  0.0000\n",
      "Train Epoch: 3 [0/49168 (0.000%)]\tLoss: 0.0848596\n",
      "Train Epoch: 3 [12800/49168 (25.974%)]\tLoss: 0.0471848\n",
      "Train Epoch: 3 [25600/49168 (51.948%)]\tLoss: 0.0392852\n",
      "Train Epoch: 3 [38400/49168 (77.922%)]\tLoss: 0.0219361\n",
      "Train Set: Average loss: 0.0559, Accuracy: 48332/49168 (98%)\n",
      "\n",
      "Test set: Average loss: 0.0632, Accuracy: 20687/21072 (98%)\n",
      "\n",
      "Time Taken: 29.035077333450317\n",
      "\n",
      "\n",
      "Epoch: 4 Learning Rate:  0.0000\n",
      "Train Epoch: 4 [0/49168 (0.000%)]\tLoss: 0.0237910\n",
      "Train Epoch: 4 [12800/49168 (25.974%)]\tLoss: 0.0131462\n",
      "Train Epoch: 4 [25600/49168 (51.948%)]\tLoss: 0.0284699\n",
      "Train Epoch: 4 [38400/49168 (77.922%)]\tLoss: 0.0749123\n",
      "Train Set: Average loss: 0.0468, Accuracy: 48488/49168 (99%)\n",
      "\n",
      "Test set: Average loss: 0.0652, Accuracy: 20650/21072 (98%)\n",
      "\n",
      "Time Taken: 28.726619482040405\n",
      "\n",
      "\n",
      "Epoch: 5 Learning Rate:  0.0000\n",
      "Train Epoch: 5 [0/49168 (0.000%)]\tLoss: 0.0205960\n",
      "Train Epoch: 5 [12800/49168 (25.974%)]\tLoss: 0.0167887\n",
      "Train Epoch: 5 [25600/49168 (51.948%)]\tLoss: 0.0735050\n",
      "Train Epoch: 5 [38400/49168 (77.922%)]\tLoss: 0.0434514\n",
      "Train Set: Average loss: 0.0417, Accuracy: 48545/49168 (99%)\n",
      "\n",
      "Test set: Average loss: 0.0583, Accuracy: 20694/21072 (98%)\n",
      "\n",
      "Time Taken: 28.785818099975586\n",
      "\n",
      "\n",
      "Epoch: 6 Learning Rate:  0.0000\n",
      "Train Epoch: 6 [0/49168 (0.000%)]\tLoss: 0.0610599\n",
      "Train Epoch: 6 [12800/49168 (25.974%)]\tLoss: 0.0389308\n",
      "Train Epoch: 6 [25600/49168 (51.948%)]\tLoss: 0.0836153\n",
      "Train Epoch: 6 [38400/49168 (77.922%)]\tLoss: 0.0516425\n",
      "Train Set: Average loss: 0.0397, Accuracy: 48578/49168 (99%)\n",
      "\n",
      "Test set: Average loss: 0.0579, Accuracy: 20705/21072 (98%)\n",
      "\n",
      "Time Taken: 28.99049186706543\n",
      "\n",
      "\n",
      "Epoch: 7 Learning Rate:  0.0000\n",
      "Train Epoch: 7 [0/49168 (0.000%)]\tLoss: 0.0091955\n",
      "Train Epoch: 7 [12800/49168 (25.974%)]\tLoss: 0.0074296\n",
      "Train Epoch: 7 [25600/49168 (51.948%)]\tLoss: 0.0300989\n",
      "Train Epoch: 7 [38400/49168 (77.922%)]\tLoss: 0.0187327\n",
      "Train Set: Average loss: 0.0389, Accuracy: 48583/49168 (99%)\n",
      "\n",
      "Test set: Average loss: 0.0578, Accuracy: 20707/21072 (98%)\n",
      "\n",
      "Time Taken: 29.09115719795227\n",
      "\n",
      "\n",
      "Epoch: 8 Learning Rate:  0.0000\n",
      "Train Epoch: 8 [0/49168 (0.000%)]\tLoss: 0.0166944\n",
      "Train Epoch: 8 [12800/49168 (25.974%)]\tLoss: 0.0257489\n",
      "Train Epoch: 8 [25600/49168 (51.948%)]\tLoss: 0.1750069\n",
      "Train Epoch: 8 [38400/49168 (77.922%)]\tLoss: 0.0578181\n",
      "Train Set: Average loss: 0.0385, Accuracy: 48600/49168 (99%)\n",
      "\n",
      "Test set: Average loss: 0.0578, Accuracy: 20707/21072 (98%)\n",
      "\n",
      "Time Taken: 28.77691102027893\n",
      "\n",
      "\n",
      "Epoch: 9 Learning Rate:  0.0000\n",
      "Train Epoch: 9 [0/49168 (0.000%)]\tLoss: 0.0433756\n",
      "Train Epoch: 9 [12800/49168 (25.974%)]\tLoss: 0.0204681\n",
      "Train Epoch: 9 [25600/49168 (51.948%)]\tLoss: 0.0122761\n",
      "Train Epoch: 9 [38400/49168 (77.922%)]\tLoss: 0.0108264\n",
      "Train Set: Average loss: 0.0382, Accuracy: 48605/49168 (99%)\n",
      "\n",
      "Test set: Average loss: 0.0578, Accuracy: 20707/21072 (98%)\n",
      "\n",
      "Time Taken: 28.91050672531128\n",
      "\n",
      "\n",
      "Epoch: 10 Learning Rate:  0.0000\n",
      "Train Epoch: 10 [0/49168 (0.000%)]\tLoss: 0.0281482\n",
      "Train Epoch: 10 [12800/49168 (25.974%)]\tLoss: 0.0253681\n",
      "Train Epoch: 10 [25600/49168 (51.948%)]\tLoss: 0.0496508\n",
      "Train Epoch: 10 [38400/49168 (77.922%)]\tLoss: 0.0202048\n",
      "Train Set: Average loss: 0.0383, Accuracy: 48606/49168 (99%)\n",
      "\n",
      "Test set: Average loss: 0.0578, Accuracy: 20707/21072 (98%)\n",
      "\n",
      "Time Taken: 28.79398536682129\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "PRINT_INTERVAL = 100\n",
    "\n",
    "\n",
    "model = VGGNet(VGG13, 1, 10).to(device)\n",
    "\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.000050)\n",
    "scheduler = StepLR(optimizer,step_size=EPOCHS//5, gamma=0.1)\n",
    "# early_stopping = EarlyStopping(track=\"max\",patience=15, verbose=True, delta=0.00001>)\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS+ 1):\n",
    "    curT = time.time()\n",
    "    print(\"Epoch: {} Learning Rate:  {:0.4f}\".format(epoch, scheduler.get_lr()[0]))\n",
    "    train_classifier(model, optimizer, nn.NLLLoss(reduction=\"mean\"), epoch, trainloader, device, print_interval=100)\n",
    "    val_loss, val_acc = test_classifier(model,nn.NLLLoss(reduction=\"sum\"), device, validloader)\n",
    "    print(\"Time Taken: {}\\n\\n\".format(time.time()-curT))\n",
    "    scheduler.step()\n",
    "#     early_stopping(val_acc, model)\n",
    "    \n",
    "#     if early_stopping.early_stop:\n",
    "#         break\n",
    "torch.save(model.state_dict(), \"model_\"+str(EPOCHS)+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGGNet(VGG13, 1, 10).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"model_5.pt\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGGNet(\n",
       "  (vgg): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): ReLU(inplace=True)\n",
       "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): ReLU(inplace=True)\n",
       "    (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (adjustor): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=18432, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "    (7): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "for x,y in testloader:\n",
    "    pred = model(x.cuda())\n",
    "    print(pred.argmax().item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict0 = torch.load(models[0], map_location=device)\n",
    "dict1 = torch.load(models[1], map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in dict0.keys():\n",
    "    dict0[key]*=weights[0]\n",
    "    dict0[key]+=weights[1]*dict1[key]\n",
    "model.load_state_dict(dict0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.2989, Accuracy: 1068/10240 (10%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.2988876193761825, 10.4296875)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classifier (model, nn.NLLLoss(reduction=\"sum\"), device,  digloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = dict(dict0.copy())\n",
    "for name in p:\n",
    "    p[name].data.copy_(weights[0]*p[name].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vgg.0.weight': tensor([[[[-0.1049, -0.0948, -0.0666],\n",
       "           [-0.0114,  0.0723, -0.1524],\n",
       "           [ 0.0565, -0.0459,  0.0674]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0704,  0.0068, -0.0435],\n",
       "           [-0.0440, -0.1049, -0.0821],\n",
       "           [-0.0539, -0.1630, -0.1326]]],\n",
       " \n",
       " \n",
       "         [[[-0.0490, -0.0115,  0.0563],\n",
       "           [ 0.0268, -0.1036, -0.0699],\n",
       "           [ 0.1206,  0.1361,  0.1237]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0560,  0.0326, -0.1720],\n",
       "           [-0.0047, -0.0010, -0.0613],\n",
       "           [-0.0705,  0.1015,  0.1622]]],\n",
       " \n",
       " \n",
       "         [[[-0.0311, -0.0242,  0.0133],\n",
       "           [ 0.0409,  0.0573,  0.0931],\n",
       "           [-0.0856,  0.0389,  0.0915]]],\n",
       " \n",
       " \n",
       "         [[[-0.0950,  0.0257, -0.0516],\n",
       "           [ 0.1471,  0.0642, -0.0888],\n",
       "           [-0.0813, -0.0197, -0.1068]]],\n",
       " \n",
       " \n",
       "         [[[-0.0409,  0.0773,  0.1405],\n",
       "           [-0.0818,  0.1557, -0.1935],\n",
       "           [-0.1701, -0.0965, -0.0527]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1045,  0.1607,  0.0599],\n",
       "           [ 0.0853, -0.0278, -0.0106],\n",
       "           [-0.0816,  0.0756, -0.0621]]],\n",
       " \n",
       " \n",
       "         [[[-0.0111, -0.0769,  0.0980],\n",
       "           [ 0.1165,  0.1164,  0.0230],\n",
       "           [ 0.0204, -0.0031, -0.0562]]],\n",
       " \n",
       " \n",
       "         [[[-0.1132,  0.0613,  0.0620],\n",
       "           [ 0.0400, -0.0372,  0.1019],\n",
       "           [-0.0958, -0.1839,  0.1066]]],\n",
       " \n",
       " \n",
       "         [[[-0.0537, -0.0276, -0.0661],\n",
       "           [-0.0727,  0.1092,  0.0455],\n",
       "           [ 0.0302,  0.1457,  0.0105]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0597, -0.1200,  0.0366],\n",
       "           [ 0.0283, -0.0987, -0.1656],\n",
       "           [-0.0567, -0.0124, -0.1788]]],\n",
       " \n",
       " \n",
       "         [[[-0.1338,  0.0690, -0.0650],\n",
       "           [ 0.0447,  0.0954,  0.0082],\n",
       "           [ 0.0250,  0.1028, -0.0367]]],\n",
       " \n",
       " \n",
       "         [[[-0.0165,  0.1153, -0.1247],\n",
       "           [ 0.0434,  0.0968,  0.0318],\n",
       "           [-0.0246,  0.1388,  0.0643]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0516, -0.0298, -0.0617],\n",
       "           [-0.1272,  0.0283,  0.1585],\n",
       "           [ 0.0716, -0.1709, -0.1228]]],\n",
       " \n",
       " \n",
       "         [[[-0.0719,  0.1573,  0.0331],\n",
       "           [-0.0019, -0.1656, -0.0702],\n",
       "           [ 0.0953,  0.0984,  0.0589]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0225, -0.1393, -0.0649],\n",
       "           [ 0.0418, -0.0257,  0.0208],\n",
       "           [ 0.0260, -0.0210,  0.0068]]],\n",
       " \n",
       " \n",
       "         [[[-0.1584,  0.1460, -0.1746],\n",
       "           [-0.0318, -0.0696, -0.0982],\n",
       "           [-0.1100,  0.0584,  0.0364]]],\n",
       " \n",
       " \n",
       "         [[[-0.1120, -0.1025, -0.0187],\n",
       "           [-0.0121, -0.0262,  0.0487],\n",
       "           [ 0.0302,  0.0617,  0.0060]]],\n",
       " \n",
       " \n",
       "         [[[-0.0941, -0.1204,  0.0520],\n",
       "           [-0.0244,  0.0886, -0.1309],\n",
       "           [-0.0375,  0.0635,  0.0332]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0214, -0.0002,  0.0366],\n",
       "           [ 0.1855, -0.1458,  0.0463],\n",
       "           [-0.1021,  0.0230,  0.0356]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0054, -0.1677, -0.0397],\n",
       "           [ 0.1508, -0.0225, -0.0886],\n",
       "           [ 0.0574, -0.0543, -0.0355]]],\n",
       " \n",
       " \n",
       "         [[[-0.0308,  0.1383, -0.0914],\n",
       "           [-0.0550,  0.0883,  0.1546],\n",
       "           [ 0.0235,  0.0563,  0.1045]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1380,  0.0811, -0.0119],\n",
       "           [ 0.0386,  0.0691,  0.0685],\n",
       "           [-0.0397,  0.0187,  0.1310]]],\n",
       " \n",
       " \n",
       "         [[[-0.1377, -0.0164, -0.0110],\n",
       "           [-0.0524,  0.0187, -0.0927],\n",
       "           [-0.0071,  0.1540, -0.0330]]],\n",
       " \n",
       " \n",
       "         [[[-0.0902,  0.1061,  0.0121],\n",
       "           [-0.0335,  0.0470, -0.0205],\n",
       "           [-0.1773,  0.1387,  0.0233]]],\n",
       " \n",
       " \n",
       "         [[[-0.0368,  0.0348, -0.0611],\n",
       "           [-0.0573, -0.0713, -0.1800],\n",
       "           [ 0.1402,  0.1382, -0.0096]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1234, -0.1280, -0.0069],\n",
       "           [-0.1013, -0.0148,  0.0360],\n",
       "           [-0.0056, -0.0774,  0.0974]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0369,  0.0911,  0.1240],\n",
       "           [ 0.0842, -0.0087,  0.0872],\n",
       "           [ 0.1113, -0.0242, -0.1093]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0133, -0.0465, -0.0567],\n",
       "           [-0.1225, -0.0848, -0.1033],\n",
       "           [-0.0731, -0.0718,  0.0805]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0686,  0.1443, -0.0250],\n",
       "           [-0.1410,  0.0065, -0.1585],\n",
       "           [-0.0654, -0.0462,  0.0771]]],\n",
       " \n",
       " \n",
       "         [[[-0.0484,  0.0534, -0.0618],\n",
       "           [-0.0915, -0.0558,  0.0291],\n",
       "           [ 0.0756,  0.1517,  0.0900]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0937,  0.0952, -0.0231],\n",
       "           [ 0.0009, -0.1536, -0.1426],\n",
       "           [ 0.1887, -0.1677,  0.0257]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1635,  0.1176, -0.0010],\n",
       "           [-0.0504,  0.0433,  0.1274],\n",
       "           [ 0.1339,  0.0316,  0.0281]]],\n",
       " \n",
       " \n",
       "         [[[-0.1431, -0.0428, -0.1094],\n",
       "           [ 0.1752,  0.1261, -0.0380],\n",
       "           [-0.0264,  0.0487,  0.0287]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1627, -0.0505,  0.0239],\n",
       "           [ 0.0198, -0.0047,  0.0831],\n",
       "           [ 0.0063, -0.0237, -0.1329]]],\n",
       " \n",
       " \n",
       "         [[[-0.0699,  0.0101,  0.1200],\n",
       "           [-0.1374, -0.0635, -0.0845],\n",
       "           [ 0.0522, -0.1117,  0.1105]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1231,  0.1332, -0.0070],\n",
       "           [-0.0940, -0.0665, -0.0720],\n",
       "           [ 0.0774, -0.1187,  0.1396]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0149,  0.0423,  0.0834],\n",
       "           [-0.1184, -0.1560,  0.1053],\n",
       "           [-0.0994, -0.0418,  0.1158]]],\n",
       " \n",
       " \n",
       "         [[[-0.0054, -0.0703, -0.0260],\n",
       "           [ 0.0673,  0.0629, -0.0194],\n",
       "           [ 0.0398,  0.1975,  0.0937]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1528, -0.1778,  0.1855],\n",
       "           [-0.0106, -0.0320, -0.0022],\n",
       "           [ 0.1112,  0.1027,  0.1116]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1241,  0.1331,  0.0392],\n",
       "           [ 0.0735, -0.0053, -0.0243],\n",
       "           [ 0.0479,  0.1378,  0.0567]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0685, -0.0851,  0.0519],\n",
       "           [ 0.1265,  0.0230,  0.0022],\n",
       "           [-0.1211,  0.0222,  0.0994]]],\n",
       " \n",
       " \n",
       "         [[[-0.1270,  0.0536,  0.1599],\n",
       "           [ 0.1215, -0.0714,  0.1184],\n",
       "           [ 0.0954, -0.1182,  0.1007]]],\n",
       " \n",
       " \n",
       "         [[[-0.0554,  0.0360,  0.0645],\n",
       "           [ 0.0851, -0.0307,  0.0748],\n",
       "           [-0.0631, -0.0665,  0.0226]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0383, -0.0251, -0.1293],\n",
       "           [-0.1052, -0.0495, -0.0420],\n",
       "           [-0.1429,  0.0073,  0.0232]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1534,  0.2151,  0.0920],\n",
       "           [-0.1091, -0.1027, -0.1488],\n",
       "           [-0.0294, -0.0248, -0.1233]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0243, -0.0267,  0.1944],\n",
       "           [-0.0304, -0.1333, -0.0268],\n",
       "           [ 0.1550, -0.1168,  0.1032]]],\n",
       " \n",
       " \n",
       "         [[[-0.1150, -0.0935,  0.0248],\n",
       "           [-0.0138,  0.0381, -0.0448],\n",
       "           [-0.0236, -0.1492,  0.1176]]],\n",
       " \n",
       " \n",
       "         [[[-0.0285, -0.1303,  0.1496],\n",
       "           [-0.1128, -0.0241,  0.1551],\n",
       "           [ 0.1014,  0.0157, -0.0341]]],\n",
       " \n",
       " \n",
       "         [[[ 0.2077, -0.0599,  0.1593],\n",
       "           [-0.1199,  0.0162, -0.1378],\n",
       "           [ 0.0158,  0.0010,  0.0139]]],\n",
       " \n",
       " \n",
       "         [[[-0.0003, -0.1437, -0.0062],\n",
       "           [ 0.0261, -0.0476,  0.1502],\n",
       "           [-0.0336, -0.0371,  0.1300]]],\n",
       " \n",
       " \n",
       "         [[[-0.0925, -0.0190, -0.0380],\n",
       "           [ 0.1457,  0.1249,  0.2117],\n",
       "           [-0.1154, -0.1225, -0.0501]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0597,  0.0809, -0.1009],\n",
       "           [-0.0127,  0.1612,  0.1867],\n",
       "           [ 0.0771, -0.0646,  0.0843]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0066, -0.0378,  0.1269],\n",
       "           [-0.0409,  0.1194,  0.1857],\n",
       "           [ 0.0093, -0.1043,  0.1105]]],\n",
       " \n",
       " \n",
       "         [[[-0.0021, -0.0013, -0.0949],\n",
       "           [ 0.0596, -0.0145,  0.0167],\n",
       "           [-0.0473,  0.0008, -0.0169]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1247, -0.1815, -0.0374],\n",
       "           [ 0.0705, -0.1209,  0.1160],\n",
       "           [-0.1861,  0.1878,  0.0559]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0457,  0.0301,  0.0452],\n",
       "           [ 0.0452,  0.1587, -0.0946],\n",
       "           [-0.1016, -0.1173,  0.0542]]],\n",
       " \n",
       " \n",
       "         [[[-0.0222, -0.1781, -0.1443],\n",
       "           [ 0.1067,  0.1312,  0.1559],\n",
       "           [ 0.1264,  0.0766,  0.0322]]],\n",
       " \n",
       " \n",
       "         [[[-0.0623, -0.0619,  0.0787],\n",
       "           [ 0.1225, -0.0462, -0.0983],\n",
       "           [-0.0431, -0.0563,  0.1063]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0155,  0.1409, -0.1188],\n",
       "           [ 0.0976, -0.0335, -0.0709],\n",
       "           [-0.0075,  0.1309,  0.1338]]],\n",
       " \n",
       " \n",
       "         [[[-0.1000,  0.1217, -0.0400],\n",
       "           [-0.1068,  0.0331,  0.0263],\n",
       "           [ 0.1021,  0.1334, -0.1102]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0467,  0.0471,  0.0471],\n",
       "           [ 0.0285,  0.0150,  0.0686],\n",
       "           [-0.0691, -0.0475,  0.1111]]],\n",
       " \n",
       " \n",
       "         [[[-0.1173, -0.1486,  0.1635],\n",
       "           [-0.0643, -0.0507, -0.1302],\n",
       "           [-0.1876,  0.0688,  0.0717]]]], device='cuda:0'),\n",
       " 'vgg.0.bias': tensor([ 0.1039,  0.0806,  0.1275,  0.0891,  0.0354, -0.1420, -0.0234, -0.0387,\n",
       "          0.0382, -0.0045,  0.0743,  0.0845,  0.0170, -0.1113, -0.0255, -0.0894,\n",
       "          0.0407,  0.0999, -0.0454, -0.0157,  0.0409, -0.1067,  0.0573, -0.0416,\n",
       "         -0.0824,  0.1342,  0.1688,  0.0718,  0.0157, -0.0277,  0.0145,  0.0762,\n",
       "         -0.0757, -0.1293,  0.0210,  0.0105, -0.1080, -0.0916,  0.0217,  0.0119,\n",
       "         -0.0205,  0.1124,  0.1471, -0.1346,  0.0279, -0.0516, -0.0110, -0.0838,\n",
       "          0.0012, -0.0293,  0.0638, -0.0124, -0.1577,  0.0588, -0.0760,  0.1181,\n",
       "         -0.0847,  0.0938,  0.1425,  0.0044,  0.0681, -0.0277, -0.0537,  0.0497],\n",
       "        device='cuda:0'),\n",
       " 'vgg.2.weight': tensor([[[[ 2.5602e-03,  1.5847e-03,  2.0468e-02],\n",
       "           [ 9.5662e-03, -1.9760e-02,  2.0228e-02],\n",
       "           [ 1.6990e-02,  1.2413e-02, -6.5131e-03]],\n",
       " \n",
       "          [[-1.2683e-02,  6.3022e-03,  2.3483e-03],\n",
       "           [ 4.2674e-03, -3.9165e-03,  5.5783e-03],\n",
       "           [ 8.0666e-03,  2.4367e-02,  2.3935e-03]],\n",
       " \n",
       "          [[-1.4903e-02, -2.8905e-03, -9.3589e-03],\n",
       "           [ 8.3703e-03, -6.4539e-03, -1.6983e-02],\n",
       "           [-1.7011e-02,  1.1173e-02,  1.6047e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.5429e-03,  3.9358e-03,  1.1304e-03],\n",
       "           [-1.4703e-02,  4.8670e-03, -1.0960e-02],\n",
       "           [ 4.0475e-03,  9.3123e-04,  4.1489e-03]],\n",
       " \n",
       "          [[-3.0599e-03, -1.7303e-02,  9.7529e-03],\n",
       "           [ 1.9613e-02, -1.4139e-02, -4.5327e-03],\n",
       "           [-5.4599e-03,  1.5514e-02,  8.6258e-03]],\n",
       " \n",
       "          [[ 1.1793e-02, -1.7815e-02, -8.5750e-03],\n",
       "           [-9.3226e-04, -1.8435e-02,  9.2354e-03],\n",
       "           [-7.8395e-03, -4.4989e-03, -1.1307e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.5927e-02,  9.6638e-03,  2.0841e-02],\n",
       "           [-3.3885e-04,  1.4629e-02, -1.0036e-02],\n",
       "           [-1.2627e-02, -1.4733e-02,  6.9318e-03]],\n",
       " \n",
       "          [[-3.5391e-04, -8.8632e-03, -2.6574e-02],\n",
       "           [-1.2440e-02, -5.1240e-03,  1.4713e-02],\n",
       "           [ 5.5603e-03,  2.3143e-02, -7.4552e-03]],\n",
       " \n",
       "          [[ 9.3145e-03,  8.3863e-03,  2.2104e-02],\n",
       "           [ 2.4242e-02,  1.8027e-02, -2.2270e-02],\n",
       "           [-1.4890e-02, -1.2042e-02,  3.2963e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.0808e-02,  9.7914e-03,  1.7191e-02],\n",
       "           [-5.4654e-03,  1.7896e-03,  1.8627e-02],\n",
       "           [-7.4038e-03, -9.5189e-03,  2.9502e-03]],\n",
       " \n",
       "          [[ 1.4589e-03,  7.6720e-03, -5.6780e-03],\n",
       "           [ 2.3170e-03, -3.1386e-03, -1.5040e-03],\n",
       "           [-9.1212e-03,  6.2753e-03,  2.4424e-03]],\n",
       " \n",
       "          [[-9.6520e-03,  1.7104e-02, -2.0526e-02],\n",
       "           [ 1.0000e-02, -7.5007e-03,  4.7213e-03],\n",
       "           [-7.4813e-03, -9.0019e-03, -2.2168e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 6.7460e-03,  1.3492e-02,  4.5431e-03],\n",
       "           [ 9.7353e-04, -1.7004e-03, -1.6041e-02],\n",
       "           [-1.0255e-03, -2.1386e-02,  1.6324e-02]],\n",
       " \n",
       "          [[ 1.3181e-02,  1.6700e-04,  2.0706e-02],\n",
       "           [ 3.0020e-03,  1.4795e-03,  9.3681e-03],\n",
       "           [-1.4529e-02,  1.9085e-02,  3.4155e-03]],\n",
       " \n",
       "          [[-2.2348e-02,  1.2815e-02,  1.7926e-02],\n",
       "           [ 3.3383e-03, -4.8879e-03,  1.7872e-03],\n",
       "           [ 1.9790e-03,  8.8138e-03, -1.1571e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.1170e-02, -5.0725e-03, -7.2739e-03],\n",
       "           [-9.1760e-03, -1.2605e-03, -8.3335e-03],\n",
       "           [-1.6789e-02,  3.7634e-03,  6.4233e-03]],\n",
       " \n",
       "          [[ 2.1427e-03, -5.8342e-03, -2.2836e-03],\n",
       "           [ 8.6240e-04, -2.9179e-03, -1.6100e-02],\n",
       "           [ 8.3347e-03, -1.5870e-02,  1.8826e-02]],\n",
       " \n",
       "          [[-2.8111e-03, -6.7012e-03,  5.8566e-03],\n",
       "           [-8.6486e-04, -1.5549e-02, -1.2032e-02],\n",
       "           [ 1.5138e-02, -1.6311e-02, -2.7146e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 1.8800e-03, -2.3388e-03,  7.8132e-03],\n",
       "           [ 4.5188e-03, -7.2337e-03,  6.9934e-03],\n",
       "           [-1.3050e-03,  4.5724e-04,  2.2534e-03]],\n",
       " \n",
       "          [[-3.8636e-03,  2.2732e-04,  1.9342e-03],\n",
       "           [-1.6921e-02, -9.0462e-03,  1.7851e-02],\n",
       "           [ 1.8192e-02,  1.7797e-03, -6.7623e-03]],\n",
       " \n",
       "          [[ 4.7542e-03, -2.2091e-02,  4.6447e-03],\n",
       "           [ 1.0541e-02, -2.0391e-02,  1.6310e-03],\n",
       "           [ 1.4092e-03,  3.1300e-03, -2.0731e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.7449e-02, -2.8431e-03,  4.3210e-03],\n",
       "           [ 3.5434e-03,  2.3344e-03,  7.6250e-03],\n",
       "           [ 1.6205e-03, -2.6327e-03, -1.8525e-03]],\n",
       " \n",
       "          [[ 9.6454e-03, -7.4179e-03,  4.6574e-04],\n",
       "           [ 2.2079e-02,  9.2485e-03,  7.7621e-03],\n",
       "           [ 2.0957e-02,  1.0465e-02, -9.2260e-03]],\n",
       " \n",
       "          [[-1.1125e-03,  5.3708e-03, -7.5984e-03],\n",
       "           [-6.7074e-03,  2.2874e-03,  3.1935e-03],\n",
       "           [ 1.2093e-02, -1.2889e-02, -5.1325e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 4.7014e-03,  5.3178e-04, -6.1617e-03],\n",
       "           [-1.8638e-02, -1.5601e-02, -3.0089e-03],\n",
       "           [ 2.3129e-02,  9.9019e-03, -8.9664e-03]],\n",
       " \n",
       "          [[-8.9405e-03, -1.0744e-02, -1.5255e-03],\n",
       "           [-7.5824e-03, -2.0295e-03,  4.4890e-03],\n",
       "           [ 2.3693e-02, -1.0519e-02,  2.6389e-02]],\n",
       " \n",
       "          [[-5.2012e-03,  2.9228e-03, -1.9098e-02],\n",
       "           [-2.2350e-03, -2.6109e-03, -8.5121e-03],\n",
       "           [ 1.2656e-02, -1.3594e-02,  9.0320e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.7625e-03,  4.6007e-03,  1.0798e-02],\n",
       "           [ 9.0340e-03,  1.7364e-02, -9.2961e-03],\n",
       "           [-1.0644e-02, -1.3150e-03,  1.4305e-02]],\n",
       " \n",
       "          [[ 1.4854e-02, -6.6720e-03, -1.8769e-02],\n",
       "           [-5.6407e-03,  1.1529e-02, -2.1965e-03],\n",
       "           [-9.2024e-03, -7.7929e-03,  1.1098e-02]],\n",
       " \n",
       "          [[ 1.9711e-02, -2.1249e-03, -7.6836e-03],\n",
       "           [-5.5909e-03, -5.2921e-04, -1.7506e-02],\n",
       "           [ 1.5792e-02,  1.4140e-02, -1.9167e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.1284e-02,  2.1544e-02,  7.8144e-04],\n",
       "           [ 1.0783e-02,  2.5427e-02,  2.3952e-02],\n",
       "           [-2.2273e-02,  5.6025e-03,  1.5854e-02]],\n",
       " \n",
       "          [[-4.0892e-03,  1.0707e-02, -1.7303e-02],\n",
       "           [-1.6394e-02, -1.4116e-02,  1.7054e-03],\n",
       "           [ 2.1900e-03,  2.2856e-02, -9.4334e-03]],\n",
       " \n",
       "          [[ 2.5030e-02, -1.0764e-03, -1.9160e-02],\n",
       "           [ 2.8526e-03,  3.5938e-03, -1.8868e-02],\n",
       "           [-1.5383e-02,  1.2331e-03,  3.3635e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.0775e-03,  2.7414e-03,  2.0129e-02],\n",
       "           [-8.7485e-03, -4.0434e-03, -3.6078e-05],\n",
       "           [-8.7499e-03,  1.5384e-02, -9.6425e-03]],\n",
       " \n",
       "          [[-1.2189e-02, -5.5634e-03,  1.4710e-03],\n",
       "           [-1.5478e-02, -9.0738e-03,  7.2883e-03],\n",
       "           [ 2.1167e-02,  4.7940e-03,  8.8043e-03]],\n",
       " \n",
       "          [[ 2.2180e-03, -3.8456e-03, -7.9957e-03],\n",
       "           [ 2.2044e-02, -7.4427e-03,  1.0424e-02],\n",
       "           [-1.5249e-02, -8.0447e-03, -5.7682e-03]]]], device='cuda:0'),\n",
       " 'vgg.2.bias': tensor([-0.0050,  0.0025, -0.0087,  0.0248,  0.0080,  0.0149, -0.0012, -0.0073,\n",
       "          0.0230,  0.0057, -0.0152, -0.0056, -0.0021, -0.0143,  0.0053, -0.0068,\n",
       "          0.0207, -0.0038, -0.0096,  0.0211,  0.0249,  0.0157,  0.0085,  0.0059,\n",
       "          0.0035, -0.0060,  0.0184,  0.0132, -0.0063, -0.0063,  0.0023,  0.0044,\n",
       "         -0.0107, -0.0139,  0.0025, -0.0069, -0.0181,  0.0047, -0.0227,  0.0049,\n",
       "          0.0126,  0.0232,  0.0080,  0.0099, -0.0009,  0.0008, -0.0146, -0.0020,\n",
       "         -0.0019,  0.0142, -0.0073,  0.0192,  0.0134, -0.0013, -0.0092,  0.0019,\n",
       "          0.0113, -0.0063,  0.0055,  0.0128,  0.0010, -0.0015, -0.0002, -0.0049],\n",
       "        device='cuda:0'),\n",
       " 'vgg.5.weight': tensor([[[[ 1.0704e-02, -1.2533e-02, -4.7041e-04],\n",
       "           [-9.9533e-03, -6.7991e-03, -1.9416e-03],\n",
       "           [-1.3212e-02,  2.3195e-02,  1.5443e-02]],\n",
       " \n",
       "          [[-4.9220e-03, -6.9244e-03, -1.2567e-02],\n",
       "           [-4.5352e-03, -1.6726e-02,  3.7752e-03],\n",
       "           [-7.0398e-03, -4.0340e-03,  2.6279e-02]],\n",
       " \n",
       "          [[ 7.3100e-03,  1.7713e-02,  1.5430e-02],\n",
       "           [-1.1167e-02,  1.0823e-02, -1.1009e-02],\n",
       "           [ 1.0864e-02,  9.9663e-03,  7.7534e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 8.7609e-03,  2.0800e-02,  2.4366e-03],\n",
       "           [ 5.6264e-03, -2.0796e-02,  1.3414e-02],\n",
       "           [ 1.7095e-02,  1.0358e-02,  1.3302e-02]],\n",
       " \n",
       "          [[ 3.0308e-04, -9.2560e-03,  9.6544e-03],\n",
       "           [-5.0688e-03,  9.9523e-03, -1.7856e-02],\n",
       "           [-7.2756e-03,  5.7422e-03,  9.7485e-03]],\n",
       " \n",
       "          [[ 5.4248e-03, -6.2868e-03, -9.2567e-03],\n",
       "           [-8.3639e-03, -2.0069e-02,  1.7809e-03],\n",
       "           [-1.7810e-02, -4.4714e-03,  9.4552e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 2.6197e-03, -1.1830e-02, -1.2463e-02],\n",
       "           [ 2.0668e-02, -1.7941e-03,  2.3165e-02],\n",
       "           [-1.1865e-02, -1.3585e-02,  1.8997e-02]],\n",
       " \n",
       "          [[ 6.3473e-03,  3.0403e-03, -1.8084e-02],\n",
       "           [ 6.0806e-03, -2.5598e-03, -1.0358e-02],\n",
       "           [ 8.6590e-03,  6.3456e-03, -1.3913e-02]],\n",
       " \n",
       "          [[ 2.9569e-03,  6.2088e-04,  5.0473e-03],\n",
       "           [ 2.4300e-03,  1.5640e-03,  2.9329e-03],\n",
       "           [-3.6194e-04,  4.8002e-03,  1.2474e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.6058e-02, -2.2407e-02,  9.2918e-03],\n",
       "           [-8.7314e-03,  1.8136e-02, -1.7870e-02],\n",
       "           [-5.6188e-03,  3.4002e-03, -4.0422e-04]],\n",
       " \n",
       "          [[-1.0440e-02, -1.8835e-02, -1.6485e-02],\n",
       "           [ 9.6248e-03,  3.8680e-03,  9.1131e-03],\n",
       "           [-2.9695e-03,  8.2386e-05, -1.3008e-02]],\n",
       " \n",
       "          [[-4.0016e-03, -1.0856e-02, -1.7737e-03],\n",
       "           [-1.0512e-02,  9.9427e-03, -1.3592e-03],\n",
       "           [-1.0937e-02, -1.4159e-02,  5.9924e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.0288e-02,  1.4927e-03, -8.2125e-03],\n",
       "           [-2.1526e-03,  1.7883e-03, -8.2231e-03],\n",
       "           [ 2.0821e-02, -5.7057e-03,  7.9421e-03]],\n",
       " \n",
       "          [[-1.2570e-04, -1.0848e-02, -1.2745e-02],\n",
       "           [ 2.3844e-02,  1.2758e-02, -3.4454e-03],\n",
       "           [-1.6495e-02, -1.6047e-02, -1.5322e-02]],\n",
       " \n",
       "          [[-2.1116e-03, -4.6227e-03, -7.4737e-03],\n",
       "           [ 1.5266e-02, -8.0474e-03, -8.9120e-03],\n",
       "           [-7.5513e-03, -1.7332e-02, -2.5166e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.0192e-03,  9.2589e-03, -1.4783e-02],\n",
       "           [ 1.4494e-02,  1.3416e-02,  2.0077e-02],\n",
       "           [ 1.1697e-02,  2.1524e-02, -4.0632e-03]],\n",
       " \n",
       "          [[ 6.6414e-03,  3.1682e-03,  9.5263e-03],\n",
       "           [ 6.1924e-03,  4.5034e-04,  1.0390e-03],\n",
       "           [ 4.9901e-03,  1.9165e-02,  4.0471e-03]],\n",
       " \n",
       "          [[ 5.3565e-04, -5.1027e-03,  5.3963e-03],\n",
       "           [-1.5949e-04,  5.0113e-03, -1.7985e-03],\n",
       "           [-9.3055e-03, -1.5902e-04, -9.5675e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 8.1779e-03, -7.1752e-03, -9.8637e-03],\n",
       "           [ 2.4220e-03,  1.6581e-02,  1.1514e-02],\n",
       "           [-3.2694e-03,  1.1136e-02,  6.0374e-03]],\n",
       " \n",
       "          [[ 4.5500e-03,  3.4652e-03,  1.0197e-02],\n",
       "           [ 5.7248e-03,  3.7470e-03,  1.0085e-02],\n",
       "           [-2.3791e-03,  1.6686e-02, -1.4110e-03]],\n",
       " \n",
       "          [[-4.7541e-03,  7.3900e-04, -2.1537e-02],\n",
       "           [ 5.6714e-03,  9.4653e-03,  1.7223e-02],\n",
       "           [-1.0059e-02, -2.2006e-02,  5.9982e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 5.8489e-03,  1.6871e-02, -1.3119e-02],\n",
       "           [-1.1644e-03,  2.1271e-02, -2.8824e-03],\n",
       "           [ 1.1582e-02, -2.3722e-02, -1.7676e-02]],\n",
       " \n",
       "          [[ 2.3347e-04,  1.3784e-02,  2.0466e-02],\n",
       "           [-2.2876e-03,  2.2660e-02,  3.7687e-03],\n",
       "           [ 1.1326e-02,  8.7729e-03,  1.3517e-02]],\n",
       " \n",
       "          [[ 4.2281e-03,  1.9776e-02, -1.4586e-02],\n",
       "           [-4.9342e-03,  5.4651e-03, -1.9136e-02],\n",
       "           [ 8.4738e-03, -9.1138e-03, -5.3910e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 7.2283e-03, -5.6243e-04,  1.6333e-02],\n",
       "           [-3.8122e-03,  1.1662e-02,  1.3922e-02],\n",
       "           [-1.8418e-02, -6.4684e-03,  1.0668e-02]],\n",
       " \n",
       "          [[-4.4340e-03, -7.5458e-03, -9.6648e-03],\n",
       "           [-8.7083e-03, -2.4462e-02, -1.5406e-02],\n",
       "           [-8.7514e-03,  6.1725e-03, -1.0730e-02]],\n",
       " \n",
       "          [[-2.3949e-02, -1.2825e-02,  1.7661e-02],\n",
       "           [ 5.9936e-03,  2.5370e-02,  6.6518e-03],\n",
       "           [-1.2651e-02, -1.1364e-02, -1.7883e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.7374e-03, -4.5662e-03,  7.5467e-03],\n",
       "           [-1.0572e-02,  1.9317e-02,  2.4207e-02],\n",
       "           [ 1.6460e-02, -4.1918e-03, -1.4025e-02]],\n",
       " \n",
       "          [[-1.1642e-03, -1.1253e-02, -1.7475e-02],\n",
       "           [ 8.7026e-03, -1.1389e-02, -1.0275e-02],\n",
       "           [-4.7545e-03,  1.0329e-02, -2.0581e-03]],\n",
       " \n",
       "          [[ 1.5535e-02, -1.0754e-02, -4.9716e-04],\n",
       "           [-1.7134e-03, -9.0728e-03, -1.3075e-02],\n",
       "           [-1.7877e-02, -7.8647e-03, -1.8629e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.0813e-03,  2.2129e-03, -1.8857e-02],\n",
       "           [-4.3072e-03, -8.7396e-04,  1.2700e-02],\n",
       "           [-1.5393e-02,  3.4351e-03,  9.0049e-03]],\n",
       " \n",
       "          [[-2.6211e-03, -1.6195e-02,  2.4776e-03],\n",
       "           [ 6.6061e-03,  3.7170e-03, -1.7078e-02],\n",
       "           [-1.2774e-02, -7.6019e-03, -2.1027e-02]],\n",
       " \n",
       "          [[ 1.2737e-02, -2.2032e-03,  1.7750e-03],\n",
       "           [ 8.1222e-03, -1.4150e-02,  5.4381e-03],\n",
       "           [ 1.5355e-02,  3.8065e-03, -1.5073e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.3611e-02,  2.0187e-02,  4.7547e-03],\n",
       "           [ 4.0682e-03, -2.6313e-03,  1.2412e-02],\n",
       "           [-7.6085e-03,  5.2607e-03, -4.7466e-03]],\n",
       " \n",
       "          [[-8.5525e-03,  7.1382e-03, -2.1981e-02],\n",
       "           [-1.1595e-02,  8.0584e-03,  2.2162e-02],\n",
       "           [ 1.7473e-02,  2.3339e-02, -1.3113e-02]],\n",
       " \n",
       "          [[ 2.9741e-03, -1.0776e-02,  4.4927e-03],\n",
       "           [ 1.3754e-02, -1.4732e-03,  9.4524e-03],\n",
       "           [-4.8171e-03,  1.5374e-03,  9.8073e-03]]]], device='cuda:0'),\n",
       " 'vgg.5.bias': tensor([-0.0134, -0.0074, -0.0083, -0.0003,  0.0107, -0.0059, -0.0061, -0.0121,\n",
       "         -0.0077, -0.0087,  0.0099, -0.0067,  0.0196, -0.0066,  0.0012, -0.0011,\n",
       "         -0.0192,  0.0139,  0.0013, -0.0070, -0.0007, -0.0023, -0.0239, -0.0011,\n",
       "          0.0038,  0.0084, -0.0018, -0.0111,  0.0007,  0.0197,  0.0068,  0.0067,\n",
       "         -0.0125,  0.0090, -0.0109,  0.0019, -0.0103, -0.0164, -0.0236, -0.0113,\n",
       "         -0.0108,  0.0088,  0.0021,  0.0136,  0.0075,  0.0200, -0.0127,  0.0125,\n",
       "         -0.0146,  0.0151, -0.0139, -0.0134,  0.0059, -0.0013, -0.0099, -0.0105,\n",
       "         -0.0020,  0.0023,  0.0016,  0.0061, -0.0034, -0.0203, -0.0001, -0.0211,\n",
       "         -0.0045,  0.0056,  0.0002, -0.0052, -0.0005, -0.0118, -0.0011, -0.0022,\n",
       "          0.0021, -0.0157, -0.0038,  0.0022,  0.0118,  0.0073,  0.0103, -0.0087,\n",
       "         -0.0086, -0.0103,  0.0077,  0.0144,  0.0040,  0.0226, -0.0040,  0.0002,\n",
       "         -0.0186, -0.0080, -0.0221, -0.0019, -0.0013, -0.0013,  0.0282,  0.0110,\n",
       "          0.0163, -0.0053, -0.0002,  0.0178, -0.0008,  0.0030, -0.0047,  0.0152,\n",
       "         -0.0158,  0.0058, -0.0082,  0.0042, -0.0007,  0.0106,  0.0029,  0.0131,\n",
       "         -0.0149,  0.0037, -0.0150,  0.0009, -0.0032,  0.0046, -0.0077,  0.0048,\n",
       "         -0.0118,  0.0037, -0.0148, -0.0124, -0.0115, -0.0098, -0.0143, -0.0109],\n",
       "        device='cuda:0'),\n",
       " 'vgg.7.weight': tensor([[[[-0.0048,  0.0047, -0.0051],\n",
       "           [ 0.0013,  0.0169, -0.0009],\n",
       "           [ 0.0103, -0.0043, -0.0074]],\n",
       " \n",
       "          [[-0.0075, -0.0007,  0.0056],\n",
       "           [-0.0065, -0.0037,  0.0033],\n",
       "           [-0.0032,  0.0080,  0.0135]],\n",
       " \n",
       "          [[-0.0060,  0.0010, -0.0130],\n",
       "           [ 0.0066,  0.0110, -0.0161],\n",
       "           [-0.0085,  0.0022,  0.0036]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0053, -0.0095, -0.0050],\n",
       "           [-0.0158, -0.0079, -0.0036],\n",
       "           [-0.0064, -0.0056, -0.0085]],\n",
       " \n",
       "          [[ 0.0035,  0.0047, -0.0037],\n",
       "           [-0.0019, -0.0026, -0.0059],\n",
       "           [ 0.0006, -0.0044,  0.0030]],\n",
       " \n",
       "          [[ 0.0063, -0.0008, -0.0004],\n",
       "           [ 0.0146, -0.0025,  0.0019],\n",
       "           [-0.0089,  0.0166, -0.0035]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0004, -0.0078,  0.0084],\n",
       "           [ 0.0096,  0.0023,  0.0025],\n",
       "           [-0.0042,  0.0045, -0.0010]],\n",
       " \n",
       "          [[ 0.0016,  0.0120, -0.0118],\n",
       "           [-0.0059, -0.0005,  0.0031],\n",
       "           [-0.0014, -0.0105, -0.0023]],\n",
       " \n",
       "          [[ 0.0035, -0.0063, -0.0178],\n",
       "           [ 0.0143,  0.0068, -0.0099],\n",
       "           [-0.0052,  0.0096, -0.0054]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0083,  0.0062,  0.0095],\n",
       "           [-0.0043, -0.0006,  0.0059],\n",
       "           [-0.0067, -0.0051,  0.0003]],\n",
       " \n",
       "          [[-0.0029, -0.0062, -0.0120],\n",
       "           [ 0.0039,  0.0011,  0.0036],\n",
       "           [ 0.0026,  0.0138, -0.0132]],\n",
       " \n",
       "          [[ 0.0062,  0.0127,  0.0056],\n",
       "           [ 0.0056, -0.0055, -0.0145],\n",
       "           [-0.0006, -0.0031,  0.0084]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0050, -0.0155,  0.0104],\n",
       "           [-0.0083, -0.0059, -0.0092],\n",
       "           [ 0.0017,  0.0046, -0.0172]],\n",
       " \n",
       "          [[-0.0068,  0.0001,  0.0107],\n",
       "           [-0.0029, -0.0068, -0.0033],\n",
       "           [-0.0029, -0.0056, -0.0003]],\n",
       " \n",
       "          [[ 0.0078, -0.0086,  0.0091],\n",
       "           [ 0.0082, -0.0050,  0.0135],\n",
       "           [ 0.0143, -0.0177,  0.0146]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0093,  0.0035,  0.0030],\n",
       "           [-0.0017, -0.0122, -0.0075],\n",
       "           [-0.0117, -0.0119, -0.0151]],\n",
       " \n",
       "          [[-0.0133, -0.0042, -0.0002],\n",
       "           [ 0.0013, -0.0081, -0.0029],\n",
       "           [-0.0036,  0.0012, -0.0092]],\n",
       " \n",
       "          [[-0.0049,  0.0102, -0.0004],\n",
       "           [ 0.0126, -0.0035, -0.0070],\n",
       "           [ 0.0036, -0.0038,  0.0153]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0151, -0.0043,  0.0021],\n",
       "           [-0.0083,  0.0008, -0.0100],\n",
       "           [ 0.0026, -0.0120,  0.0120]],\n",
       " \n",
       "          [[ 0.0096, -0.0058, -0.0048],\n",
       "           [ 0.0126,  0.0060, -0.0044],\n",
       "           [ 0.0082, -0.0070, -0.0054]],\n",
       " \n",
       "          [[ 0.0028,  0.0083, -0.0189],\n",
       "           [ 0.0031, -0.0107,  0.0064],\n",
       "           [ 0.0134, -0.0137,  0.0122]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0059,  0.0012, -0.0165],\n",
       "           [ 0.0160, -0.0157, -0.0030],\n",
       "           [-0.0147, -0.0128,  0.0028]],\n",
       " \n",
       "          [[-0.0083, -0.0117,  0.0002],\n",
       "           [ 0.0035, -0.0178, -0.0046],\n",
       "           [ 0.0067, -0.0074, -0.0011]],\n",
       " \n",
       "          [[ 0.0036, -0.0016,  0.0148],\n",
       "           [ 0.0147,  0.0061,  0.0038],\n",
       "           [ 0.0031, -0.0078, -0.0020]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0065, -0.0079, -0.0034],\n",
       "           [ 0.0044, -0.0037,  0.0057],\n",
       "           [ 0.0108, -0.0045,  0.0101]],\n",
       " \n",
       "          [[ 0.0047,  0.0010,  0.0178],\n",
       "           [-0.0133, -0.0124,  0.0023],\n",
       "           [-0.0004,  0.0095,  0.0019]],\n",
       " \n",
       "          [[-0.0098,  0.0090, -0.0019],\n",
       "           [-0.0015,  0.0029,  0.0054],\n",
       "           [ 0.0077,  0.0043,  0.0124]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0005, -0.0142, -0.0110],\n",
       "           [-0.0196,  0.0015, -0.0087],\n",
       "           [-0.0118, -0.0173,  0.0035]],\n",
       " \n",
       "          [[-0.0054,  0.0067, -0.0012],\n",
       "           [-0.0085, -0.0142,  0.0034],\n",
       "           [-0.0073, -0.0106,  0.0076]],\n",
       " \n",
       "          [[ 0.0026, -0.0041, -0.0155],\n",
       "           [ 0.0179,  0.0068,  0.0026],\n",
       "           [ 0.0013,  0.0002, -0.0024]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0108, -0.0015, -0.0141],\n",
       "           [-0.0028,  0.0072,  0.0063],\n",
       "           [-0.0058, -0.0015, -0.0135]],\n",
       " \n",
       "          [[ 0.0094, -0.0116,  0.0067],\n",
       "           [-0.0176,  0.0052,  0.0009],\n",
       "           [-0.0043, -0.0123, -0.0108]],\n",
       " \n",
       "          [[ 0.0019,  0.0047,  0.0063],\n",
       "           [-0.0038,  0.0118,  0.0034],\n",
       "           [-0.0003, -0.0010,  0.0050]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0011,  0.0010,  0.0011],\n",
       "           [ 0.0066,  0.0188,  0.0061],\n",
       "           [-0.0102, -0.0121, -0.0116]],\n",
       " \n",
       "          [[ 0.0028,  0.0059, -0.0040],\n",
       "           [-0.0086,  0.0100, -0.0076],\n",
       "           [ 0.0035, -0.0026,  0.0015]],\n",
       " \n",
       "          [[ 0.0083, -0.0034,  0.0173],\n",
       "           [ 0.0019, -0.0100, -0.0032],\n",
       "           [ 0.0012, -0.0114,  0.0135]]]], device='cuda:0'),\n",
       " 'vgg.7.bias': tensor([ 3.2403e-03, -1.4352e-02, -5.6116e-03,  1.6222e-03, -7.5650e-03,\n",
       "          1.5673e-04, -7.0199e-03, -8.6731e-03,  6.5111e-03,  1.6276e-02,\n",
       "         -5.2861e-03, -3.7653e-03, -1.1400e-03,  1.1987e-02,  1.2010e-02,\n",
       "         -7.4736e-03, -1.2350e-02,  4.0327e-03, -2.0569e-03,  1.5142e-02,\n",
       "         -5.8094e-03,  1.0990e-03, -5.5993e-03,  1.3949e-03,  3.5135e-03,\n",
       "         -9.4903e-03, -7.9233e-03, -4.2197e-03, -9.0400e-03,  4.8496e-03,\n",
       "          9.4345e-03,  1.1329e-02, -3.4479e-03,  1.7042e-02, -1.3785e-02,\n",
       "          1.2118e-02, -9.3419e-03,  2.9271e-04,  7.0936e-03,  2.3218e-03,\n",
       "          1.5976e-03,  7.6865e-05, -2.5203e-03, -1.3093e-02,  2.5245e-03,\n",
       "          2.5564e-04,  1.4464e-02,  1.0353e-02,  3.5155e-03, -4.4211e-03,\n",
       "         -7.5825e-03, -1.0649e-02,  1.3352e-02, -7.8247e-03,  7.0510e-03,\n",
       "         -9.5937e-03,  5.9137e-03,  1.1132e-02,  1.5961e-03,  8.2459e-03,\n",
       "          1.4224e-02,  6.4248e-03,  6.1002e-03, -5.1786e-03,  4.7863e-03,\n",
       "          1.3420e-02,  1.2665e-02, -2.5937e-03,  3.5145e-03,  1.0857e-02,\n",
       "          1.7193e-02,  4.2772e-03, -3.8854e-03, -9.6541e-03,  6.2556e-04,\n",
       "          1.6702e-03,  1.0092e-02,  4.1591e-03, -4.2802e-03,  3.7926e-03,\n",
       "          7.5849e-03,  8.9924e-03,  3.6533e-03,  8.7123e-04, -2.2583e-03,\n",
       "          6.8512e-03, -1.2320e-03,  8.6843e-03, -1.0703e-03, -2.3723e-03,\n",
       "         -9.0936e-04,  5.0694e-03,  7.0925e-03, -2.7638e-03,  6.2704e-03,\n",
       "          2.7974e-03, -1.5198e-02, -8.9100e-03, -4.0132e-03,  1.3929e-03,\n",
       "          5.6462e-03,  1.0893e-02,  1.5540e-02,  1.2243e-02,  1.7757e-02,\n",
       "         -1.0092e-02, -1.2498e-02,  6.6728e-05, -5.5199e-03,  9.1183e-03,\n",
       "          1.5693e-02, -4.4937e-03, -4.7818e-03,  1.0006e-04, -6.5811e-03,\n",
       "          4.1392e-03,  9.1441e-04,  3.7469e-03,  5.6218e-03, -6.4738e-03,\n",
       "          9.9371e-04,  3.7022e-04, -1.5602e-02, -8.4652e-03,  8.3545e-03,\n",
       "          1.3848e-02,  1.5621e-02,  3.7478e-03], device='cuda:0'),\n",
       " 'vgg.10.weight': tensor([[[[ 4.6073e-03, -6.6714e-03, -5.0992e-03],\n",
       "           [-2.7094e-03,  1.6807e-02,  7.5427e-03],\n",
       "           [-1.2154e-03, -1.6435e-02, -6.8073e-03]],\n",
       " \n",
       "          [[-1.1260e-03,  1.2810e-02, -1.2174e-03],\n",
       "           [ 2.2627e-03, -6.8468e-03, -8.9342e-03],\n",
       "           [ 9.1415e-03, -1.8492e-02, -8.2793e-03]],\n",
       " \n",
       "          [[ 3.1580e-03, -7.0922e-03, -2.9636e-03],\n",
       "           [-6.8689e-03,  1.6369e-04,  4.2051e-03],\n",
       "           [ 3.9289e-03,  9.6436e-03,  1.5222e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.1002e-03, -4.6788e-03,  3.7116e-03],\n",
       "           [-4.7534e-03, -7.8271e-03, -7.8842e-03],\n",
       "           [ 7.7512e-03, -6.5512e-03,  1.7293e-02]],\n",
       " \n",
       "          [[ 2.4907e-04,  1.3411e-02,  5.3404e-03],\n",
       "           [-2.9951e-03,  4.4391e-03,  1.3081e-03],\n",
       "           [-1.0263e-02, -1.5242e-02, -4.6271e-03]],\n",
       " \n",
       "          [[ 3.9451e-03, -4.6370e-03,  1.4767e-02],\n",
       "           [-4.9403e-03, -8.7761e-03,  6.5268e-03],\n",
       "           [-1.0024e-02, -1.0372e-02, -4.6463e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.8875e-02,  6.8725e-03,  1.5344e-03],\n",
       "           [ 1.0645e-02,  1.2463e-04, -3.1702e-03],\n",
       "           [-1.3217e-02, -8.0635e-03, -7.6668e-03]],\n",
       " \n",
       "          [[ 1.9551e-04, -3.2064e-03, -1.2165e-02],\n",
       "           [ 4.2323e-03, -1.1807e-03,  8.2802e-03],\n",
       "           [-1.1992e-02,  1.5415e-02,  3.6566e-03]],\n",
       " \n",
       "          [[ 1.5262e-02,  8.6702e-03,  5.8265e-03],\n",
       "           [-1.3258e-04, -1.0024e-03, -5.1754e-03],\n",
       "           [-3.5043e-03,  7.7102e-03, -9.1812e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 5.6030e-04,  7.6348e-03, -1.6008e-03],\n",
       "           [-4.8430e-03, -9.9764e-03,  1.3719e-02],\n",
       "           [-8.1322e-03,  6.8783e-03, -1.2120e-02]],\n",
       " \n",
       "          [[ 5.4987e-03,  1.4023e-02, -1.1878e-02],\n",
       "           [ 2.8509e-03,  1.5364e-02, -4.5780e-03],\n",
       "           [ 7.9735e-03,  2.5214e-04,  1.8151e-02]],\n",
       " \n",
       "          [[ 1.6552e-02, -8.9573e-03,  3.0189e-03],\n",
       "           [-7.1281e-03,  2.4350e-03, -9.6578e-04],\n",
       "           [-1.5976e-02,  8.1183e-04,  6.5439e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 5.8915e-03,  6.3977e-03,  1.5477e-02],\n",
       "           [-1.0685e-02, -1.1805e-02,  1.9865e-04],\n",
       "           [ 1.0624e-03, -6.4002e-03,  6.2411e-03]],\n",
       " \n",
       "          [[ 1.4589e-03,  5.1763e-03,  9.2730e-03],\n",
       "           [-5.2307e-03, -5.7563e-05, -2.8195e-03],\n",
       "           [ 2.6457e-03, -1.1599e-02,  4.4669e-03]],\n",
       " \n",
       "          [[ 2.3266e-04,  4.3491e-03,  9.3951e-04],\n",
       "           [-1.3733e-02, -6.8999e-03, -3.0160e-03],\n",
       "           [-3.6658e-03,  7.4813e-03,  1.0814e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 9.5263e-03,  2.0074e-03, -3.3476e-03],\n",
       "           [ 4.7880e-03, -8.3714e-03, -1.4927e-02],\n",
       "           [ 1.0357e-02,  1.0466e-03,  1.1799e-02]],\n",
       " \n",
       "          [[ 2.7098e-03,  3.5338e-03, -2.7707e-03],\n",
       "           [ 1.0971e-03,  6.4132e-03, -1.0353e-02],\n",
       "           [-1.1908e-02,  1.9483e-02, -1.2888e-02]],\n",
       " \n",
       "          [[-1.5447e-02,  1.2741e-02,  2.0794e-03],\n",
       "           [ 5.7175e-03,  8.0625e-03, -7.4810e-03],\n",
       "           [ 1.1257e-02, -1.0449e-02,  1.1535e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 5.4671e-03, -1.9108e-03,  1.2957e-02],\n",
       "           [-3.2622e-03, -9.1156e-03,  5.6010e-03],\n",
       "           [-2.1345e-03,  5.3554e-03, -8.4924e-03]],\n",
       " \n",
       "          [[ 8.8090e-03, -2.0826e-03,  1.4268e-03],\n",
       "           [-7.4046e-03,  3.2451e-04, -1.1970e-02],\n",
       "           [-4.6975e-03, -1.8926e-02,  1.2015e-02]],\n",
       " \n",
       "          [[ 5.7260e-04, -6.1881e-03, -9.2835e-03],\n",
       "           [-6.6939e-04, -4.5240e-03,  4.0988e-03],\n",
       "           [-1.0206e-02, -7.4326e-03, -4.1565e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.2799e-03,  3.3341e-04,  9.5697e-03],\n",
       "           [ 2.7522e-03, -4.1559e-03,  5.4196e-03],\n",
       "           [ 6.6445e-03, -5.4102e-03, -3.5727e-03]],\n",
       " \n",
       "          [[ 8.0102e-03, -9.3554e-03, -1.4243e-03],\n",
       "           [ 7.6494e-03, -7.0555e-03,  1.0704e-02],\n",
       "           [-2.8995e-03, -8.4468e-03,  5.7073e-03]],\n",
       " \n",
       "          [[ 2.4437e-03,  3.2284e-03, -4.3707e-03],\n",
       "           [-8.3129e-03, -1.7324e-05,  1.0264e-02],\n",
       "           [-5.5694e-03,  1.1977e-02,  4.6285e-03]]],\n",
       " \n",
       " \n",
       "         [[[-7.3634e-04, -9.7308e-03, -1.6563e-02],\n",
       "           [-4.6075e-03,  8.5669e-03,  9.2777e-03],\n",
       "           [-1.4036e-03, -2.2700e-03, -1.2231e-02]],\n",
       " \n",
       "          [[-7.7902e-03, -3.0758e-03,  1.0573e-02],\n",
       "           [ 7.7889e-03, -1.3847e-04, -6.7059e-03],\n",
       "           [-1.0263e-02, -4.1343e-04, -6.6069e-05]],\n",
       " \n",
       "          [[-3.0600e-03, -1.0572e-02,  5.3461e-03],\n",
       "           [-6.1564e-03, -3.5056e-03,  2.1373e-03],\n",
       "           [-1.1707e-02, -1.4418e-02,  4.8886e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.4328e-03, -5.8896e-03, -8.3300e-03],\n",
       "           [ 9.9889e-03,  9.7877e-03, -8.5741e-03],\n",
       "           [ 1.6816e-03, -8.3993e-03, -7.6155e-03]],\n",
       " \n",
       "          [[ 1.1929e-02, -5.1350e-03, -1.5905e-02],\n",
       "           [-1.3626e-02,  1.3856e-02,  1.0123e-02],\n",
       "           [-3.0798e-03,  6.0690e-03,  4.8454e-03]],\n",
       " \n",
       "          [[-6.9076e-03,  6.0402e-03, -6.5549e-03],\n",
       "           [ 8.3115e-03,  1.0853e-03, -1.3347e-02],\n",
       "           [-1.2369e-02, -1.5397e-02, -8.7725e-04]]],\n",
       " \n",
       " \n",
       "         [[[ 1.1262e-02, -1.7509e-03,  1.0055e-02],\n",
       "           [ 2.2370e-03,  7.2033e-03, -1.7963e-03],\n",
       "           [ 8.8749e-03, -7.0006e-04,  4.8171e-03]],\n",
       " \n",
       "          [[ 2.2444e-04,  8.1246e-03, -5.2302e-03],\n",
       "           [-5.3305e-03, -9.0429e-03,  8.6629e-03],\n",
       "           [ 3.8203e-03, -1.1332e-02,  8.0635e-03]],\n",
       " \n",
       "          [[ 3.1403e-04,  1.7368e-02, -2.3580e-04],\n",
       "           [ 9.4087e-03,  1.0836e-02, -3.9261e-03],\n",
       "           [-3.6390e-03,  2.3033e-03, -1.5567e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 7.0058e-03,  5.0994e-03,  8.1543e-03],\n",
       "           [ 6.8446e-03, -9.4987e-03,  1.3844e-02],\n",
       "           [ 8.4173e-03, -5.7404e-03, -2.9049e-03]],\n",
       " \n",
       "          [[-6.0824e-03,  8.7089e-03,  9.4148e-03],\n",
       "           [ 5.5804e-03, -3.7227e-03, -1.0673e-02],\n",
       "           [ 3.1832e-04, -1.0189e-03, -5.0117e-03]],\n",
       " \n",
       "          [[ 1.9889e-04, -1.0203e-02, -8.5778e-04],\n",
       "           [ 1.8315e-03, -5.9820e-03, -6.2952e-04],\n",
       "           [-1.0567e-02,  2.6327e-03, -1.2780e-02]]]], device='cuda:0'),\n",
       " 'vgg.10.bias': tensor([-0.0021,  0.0050,  0.0090,  0.0040, -0.0092, -0.0050, -0.0104,  0.0110,\n",
       "          0.0157,  0.0039, -0.0069,  0.0015, -0.0133,  0.0089,  0.0181,  0.0092,\n",
       "         -0.0031,  0.0008,  0.0098,  0.0151, -0.0038,  0.0036,  0.0126, -0.0060,\n",
       "         -0.0023, -0.0172,  0.0023,  0.0173, -0.0009,  0.0042, -0.0020,  0.0160,\n",
       "         -0.0044, -0.0153,  0.0119,  0.0052,  0.0013, -0.0013,  0.0078,  0.0043,\n",
       "         -0.0038, -0.0059,  0.0107, -0.0099,  0.0035,  0.0006, -0.0047,  0.0072,\n",
       "          0.0014,  0.0036, -0.0003,  0.0150,  0.0034,  0.0100, -0.0043,  0.0102,\n",
       "         -0.0133, -0.0003, -0.0109,  0.0043,  0.0021, -0.0092, -0.0073,  0.0027,\n",
       "          0.0040,  0.0046,  0.0122, -0.0082,  0.0117, -0.0058,  0.0021,  0.0124,\n",
       "          0.0057,  0.0103, -0.0159, -0.0072,  0.0093,  0.0043, -0.0045,  0.0032,\n",
       "         -0.0004, -0.0133, -0.0124, -0.0101, -0.0038,  0.0070,  0.0077,  0.0135,\n",
       "          0.0072, -0.0009,  0.0080, -0.0150,  0.0059,  0.0020,  0.0021, -0.0081,\n",
       "          0.0059, -0.0112,  0.0010, -0.0049,  0.0056, -0.0112,  0.0065,  0.0012,\n",
       "          0.0016,  0.0076, -0.0011, -0.0088, -0.0077, -0.0063, -0.0016, -0.0139,\n",
       "          0.0050,  0.0112,  0.0006, -0.0070,  0.0014,  0.0102,  0.0034, -0.0043,\n",
       "         -0.0101, -0.0031,  0.0140,  0.0079, -0.0003,  0.0115, -0.0022,  0.0064,\n",
       "         -0.0119, -0.0095,  0.0024,  0.0021, -0.0022, -0.0072,  0.0100, -0.0041,\n",
       "          0.0018, -0.0012,  0.0006,  0.0055, -0.0147,  0.0005,  0.0002, -0.0027,\n",
       "          0.0093,  0.0089,  0.0022,  0.0115,  0.0017,  0.0034, -0.0040, -0.0020,\n",
       "         -0.0096,  0.0089,  0.0090, -0.0012, -0.0039,  0.0037, -0.0029,  0.0050,\n",
       "          0.0157, -0.0094,  0.0065,  0.0098,  0.0038,  0.0062,  0.0018,  0.0030,\n",
       "         -0.0121,  0.0037, -0.0042, -0.0109,  0.0096,  0.0059, -0.0021,  0.0124,\n",
       "         -0.0070, -0.0033, -0.0159,  0.0141, -0.0037, -0.0057, -0.0044,  0.0094,\n",
       "         -0.0048, -0.0048,  0.0161,  0.0114, -0.0017, -0.0073, -0.0094,  0.0009,\n",
       "         -0.0033,  0.0066, -0.0175, -0.0060,  0.0093, -0.0051,  0.0012, -0.0065,\n",
       "          0.0029,  0.0067, -0.0058,  0.0107, -0.0012, -0.0110,  0.0180,  0.0038,\n",
       "          0.0002, -0.0055,  0.0025, -0.0060, -0.0065,  0.0065, -0.0112,  0.0004,\n",
       "         -0.0021, -0.0065,  0.0045, -0.0021, -0.0079,  0.0036,  0.0113, -0.0035,\n",
       "         -0.0095,  0.0071, -0.0038,  0.0182, -0.0109, -0.0010,  0.0006, -0.0029,\n",
       "         -0.0115,  0.0036,  0.0119, -0.0017, -0.0061, -0.0157, -0.0039,  0.0129,\n",
       "         -0.0155,  0.0156,  0.0029, -0.0107,  0.0045, -0.0116,  0.0094,  0.0057,\n",
       "         -0.0029,  0.0105,  0.0056,  0.0065,  0.0051, -0.0108,  0.0059,  0.0089],\n",
       "        device='cuda:0'),\n",
       " 'vgg.12.weight': tensor([[[[-4.9389e-03, -8.8861e-03,  8.2148e-04],\n",
       "           [ 1.4110e-03, -8.6853e-03, -8.3135e-04],\n",
       "           [-1.3984e-03, -4.9546e-03,  4.0840e-04]],\n",
       " \n",
       "          [[-2.1899e-03, -6.9859e-04,  6.6787e-03],\n",
       "           [ 3.0532e-03, -1.5702e-04,  4.8159e-03],\n",
       "           [-4.4757e-03,  5.5935e-04,  1.1365e-02]],\n",
       " \n",
       "          [[-7.9405e-04, -3.9626e-04, -5.6046e-03],\n",
       "           [-1.1017e-03,  1.8513e-03,  7.6152e-03],\n",
       "           [-3.9555e-03,  4.8554e-03,  6.2078e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-8.5099e-03, -4.1050e-03, -6.7474e-03],\n",
       "           [-7.0273e-03, -4.3859e-04,  9.8223e-03],\n",
       "           [-1.2788e-03,  8.8885e-03, -9.1563e-04]],\n",
       " \n",
       "          [[ 7.4062e-03, -1.2619e-02, -2.0549e-03],\n",
       "           [ 5.3309e-03,  8.2100e-03, -3.5680e-03],\n",
       "           [ 8.0269e-03, -4.7206e-03, -1.2394e-02]],\n",
       " \n",
       "          [[ 3.2079e-03, -1.1784e-02, -5.7437e-03],\n",
       "           [ 1.4252e-02,  2.5846e-03, -1.3055e-04],\n",
       "           [ 4.8023e-03, -4.8708e-03,  1.6149e-03]]],\n",
       " \n",
       " \n",
       "         [[[-6.2463e-03,  3.2239e-03, -1.1919e-02],\n",
       "           [-7.2807e-03,  6.1975e-03, -3.5795e-03],\n",
       "           [-2.9659e-04, -6.4136e-03, -2.4835e-03]],\n",
       " \n",
       "          [[-3.1583e-03,  1.3091e-03, -8.6814e-03],\n",
       "           [ 7.6939e-03,  5.6275e-03, -8.0647e-03],\n",
       "           [-6.1931e-03, -1.1832e-02,  2.8992e-03]],\n",
       " \n",
       "          [[ 3.1258e-03, -6.8177e-04,  2.0021e-03],\n",
       "           [ 3.8596e-03,  4.4419e-04, -6.4739e-03],\n",
       "           [-2.8122e-03, -4.3087e-03,  4.2749e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-7.4462e-04,  6.3891e-03, -6.2114e-03],\n",
       "           [ 6.5836e-03,  4.8050e-05, -5.1370e-03],\n",
       "           [ 1.2731e-02, -9.7192e-04, -4.0336e-03]],\n",
       " \n",
       "          [[ 4.2884e-03, -4.6691e-03, -5.6738e-03],\n",
       "           [ 6.1869e-03, -2.8978e-03,  4.8594e-03],\n",
       "           [-1.4952e-03,  7.4552e-03,  5.4262e-03]],\n",
       " \n",
       "          [[ 1.6701e-03,  8.1154e-03,  4.7057e-03],\n",
       "           [-1.0031e-02, -4.7496e-03,  8.2706e-03],\n",
       "           [ 4.0423e-03,  2.4530e-04, -8.9619e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.1167e-02, -3.8284e-03, -8.5266e-03],\n",
       "           [-3.2013e-03,  2.5859e-03, -4.5310e-03],\n",
       "           [ 6.4479e-03, -3.7267e-03, -7.8195e-03]],\n",
       " \n",
       "          [[ 2.7733e-04,  4.6801e-03, -5.2769e-03],\n",
       "           [ 8.1143e-03, -1.0531e-02, -2.0600e-03],\n",
       "           [-9.5246e-03, -4.8151e-03, -6.2004e-03]],\n",
       " \n",
       "          [[-6.3684e-03,  1.2904e-02, -5.1772e-03],\n",
       "           [-5.4839e-03,  2.4145e-03,  5.2212e-03],\n",
       "           [-1.8716e-03,  6.8710e-03, -2.1443e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.1113e-03, -1.0158e-02, -3.9873e-03],\n",
       "           [ 3.1007e-03,  1.4062e-03,  4.3003e-03],\n",
       "           [-3.8351e-04, -9.2324e-03,  5.4608e-03]],\n",
       " \n",
       "          [[-5.1287e-03,  3.4609e-03,  3.5581e-03],\n",
       "           [ 4.7648e-03, -2.7972e-03, -4.6797e-03],\n",
       "           [-1.1349e-03, -7.8206e-03, -8.4894e-04]],\n",
       " \n",
       "          [[ 3.2019e-03,  1.8670e-03, -3.1464e-03],\n",
       "           [-2.4111e-03, -3.5681e-03, -8.7572e-03],\n",
       "           [-4.0071e-03, -3.7382e-03,  8.0424e-04]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-8.3656e-03,  5.8378e-03, -5.6082e-03],\n",
       "           [-7.3888e-03, -3.3719e-03,  3.8048e-03],\n",
       "           [-6.9825e-04,  8.6973e-03, -9.6500e-03]],\n",
       " \n",
       "          [[ 1.2771e-04, -1.6054e-03, -4.3213e-04],\n",
       "           [-7.6257e-05, -7.4272e-03, -2.0892e-03],\n",
       "           [ 6.2129e-03,  5.9398e-03, -9.2336e-04]],\n",
       " \n",
       "          [[-3.8851e-03,  4.1702e-03,  1.6186e-03],\n",
       "           [-5.7336e-03, -2.9786e-03,  4.3081e-03],\n",
       "           [ 9.9837e-03,  7.1626e-06, -3.9031e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.7450e-03, -4.2589e-04,  2.4409e-03],\n",
       "           [ 9.4858e-03, -6.6682e-04,  3.8996e-03],\n",
       "           [-3.3373e-03, -1.8207e-03, -8.4106e-03]],\n",
       " \n",
       "          [[ 5.4466e-03, -2.6645e-03,  5.1147e-03],\n",
       "           [-1.6310e-04,  4.3740e-03,  1.4156e-03],\n",
       "           [-7.6721e-03, -2.9057e-03, -3.9104e-03]],\n",
       " \n",
       "          [[ 8.4619e-03, -8.2051e-03,  1.1107e-03],\n",
       "           [ 8.3010e-04,  8.0633e-03,  1.4759e-03],\n",
       "           [-1.8993e-03, -6.0633e-03, -5.3163e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.7510e-03, -6.5413e-03, -1.2247e-02],\n",
       "           [ 9.7508e-03,  5.9199e-03, -9.1617e-04],\n",
       "           [ 7.8764e-03, -1.0659e-02, -2.9079e-04]],\n",
       " \n",
       "          [[ 9.7136e-04, -6.8147e-03,  6.5908e-03],\n",
       "           [-1.4206e-02, -8.3798e-03,  1.0265e-02],\n",
       "           [-7.5902e-03, -1.1038e-04,  5.1625e-03]],\n",
       " \n",
       "          [[-2.1144e-03,  4.4908e-03, -3.3532e-03],\n",
       "           [ 6.0344e-03,  1.0433e-02, -1.6986e-03],\n",
       "           [ 4.0531e-03,  6.5828e-03, -2.9180e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.4145e-03,  3.2067e-03, -3.1146e-03],\n",
       "           [-7.3654e-03, -1.7859e-03, -9.3466e-03],\n",
       "           [-8.1250e-03, -1.0006e-02, -1.1502e-02]],\n",
       " \n",
       "          [[-6.5822e-04,  6.3021e-03, -6.3020e-03],\n",
       "           [-1.2976e-02,  1.1190e-03, -8.7722e-04],\n",
       "           [-8.3745e-03,  2.3548e-03, -1.7536e-03]],\n",
       " \n",
       "          [[-2.4817e-03,  9.8123e-03, -1.2590e-02],\n",
       "           [ 4.1598e-03, -5.2397e-04,  8.8801e-03],\n",
       "           [ 1.0882e-03, -3.2434e-03, -9.5275e-03]]],\n",
       " \n",
       " \n",
       "         [[[-1.2047e-03,  5.0622e-03,  2.4576e-03],\n",
       "           [ 3.1533e-03,  6.2291e-03,  2.5108e-03],\n",
       "           [-4.5722e-03,  2.0591e-03,  5.5368e-03]],\n",
       " \n",
       "          [[-3.1318e-03, -1.2783e-03,  8.0600e-03],\n",
       "           [ 9.3441e-03, -4.2964e-03,  5.0371e-03],\n",
       "           [-3.8823e-03, -1.6415e-03,  2.9071e-03]],\n",
       " \n",
       "          [[-1.3251e-02,  5.9119e-03,  1.1686e-03],\n",
       "           [ 1.9618e-03,  3.8847e-04, -1.2296e-03],\n",
       "           [ 5.6599e-04,  6.5159e-03,  6.4155e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.0421e-03,  5.2797e-03, -9.5681e-03],\n",
       "           [ 8.5426e-03,  3.4162e-03, -7.4648e-03],\n",
       "           [-7.3839e-03,  3.8231e-03, -6.5554e-03]],\n",
       " \n",
       "          [[ 5.6319e-04,  8.2758e-04, -1.4408e-03],\n",
       "           [-9.4458e-03,  1.2005e-03, -1.0060e-02],\n",
       "           [-7.2351e-03, -3.8117e-03,  3.2301e-03]],\n",
       " \n",
       "          [[-5.7312e-03, -1.9037e-03,  5.1498e-03],\n",
       "           [-6.1085e-03,  1.0853e-02, -1.1257e-03],\n",
       "           [ 9.1606e-03,  6.2107e-03, -2.1955e-03]]]], device='cuda:0'),\n",
       " 'vgg.12.bias': tensor([ 8.1239e-04, -7.0901e-03, -2.2167e-04,  2.0527e-03,  7.1641e-03,\n",
       "         -9.6688e-03, -4.7479e-03,  1.1799e-02, -1.1511e-03, -6.9543e-03,\n",
       "          2.5306e-03, -3.1008e-03,  4.0695e-04, -2.1818e-03,  2.5552e-03,\n",
       "          6.9625e-03,  2.2003e-03,  2.8930e-04, -5.4120e-03,  2.0510e-03,\n",
       "          5.2225e-03,  1.5009e-03, -7.2736e-03,  6.1330e-03, -1.7876e-03,\n",
       "          2.1900e-03, -6.9551e-04,  6.5523e-03, -1.0129e-02,  3.9671e-03,\n",
       "         -2.8656e-03,  7.1444e-03, -7.4336e-03, -2.0518e-03,  2.6028e-03,\n",
       "         -8.5210e-03, -5.1416e-04,  7.6869e-03, -4.5129e-03,  8.7968e-03,\n",
       "         -8.2909e-03,  5.0428e-03,  6.0772e-03,  8.8757e-03, -3.1027e-03,\n",
       "         -1.0806e-02, -2.6206e-03,  7.3505e-03,  9.1005e-03,  4.9111e-03,\n",
       "         -2.2070e-03, -5.0937e-03,  5.6795e-03,  9.4584e-04, -4.6014e-03,\n",
       "          2.7482e-03,  7.1017e-03, -9.9875e-03, -5.6528e-04,  1.7629e-03,\n",
       "         -6.4490e-03, -9.8469e-03,  2.8938e-03, -3.3723e-03, -2.1640e-04,\n",
       "          2.0533e-03,  1.6824e-03,  1.8405e-03, -1.0731e-02,  1.9126e-03,\n",
       "         -5.2717e-04, -2.7857e-03,  2.9886e-03, -2.4487e-03,  4.9028e-04,\n",
       "         -2.3279e-03,  5.4388e-03, -4.0375e-03, -2.0909e-03,  4.6165e-03,\n",
       "         -1.0130e-03,  7.2966e-03, -1.0926e-02,  2.2008e-03, -1.3591e-04,\n",
       "         -1.1885e-03, -3.5069e-03,  5.7945e-03,  7.7016e-03,  4.3098e-03,\n",
       "          1.1296e-03,  4.5019e-03,  6.1145e-03, -6.8904e-03, -2.4959e-04,\n",
       "         -6.5771e-06, -5.3368e-04,  1.6125e-03,  5.3473e-03, -3.9628e-03,\n",
       "         -3.7179e-03,  8.8854e-03, -3.8892e-03,  7.7553e-03, -7.1674e-03,\n",
       "          3.9639e-03, -3.8767e-03, -3.1400e-03, -2.2794e-03,  5.2312e-03,\n",
       "          1.9806e-03,  6.1620e-03,  5.2135e-03,  7.2330e-03, -5.4969e-03,\n",
       "         -6.2060e-03,  1.8088e-03, -3.1372e-03, -1.7807e-03, -3.2507e-04,\n",
       "          1.7368e-03,  1.6968e-03,  2.4014e-03, -1.0291e-02,  9.7626e-03,\n",
       "          3.8541e-03, -6.1653e-03, -2.7070e-03, -6.8509e-03, -2.6359e-03,\n",
       "          3.7721e-03,  1.0032e-02, -4.1032e-03,  1.0464e-02, -7.3050e-04,\n",
       "          5.2212e-03, -4.9906e-04,  1.0502e-02, -5.4016e-03,  5.0404e-04,\n",
       "          9.3054e-03, -2.2876e-03,  6.3155e-03, -9.3053e-03, -3.0195e-03,\n",
       "          3.4004e-03,  6.2404e-03, -2.3560e-03,  5.3861e-03, -6.0407e-03,\n",
       "          7.6064e-03, -4.7097e-03,  4.9050e-03,  2.0271e-03,  9.3818e-03,\n",
       "         -7.9376e-03, -7.2818e-03, -1.2865e-03, -9.7260e-03, -3.7005e-03,\n",
       "          5.3516e-03,  5.5754e-03, -7.3869e-04, -1.5453e-03,  5.3052e-03,\n",
       "         -3.7689e-03, -6.0612e-03, -6.6010e-03, -1.3856e-02,  5.6363e-04,\n",
       "          9.8182e-04,  6.0685e-03, -8.8199e-03,  6.0356e-03, -9.7333e-03,\n",
       "         -4.6756e-03, -9.9424e-03,  2.6929e-03,  6.9277e-03, -1.5406e-03,\n",
       "          2.7613e-03,  1.0500e-03, -5.9284e-03, -2.3197e-03,  4.2363e-03,\n",
       "         -1.1672e-02, -7.1930e-03, -4.3900e-03, -4.6278e-03,  1.0941e-02,\n",
       "         -1.6379e-03,  1.1712e-03, -1.6778e-03,  3.1449e-03, -5.5836e-03,\n",
       "          1.2674e-02,  2.7186e-03,  3.3299e-03,  2.8429e-03, -6.9013e-03,\n",
       "         -8.5384e-03, -9.5285e-04,  1.0050e-03, -2.7168e-03, -3.8060e-05,\n",
       "          1.2456e-03, -1.5974e-03,  5.6571e-03, -3.9957e-03, -6.0238e-03,\n",
       "          7.3536e-03, -5.6392e-03,  2.3185e-03,  4.5142e-05, -5.1936e-03,\n",
       "          4.3171e-03,  7.1402e-03,  3.1784e-03, -3.1436e-03, -4.9515e-03,\n",
       "         -1.2249e-02, -1.0444e-02, -1.2072e-03, -5.5339e-03, -7.0134e-03,\n",
       "          1.1720e-02, -1.3679e-03, -3.7742e-03, -2.9640e-03,  6.1222e-03,\n",
       "          1.7187e-03, -6.8627e-03, -2.6127e-03, -2.0615e-03,  1.7025e-03,\n",
       "         -4.5128e-05, -9.2831e-03,  7.8729e-03,  4.7491e-03,  3.5430e-03,\n",
       "         -7.6888e-03,  3.9899e-03, -9.0144e-03, -4.2440e-03, -4.2664e-03,\n",
       "         -3.1296e-03,  1.0526e-02,  4.9313e-03,  3.4525e-03, -4.8990e-03,\n",
       "          4.1985e-03,  8.7113e-03, -1.0845e-03,  3.6251e-03, -7.0025e-03,\n",
       "          1.0341e-02], device='cuda:0'),\n",
       " 'vgg.15.weight': tensor([[[[-1.5624e-03,  5.7523e-03, -3.3399e-03],\n",
       "           [-1.4142e-02,  3.9626e-03,  9.6883e-03],\n",
       "           [-3.2771e-03,  1.1188e-02,  8.1783e-03]],\n",
       " \n",
       "          [[-9.1320e-03, -6.5934e-03,  1.0562e-03],\n",
       "           [-4.7454e-03,  2.5111e-03,  4.0523e-03],\n",
       "           [ 1.4016e-03, -6.6720e-04,  8.0064e-04]],\n",
       " \n",
       "          [[ 2.8804e-03, -9.6351e-03,  4.9873e-03],\n",
       "           [-5.0097e-03, -4.8334e-03,  4.8859e-03],\n",
       "           [-2.7161e-03,  8.4779e-03, -3.4165e-05]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.0289e-03, -5.7154e-03,  6.0058e-03],\n",
       "           [ 3.2784e-03,  4.0656e-03,  1.1591e-02],\n",
       "           [-9.1005e-03, -9.2289e-03, -2.5429e-03]],\n",
       " \n",
       "          [[-1.8395e-03, -1.1569e-02,  4.1794e-03],\n",
       "           [-1.1479e-02, -1.0826e-02,  9.2010e-03],\n",
       "           [-1.0098e-05, -7.6145e-03, -3.0327e-03]],\n",
       " \n",
       "          [[-1.6282e-03,  1.1322e-02, -4.9737e-03],\n",
       "           [ 4.8683e-04,  3.6805e-03, -4.9826e-03],\n",
       "           [-2.1018e-03, -1.1558e-03, -2.7309e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 5.9073e-04, -5.0542e-03,  1.8314e-03],\n",
       "           [-1.3735e-03, -6.1645e-03,  4.1424e-03],\n",
       "           [-7.9015e-04, -4.5073e-03, -5.2277e-03]],\n",
       " \n",
       "          [[-4.7419e-03,  5.2575e-03, -9.6363e-03],\n",
       "           [ 4.2765e-03,  3.4970e-03,  1.0676e-03],\n",
       "           [ 6.4227e-03, -4.1820e-03,  9.7802e-04]],\n",
       " \n",
       "          [[-2.5224e-03, -3.5703e-03,  6.3488e-03],\n",
       "           [-4.0618e-03, -9.7193e-03, -6.4915e-03],\n",
       "           [ 3.9333e-03,  1.0750e-02,  3.0290e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.0624e-03, -4.4865e-03, -1.4901e-03],\n",
       "           [-8.6680e-03,  1.0367e-02,  2.6619e-03],\n",
       "           [ 1.3458e-03, -5.4328e-03,  6.2549e-03]],\n",
       " \n",
       "          [[ 2.9518e-03, -4.0619e-03,  3.4009e-03],\n",
       "           [ 4.6385e-05,  4.7228e-03, -1.1870e-02],\n",
       "           [ 2.0623e-03,  7.5005e-04,  2.4059e-03]],\n",
       " \n",
       "          [[ 1.1769e-02, -3.0512e-03, -7.9713e-03],\n",
       "           [-7.4000e-04, -7.1244e-03, -1.7743e-03],\n",
       "           [-3.0598e-03, -2.4096e-03, -3.1616e-04]]],\n",
       " \n",
       " \n",
       "         [[[-3.3488e-04, -3.4513e-05,  1.0623e-03],\n",
       "           [ 5.7795e-03,  9.8402e-03,  1.0537e-02],\n",
       "           [-9.1732e-03, -2.0090e-03, -5.8984e-03]],\n",
       " \n",
       "          [[-8.3710e-03,  1.0849e-03, -9.2334e-04],\n",
       "           [ 4.0428e-05,  4.6381e-03,  1.9028e-03],\n",
       "           [-3.5552e-03, -4.5648e-03,  9.9481e-03]],\n",
       " \n",
       "          [[-2.8736e-03,  2.1325e-03, -4.3436e-03],\n",
       "           [ 5.2780e-03, -3.3719e-03,  7.0257e-03],\n",
       "           [ 7.2581e-04,  9.1113e-03, -2.0718e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.0932e-03,  3.4298e-03,  1.0942e-02],\n",
       "           [-3.6883e-03,  1.0024e-02, -5.1818e-03],\n",
       "           [-6.5675e-03,  3.1718e-03, -8.6828e-03]],\n",
       " \n",
       "          [[ 9.4283e-04,  9.2872e-03,  1.2031e-03],\n",
       "           [-1.5724e-03, -6.4765e-03,  4.7750e-03],\n",
       "           [ 4.3222e-03,  1.2074e-03, -8.7904e-03]],\n",
       " \n",
       "          [[-6.2210e-03,  1.9454e-03,  1.1194e-02],\n",
       "           [ 3.2648e-03,  3.3545e-03,  7.4698e-03],\n",
       "           [ 1.1871e-03,  1.2136e-02,  6.5366e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 7.4146e-03, -5.6173e-03,  3.2826e-04],\n",
       "           [ 3.3276e-03,  4.4276e-03,  1.7125e-04],\n",
       "           [-7.8733e-03,  7.7452e-04, -5.8710e-03]],\n",
       " \n",
       "          [[-5.1163e-03, -3.5668e-04,  1.9771e-03],\n",
       "           [ 3.4022e-03,  3.5575e-03,  5.4940e-03],\n",
       "           [-1.3861e-03, -4.7311e-03,  5.6046e-03]],\n",
       " \n",
       "          [[-3.9096e-03, -1.5103e-03,  5.9352e-03],\n",
       "           [-4.7776e-03,  8.5966e-03, -4.2283e-03],\n",
       "           [ 3.1980e-03,  1.8527e-03,  2.2627e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-7.3170e-03, -2.8882e-03, -6.0737e-03],\n",
       "           [ 7.2708e-03,  4.5318e-03, -1.8826e-03],\n",
       "           [ 3.9263e-03, -5.3453e-03,  5.2186e-03]],\n",
       " \n",
       "          [[-5.9306e-03, -4.5616e-03,  5.0852e-03],\n",
       "           [-1.0552e-02,  6.4713e-03,  1.3204e-02],\n",
       "           [-1.3914e-03, -3.3740e-03, -6.6119e-03]],\n",
       " \n",
       "          [[-2.1544e-03, -3.3027e-03, -1.9933e-03],\n",
       "           [ 9.3274e-03,  3.7077e-03,  6.5552e-03],\n",
       "           [-2.9786e-03, -3.9769e-03,  5.3437e-04]]],\n",
       " \n",
       " \n",
       "         [[[ 5.3056e-03, -1.1860e-03,  7.5005e-03],\n",
       "           [-4.3695e-03, -1.8762e-03, -5.0478e-03],\n",
       "           [ 1.1509e-02, -1.3420e-03, -4.5917e-03]],\n",
       " \n",
       "          [[ 8.6428e-04, -5.4391e-05,  3.2408e-03],\n",
       "           [ 2.6463e-03,  1.7134e-04,  4.3584e-03],\n",
       "           [-7.1685e-03, -9.3398e-03, -9.1096e-03]],\n",
       " \n",
       "          [[ 4.3323e-04,  5.3750e-03,  7.3956e-03],\n",
       "           [ 6.3640e-03,  2.6925e-03, -1.4544e-03],\n",
       "           [ 4.3962e-03, -9.6086e-03,  4.9553e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.6898e-04, -6.0555e-03,  7.1311e-03],\n",
       "           [-3.7812e-03,  9.7564e-04,  5.5713e-03],\n",
       "           [-5.0451e-03, -5.3502e-04,  2.1852e-03]],\n",
       " \n",
       "          [[ 2.2697e-03,  7.2487e-03, -2.0872e-03],\n",
       "           [-2.5891e-03, -9.6554e-03, -3.4231e-03],\n",
       "           [-7.1191e-03, -1.1089e-02, -2.6072e-03]],\n",
       " \n",
       "          [[ 5.0352e-03,  6.2014e-03, -1.1130e-02],\n",
       "           [ 3.8177e-03, -6.4525e-03, -3.1532e-03],\n",
       "           [ 3.2664e-03,  6.6028e-03, -6.5052e-03]]],\n",
       " \n",
       " \n",
       "         [[[-5.4912e-03, -2.8329e-04,  6.6227e-03],\n",
       "           [-3.1625e-03,  1.0343e-03,  3.1947e-03],\n",
       "           [ 1.0447e-02,  1.2506e-03, -3.6244e-03]],\n",
       " \n",
       "          [[ 6.5724e-03,  1.0004e-02, -3.4657e-03],\n",
       "           [-6.1268e-03, -5.1210e-03, -5.7746e-03],\n",
       "           [ 1.7002e-03, -8.1794e-03,  2.9208e-03]],\n",
       " \n",
       "          [[-9.1041e-03,  2.1858e-03,  7.5215e-03],\n",
       "           [ 4.0473e-03, -7.5342e-03,  2.4076e-03],\n",
       "           [-9.6631e-03,  6.4281e-03, -4.0823e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.0607e-02,  7.4941e-03,  9.7192e-03],\n",
       "           [-5.9397e-03, -4.2354e-03, -2.1220e-03],\n",
       "           [-8.5979e-03,  1.2761e-03, -6.4836e-03]],\n",
       " \n",
       "          [[ 8.2693e-03,  2.2107e-03,  5.7428e-03],\n",
       "           [ 6.8057e-03,  1.9697e-03,  1.4332e-03],\n",
       "           [-2.7229e-03,  4.3391e-03,  1.3274e-03]],\n",
       " \n",
       "          [[ 1.2789e-03,  9.4094e-04,  5.7440e-03],\n",
       "           [-2.1253e-03, -8.2009e-03, -2.4789e-03],\n",
       "           [-3.4124e-03, -6.2320e-03, -5.4715e-03]]]], device='cuda:0'),\n",
       " 'vgg.15.bias': tensor([-3.0641e-03, -1.6874e-03,  1.1262e-03, -6.5000e-03, -1.5164e-03,\n",
       "         -7.5594e-04,  3.3826e-03, -9.7923e-03,  7.7538e-03,  5.9326e-03,\n",
       "         -8.1265e-03, -5.7027e-03,  8.5828e-03, -1.6595e-04,  3.9171e-03,\n",
       "         -8.6724e-03,  6.5438e-04, -4.5852e-03, -1.0496e-02, -1.7120e-03,\n",
       "         -7.3088e-04,  1.4508e-03,  3.6371e-03, -7.2428e-03, -9.7922e-03,\n",
       "          6.3259e-03, -1.9732e-03, -1.1380e-02, -4.8830e-04, -5.1203e-03,\n",
       "          5.5023e-03,  3.3771e-03,  2.0250e-03,  1.1585e-03,  1.1054e-02,\n",
       "          3.1201e-03, -6.9554e-03,  5.7199e-03,  4.1966e-03,  3.5236e-03,\n",
       "          5.7677e-03,  2.0542e-03, -9.2706e-04, -6.7108e-03,  5.2355e-03,\n",
       "          4.7328e-03,  3.3246e-03,  5.7891e-03, -2.7457e-03, -6.9193e-03,\n",
       "          6.8269e-03, -1.1118e-03, -3.3115e-03,  1.0432e-02, -1.3082e-02,\n",
       "          2.3819e-03,  5.9196e-03, -1.1540e-03,  4.8585e-03, -3.3940e-03,\n",
       "         -3.6920e-03,  4.8142e-03,  1.1535e-02,  3.9699e-03,  6.7511e-03,\n",
       "          5.0402e-03,  7.0217e-03, -5.8901e-03, -2.7940e-03,  7.7733e-03,\n",
       "         -1.5341e-03,  7.2084e-03,  4.2022e-03, -3.7503e-03, -7.9454e-03,\n",
       "         -3.8921e-04,  7.1733e-03,  5.9665e-03, -3.0000e-03,  2.0402e-04,\n",
       "         -6.4078e-03,  2.7933e-03, -7.5127e-03, -6.7630e-03,  5.6378e-03,\n",
       "          3.5564e-03,  7.9707e-03,  1.3360e-03, -1.6735e-03, -7.3268e-04,\n",
       "          1.3561e-02, -9.8624e-03,  8.8397e-03,  1.1906e-02, -3.6562e-03,\n",
       "         -1.8669e-03,  3.9331e-03,  5.5031e-04, -3.9412e-04, -1.0733e-02,\n",
       "          9.4262e-03, -4.3253e-03, -1.0141e-02, -9.1479e-04, -3.1619e-03,\n",
       "         -1.6025e-03,  3.4390e-03,  8.0616e-04, -7.1488e-03,  9.0791e-03,\n",
       "         -4.2247e-04,  1.6265e-03,  3.9754e-03,  1.3036e-02,  3.9801e-03,\n",
       "          6.6876e-03,  1.5640e-03,  1.2342e-03,  5.3309e-03,  4.5809e-03,\n",
       "          1.7767e-03,  8.4660e-04, -2.3091e-03, -3.0845e-03,  2.8014e-03,\n",
       "          9.2826e-03,  8.7154e-03, -4.3258e-03,  1.0011e-03,  4.3167e-03,\n",
       "         -3.6870e-03,  2.8123e-03,  1.0113e-02, -7.4649e-03,  3.3098e-03,\n",
       "         -2.1655e-03, -2.1982e-03,  3.5487e-03,  8.1713e-04, -3.9728e-03,\n",
       "          5.3948e-03,  3.0391e-03,  1.2276e-02,  4.9199e-04,  1.1876e-02,\n",
       "          8.4658e-03,  5.5156e-05, -9.0016e-03, -7.6947e-03,  7.3135e-03,\n",
       "          1.0315e-03,  7.1623e-03, -3.9793e-03,  8.1526e-03,  2.2573e-04,\n",
       "         -8.4755e-03,  1.0475e-02, -4.0133e-03,  1.4205e-03,  3.2695e-03,\n",
       "         -3.1554e-03, -1.0635e-03, -3.8567e-03, -4.0697e-03,  8.3491e-03,\n",
       "         -8.3351e-03,  8.8664e-03, -5.7658e-03, -6.2188e-03,  2.0352e-04,\n",
       "         -2.6730e-05, -6.1425e-04,  5.7661e-03,  1.2821e-03,  1.8887e-03,\n",
       "         -1.5264e-03,  9.0051e-03,  6.3108e-04, -1.0536e-02,  8.5669e-03,\n",
       "         -5.3122e-03,  1.5005e-03, -1.1517e-03, -4.8788e-03,  6.9259e-04,\n",
       "         -1.3285e-03,  4.8947e-05,  1.1249e-03, -9.0559e-03, -7.0651e-03,\n",
       "         -1.3824e-02,  4.4320e-03,  3.1848e-03, -3.6291e-03,  1.8086e-03,\n",
       "         -3.5690e-03,  8.1848e-03, -6.5368e-03,  4.2105e-03, -1.1512e-02,\n",
       "         -3.8887e-03,  9.1376e-03,  8.9034e-03, -4.7804e-03, -7.9324e-03,\n",
       "         -5.4315e-03, -3.8933e-03, -3.3146e-03, -1.6928e-03,  5.6303e-03,\n",
       "          1.1111e-02,  7.7541e-03,  1.8928e-03,  6.1422e-03, -3.0714e-03,\n",
       "          2.4079e-03, -4.2869e-03, -2.5117e-03, -3.8662e-03, -8.1542e-03,\n",
       "          4.5643e-03, -2.2163e-03, -2.6780e-03,  9.0059e-03,  4.7023e-03,\n",
       "         -3.7838e-03, -2.4476e-03,  3.6631e-03, -4.2473e-03,  1.8715e-03,\n",
       "         -2.8314e-04, -5.6918e-03,  8.1624e-03,  1.9431e-03, -4.9846e-03,\n",
       "         -4.1626e-03, -1.5150e-03, -2.8677e-03,  1.8368e-03, -1.9548e-03,\n",
       "         -7.1410e-03, -1.2276e-02, -1.0537e-02, -3.8245e-03,  9.2024e-03,\n",
       "         -1.2695e-02,  3.1741e-03,  6.1703e-04, -2.0824e-03, -6.7859e-03,\n",
       "          4.4712e-03, -9.9091e-03,  9.8450e-03,  9.5744e-03,  2.6409e-03,\n",
       "         -7.3265e-04, -4.8252e-03,  7.4909e-03, -1.0251e-02,  4.9922e-04,\n",
       "         -1.6656e-03,  2.0827e-03,  3.5962e-03,  5.7525e-03,  4.4343e-03,\n",
       "          1.1202e-02, -9.4215e-03, -4.9888e-03, -8.4100e-03, -2.0259e-03,\n",
       "          2.8779e-03, -3.2817e-03, -4.3227e-03, -1.3932e-03,  3.3849e-03,\n",
       "          2.8631e-03,  2.3763e-03,  5.2362e-03,  5.3082e-03, -6.4023e-03,\n",
       "          1.6826e-03, -6.5614e-03,  1.8716e-03, -2.9356e-03, -9.2713e-03,\n",
       "         -1.3302e-03, -2.8176e-04,  1.1983e-02, -9.3958e-03, -2.9372e-03,\n",
       "          1.5643e-03, -4.1086e-03,  1.8652e-03,  7.1055e-03, -5.6556e-03,\n",
       "          5.3753e-04, -5.6791e-03, -1.2962e-02, -8.6513e-03,  1.2650e-02,\n",
       "         -9.7388e-03,  8.9823e-04, -3.9446e-03,  6.2577e-04, -4.0195e-03,\n",
       "         -8.6817e-03,  5.6173e-03,  1.0675e-02,  5.0233e-03,  1.5276e-04,\n",
       "          1.5046e-03, -5.2457e-04,  3.6620e-03,  2.7790e-04, -1.0749e-02,\n",
       "          1.2642e-02,  8.4656e-03, -6.5064e-03, -1.1180e-03, -7.8862e-03,\n",
       "          3.8434e-03, -2.2469e-04,  6.2327e-03,  9.0173e-03, -4.8018e-03,\n",
       "          1.1926e-03, -6.8050e-04, -2.0208e-03, -3.2765e-04,  5.0923e-03,\n",
       "          4.6972e-03,  6.9104e-03, -2.2326e-03,  2.7723e-03, -2.9157e-03,\n",
       "         -8.9005e-06, -6.7038e-03, -8.9313e-03, -2.7038e-03,  1.0640e-02,\n",
       "          1.9804e-03,  1.4190e-03,  3.3284e-03, -4.2483e-04,  4.2414e-04,\n",
       "         -3.1530e-03,  2.4668e-03,  5.1386e-04, -6.7531e-03, -9.6458e-04,\n",
       "         -1.2979e-03,  7.5696e-05,  5.6656e-03,  4.6457e-03,  1.4262e-03,\n",
       "         -1.6413e-03, -5.2104e-03, -1.3983e-03, -9.0334e-03, -1.1416e-02,\n",
       "          1.9154e-03,  7.0994e-04,  1.1095e-03, -8.0667e-03, -9.8209e-04,\n",
       "         -1.7542e-03,  1.3836e-02, -1.0909e-02,  1.6809e-03, -2.4491e-03,\n",
       "         -8.9356e-03, -2.5501e-03,  2.8646e-03, -3.3816e-03, -2.6926e-03,\n",
       "         -6.7741e-03, -8.3700e-03, -7.4855e-03,  8.2226e-03,  2.2246e-03,\n",
       "         -9.3234e-04, -1.2174e-03,  1.1192e-02,  8.1048e-03,  5.4146e-03,\n",
       "         -2.6333e-03, -3.5870e-03, -5.3733e-03,  7.3694e-03,  9.8269e-03,\n",
       "         -7.6642e-03, -6.5628e-04,  2.8890e-03, -7.1146e-03,  1.0110e-03,\n",
       "          8.9199e-05, -9.2718e-03, -5.6505e-04,  5.7708e-03, -6.3931e-03,\n",
       "          2.5189e-03,  9.1905e-04, -3.3305e-03,  7.9202e-03,  1.0596e-04,\n",
       "         -9.8010e-03,  8.3982e-03, -6.5933e-03, -2.0724e-04, -3.5784e-03,\n",
       "          4.3742e-03,  8.5162e-04,  1.3145e-03,  6.1413e-03,  4.4362e-03,\n",
       "          1.3287e-02,  1.1862e-02, -2.2010e-03,  4.1127e-03, -6.4966e-03,\n",
       "          1.1196e-03, -3.6744e-03,  7.6628e-03, -6.4556e-03, -1.1181e-02,\n",
       "          2.4816e-03,  4.2590e-03, -1.4991e-03,  2.6192e-03, -6.9988e-03,\n",
       "         -2.6157e-03, -2.2219e-03,  1.3134e-03, -5.0746e-03, -1.7240e-03,\n",
       "         -9.8354e-03,  1.7594e-03, -1.0551e-02,  4.8660e-03,  2.4138e-03,\n",
       "          1.0906e-03,  4.2331e-03, -3.7125e-03, -1.5397e-03, -3.6277e-03,\n",
       "         -1.6522e-03, -2.3679e-03,  2.2072e-04, -2.2017e-03, -5.1101e-04,\n",
       "         -8.7054e-03,  6.1557e-03,  3.1655e-03, -1.4684e-03,  2.8232e-03,\n",
       "          1.0214e-03,  2.8064e-03,  3.8137e-03, -4.4799e-03, -7.5209e-03,\n",
       "         -4.7836e-03, -8.2458e-03,  5.7546e-04,  4.4245e-03, -9.2887e-03,\n",
       "         -1.4157e-03, -4.1275e-03,  2.0148e-04,  9.0244e-03,  3.2536e-03,\n",
       "          7.3070e-03,  1.2549e-03, -1.2979e-03,  8.8645e-03, -3.2172e-03,\n",
       "          1.7498e-03,  5.4209e-03, -3.2677e-03,  2.1388e-03, -2.0940e-03,\n",
       "         -1.4218e-03, -7.4895e-03,  6.3616e-03,  1.2157e-03, -2.3272e-03,\n",
       "         -1.3648e-02, -7.8207e-04,  3.3915e-03,  2.7006e-03, -3.0348e-03,\n",
       "          7.7551e-03,  6.7948e-03,  4.1733e-04,  1.3179e-02, -4.9474e-03,\n",
       "         -6.2175e-03,  9.8596e-03,  6.3609e-03,  7.9960e-03, -7.3484e-03,\n",
       "          1.0935e-03,  4.6559e-03,  3.3377e-03, -1.3497e-03,  1.2192e-02,\n",
       "          4.4493e-04,  4.0927e-03, -1.6275e-03,  5.8491e-04,  5.5931e-03,\n",
       "         -1.0956e-02, -5.7424e-04], device='cuda:0'),\n",
       " 'vgg.17.weight': tensor([[[[ 1.2623e-03, -5.3952e-03,  7.4469e-03],\n",
       "           [ 2.3535e-03, -2.6902e-03, -1.3091e-03],\n",
       "           [ 6.6426e-03,  1.9540e-03,  4.8123e-03]],\n",
       " \n",
       "          [[-4.4776e-03,  5.2489e-03, -3.5345e-03],\n",
       "           [-4.1899e-03, -4.0046e-03, -5.5166e-03],\n",
       "           [ 4.4218e-03,  4.3242e-03, -4.6850e-03]],\n",
       " \n",
       "          [[ 4.1153e-03, -3.5648e-03, -3.7009e-03],\n",
       "           [-5.5106e-03,  6.5833e-03, -1.2411e-03],\n",
       "           [-9.0279e-04,  3.9097e-03, -8.7184e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.9616e-03, -9.9352e-04, -6.5998e-04],\n",
       "           [-5.5069e-04,  1.5332e-03,  1.6531e-03],\n",
       "           [-4.6379e-05,  3.5028e-03,  9.4508e-05]],\n",
       " \n",
       "          [[-4.4030e-03, -5.2372e-04,  1.0094e-03],\n",
       "           [ 4.6786e-03, -9.6845e-04, -1.8279e-04],\n",
       "           [-1.9671e-03, -6.1949e-03, -2.0666e-03]],\n",
       " \n",
       "          [[-4.6150e-03, -8.9615e-04, -4.1465e-03],\n",
       "           [-1.8891e-03, -2.7770e-03, -5.3371e-03],\n",
       "           [ 9.8733e-04, -4.4522e-03,  1.7754e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.5407e-03, -1.6537e-03, -8.4216e-03],\n",
       "           [-1.4986e-03,  1.4089e-04,  6.8284e-03],\n",
       "           [ 1.5868e-03, -1.2110e-04, -3.7698e-03]],\n",
       " \n",
       "          [[ 9.4438e-04,  3.9355e-04, -8.5473e-04],\n",
       "           [ 2.1622e-03,  2.7908e-03,  1.7897e-03],\n",
       "           [-6.6013e-03, -2.2704e-05,  3.8965e-03]],\n",
       " \n",
       "          [[ 5.8036e-03, -2.1177e-03,  3.6219e-03],\n",
       "           [ 3.1008e-03,  3.5576e-03, -4.7742e-03],\n",
       "           [ 1.6971e-03,  5.9629e-04,  4.8785e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.7906e-04, -1.3842e-03, -1.8704e-03],\n",
       "           [-2.6895e-03,  1.5830e-04,  4.4424e-04],\n",
       "           [-1.7735e-03,  2.4061e-03, -8.5644e-04]],\n",
       " \n",
       "          [[-3.2071e-03,  8.5806e-04,  5.6151e-04],\n",
       "           [ 1.0951e-03, -1.7120e-03, -6.7992e-03],\n",
       "           [ 2.7838e-03,  2.8982e-03, -8.2284e-03]],\n",
       " \n",
       "          [[ 6.2725e-03,  1.1359e-03, -2.8447e-03],\n",
       "           [-4.6532e-03,  2.2993e-03, -5.8987e-03],\n",
       "           [ 5.4159e-03, -3.1142e-03, -5.1308e-03]]],\n",
       " \n",
       " \n",
       "         [[[-4.1198e-03,  1.9230e-03,  8.6964e-04],\n",
       "           [ 1.3959e-03, -4.3047e-03, -2.7915e-03],\n",
       "           [ 4.2219e-03,  4.6265e-03, -1.4143e-03]],\n",
       " \n",
       "          [[-6.2564e-03,  2.2044e-04,  5.5201e-03],\n",
       "           [ 3.0362e-03,  8.2423e-03, -3.4468e-03],\n",
       "           [ 2.3549e-03,  5.1875e-03,  3.6238e-03]],\n",
       " \n",
       "          [[ 3.6062e-04, -5.9838e-03, -1.0890e-03],\n",
       "           [ 9.3415e-04, -2.2420e-05, -6.8287e-03],\n",
       "           [-5.7350e-03, -7.9252e-03,  1.5138e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 5.3523e-03,  5.3503e-03, -1.7249e-03],\n",
       "           [-2.7584e-03, -5.2414e-03,  2.3806e-03],\n",
       "           [-2.2763e-04, -6.6298e-03, -2.0360e-03]],\n",
       " \n",
       "          [[ 3.8923e-03, -4.4783e-03, -4.8123e-05],\n",
       "           [ 1.0318e-03, -4.5873e-04,  6.3945e-03],\n",
       "           [ 4.4588e-03, -4.0289e-03, -1.8965e-04]],\n",
       " \n",
       "          [[ 6.2654e-03, -5.3660e-03,  1.6013e-04],\n",
       "           [-8.1429e-05, -4.0821e-03,  9.1038e-04],\n",
       "           [ 3.4414e-03,  5.3815e-03,  2.2211e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 7.6644e-03,  5.9754e-03,  8.4383e-03],\n",
       "           [ 1.5384e-04,  2.6921e-03,  1.5920e-04],\n",
       "           [-3.3095e-03, -1.0076e-02,  1.9429e-03]],\n",
       " \n",
       "          [[-2.2092e-03, -5.8740e-04,  3.0368e-03],\n",
       "           [ 6.7312e-04, -2.1331e-03,  1.4150e-03],\n",
       "           [-5.8495e-03,  2.3825e-03, -1.1215e-04]],\n",
       " \n",
       "          [[-5.0554e-03,  3.1331e-03, -7.8467e-03],\n",
       "           [ 6.5243e-04,  3.1204e-03, -2.7288e-03],\n",
       "           [ 1.7897e-03,  4.3413e-03, -2.7187e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.8367e-03,  1.1372e-03, -2.6818e-03],\n",
       "           [ 7.8302e-04, -2.1437e-03,  2.9219e-03],\n",
       "           [-5.9388e-04, -4.1751e-03, -1.4559e-03]],\n",
       " \n",
       "          [[ 2.9660e-03,  4.1307e-04, -6.0447e-03],\n",
       "           [ 4.2938e-03,  1.2852e-03,  5.4925e-04],\n",
       "           [-4.5607e-03, -5.2474e-03,  1.4490e-03]],\n",
       " \n",
       "          [[ 8.2814e-03, -8.0712e-03,  7.6232e-03],\n",
       "           [-1.2413e-04,  2.1356e-03, -1.0884e-03],\n",
       "           [-5.4902e-03,  2.0470e-03,  4.3710e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.2023e-03, -1.4152e-03, -2.4145e-03],\n",
       "           [-2.3988e-04,  2.0421e-03, -1.1260e-03],\n",
       "           [-2.1876e-03, -5.3649e-03, -1.4498e-03]],\n",
       " \n",
       "          [[ 4.2071e-03,  8.1191e-03, -5.5788e-03],\n",
       "           [-5.5875e-03,  1.4614e-03, -2.1621e-03],\n",
       "           [-7.2492e-03,  7.0703e-04,  1.1776e-03]],\n",
       " \n",
       "          [[-3.5526e-03, -4.7152e-03,  1.8539e-03],\n",
       "           [ 3.6362e-03, -4.3966e-03, -4.1326e-04],\n",
       "           [ 2.1341e-03, -6.0819e-03,  5.2004e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 5.7759e-04, -5.4576e-03,  6.3217e-03],\n",
       "           [ 3.0261e-03,  2.0024e-03,  7.0665e-04],\n",
       "           [-4.2231e-03, -8.3965e-04, -2.2720e-03]],\n",
       " \n",
       "          [[ 3.6876e-04, -2.3733e-03, -4.9008e-03],\n",
       "           [ 6.5919e-03, -5.2561e-03, -3.8698e-03],\n",
       "           [ 3.9056e-03,  9.0799e-04, -1.7643e-03]],\n",
       " \n",
       "          [[ 4.7609e-03, -1.2370e-04, -5.7971e-03],\n",
       "           [ 3.2659e-03,  2.4637e-03, -3.9555e-03],\n",
       "           [-5.7872e-03, -6.1342e-03, -5.8879e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 7.7916e-04, -3.2194e-03, -6.3907e-03],\n",
       "           [-2.3763e-03, -2.3744e-04,  6.7130e-04],\n",
       "           [ 1.8175e-03,  6.2646e-03,  5.2190e-03]],\n",
       " \n",
       "          [[-3.9082e-04,  7.5561e-03, -7.7300e-03],\n",
       "           [ 4.7725e-03, -1.1911e-03, -2.3546e-03],\n",
       "           [ 7.5153e-03, -7.3178e-03, -4.3399e-03]],\n",
       " \n",
       "          [[-9.1599e-03,  4.8112e-03,  1.6964e-03],\n",
       "           [ 4.5557e-03, -4.5201e-03, -4.9655e-03],\n",
       "           [-1.7742e-03,  2.1038e-03,  5.3451e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-7.7524e-04,  2.2467e-03,  2.6673e-03],\n",
       "           [-3.5311e-03, -3.3425e-03,  5.2920e-03],\n",
       "           [-2.7954e-03,  1.2245e-03,  7.2279e-03]],\n",
       " \n",
       "          [[ 1.6004e-03, -9.2593e-03,  4.6880e-03],\n",
       "           [-1.3379e-03, -2.1507e-03, -3.4313e-03],\n",
       "           [-1.6468e-04,  4.4825e-03,  3.9492e-03]],\n",
       " \n",
       "          [[-2.6585e-03, -1.3671e-03,  2.7934e-03],\n",
       "           [ 3.7529e-03,  3.1650e-03, -4.2255e-03],\n",
       "           [ 7.6029e-05, -1.6713e-03,  1.6670e-03]]]], device='cuda:0'),\n",
       " 'vgg.17.bias': tensor([ 9.9431e-04, -3.6255e-03,  9.0474e-04,  2.3825e-03, -3.2391e-03,\n",
       "          2.7764e-03,  2.9165e-03, -2.6926e-03,  2.2820e-03,  3.6035e-03,\n",
       "         -1.9598e-03, -7.2867e-03,  3.1639e-04, -2.9942e-03,  4.7389e-03,\n",
       "          5.4603e-03, -4.3629e-03, -2.6248e-03, -4.2276e-03, -2.5322e-03,\n",
       "         -6.9083e-04, -7.5139e-03,  3.1391e-03,  2.0196e-03, -3.4985e-03,\n",
       "          2.3167e-03, -3.1181e-03, -4.4688e-04,  2.8106e-05,  4.8143e-04,\n",
       "         -3.0253e-03,  1.7330e-03,  2.8961e-03, -4.9244e-03, -9.7230e-04,\n",
       "          7.8443e-03, -5.0368e-03, -2.9866e-03,  1.8123e-03, -1.3680e-03,\n",
       "         -4.9135e-03,  3.9646e-03,  4.2357e-03, -3.3354e-03, -5.3580e-04,\n",
       "         -3.5096e-03,  4.1758e-03, -2.2426e-03, -1.7439e-03,  3.7433e-03,\n",
       "         -2.4050e-03,  2.6550e-03,  4.4508e-03, -1.0133e-02,  4.3428e-03,\n",
       "         -5.7509e-03, -7.2450e-03, -4.2298e-03,  1.0341e-03, -4.8582e-03,\n",
       "          2.1128e-03, -5.2515e-03, -6.8442e-03,  3.5032e-03,  4.8969e-03,\n",
       "          2.8850e-03, -6.2974e-03, -7.0640e-03,  3.7287e-03,  1.3943e-03,\n",
       "          1.6519e-03, -1.5666e-03,  7.0809e-04,  6.9518e-03, -3.8673e-03,\n",
       "          6.8406e-03, -2.6675e-03, -1.6855e-03, -7.5535e-03,  8.2228e-03,\n",
       "          1.6088e-03,  4.2654e-03, -2.5456e-03,  4.3609e-03, -1.8570e-04,\n",
       "          1.4655e-03, -1.4325e-03,  1.4015e-03, -5.4065e-03,  6.4338e-04,\n",
       "         -2.6448e-03,  5.6551e-03,  6.6102e-04, -2.2088e-03, -5.4847e-04,\n",
       "          3.1524e-03, -3.8006e-03, -2.3393e-03,  1.9253e-03, -6.7566e-03,\n",
       "          2.1093e-03,  8.0411e-03, -1.4967e-03,  7.3812e-03, -2.5821e-03,\n",
       "          3.0173e-03, -6.2754e-03, -1.1173e-03,  1.2109e-03, -2.5187e-03,\n",
       "         -5.1696e-03, -1.1760e-03, -1.6219e-03,  6.2306e-03, -3.5489e-03,\n",
       "          1.9123e-03,  2.0517e-03,  4.5403e-03, -9.4153e-04, -5.2065e-03,\n",
       "          4.7150e-03, -4.3487e-03, -3.7109e-03, -5.0142e-03,  3.4903e-04,\n",
       "         -5.5884e-03, -2.9835e-03,  4.2522e-03,  9.2010e-04, -1.1034e-04,\n",
       "         -6.5715e-03, -7.5636e-03, -2.4704e-03, -1.1008e-03, -6.6917e-03,\n",
       "          7.6062e-03,  2.0379e-03,  2.4520e-04, -5.2753e-03,  6.9883e-03,\n",
       "         -6.9489e-03, -8.4873e-03,  8.9205e-03,  2.9763e-03,  4.5668e-03,\n",
       "         -1.2517e-03, -5.2280e-03, -1.2869e-03,  5.5777e-03,  1.7943e-03,\n",
       "          3.5082e-03, -3.9837e-03, -1.2301e-03,  6.7955e-03, -7.9986e-03,\n",
       "         -5.9377e-03, -2.1898e-04, -4.8878e-03, -8.0982e-03, -2.8640e-03,\n",
       "         -1.5277e-03,  1.9096e-03, -3.0887e-03,  6.1481e-03,  1.0669e-03,\n",
       "         -1.9715e-03, -1.1384e-03, -1.0318e-03,  6.9726e-04, -2.2346e-03,\n",
       "          8.2788e-03,  6.2714e-03, -6.4669e-03,  5.2286e-03, -4.7121e-03,\n",
       "         -3.2351e-03, -4.1345e-03,  1.3651e-03,  7.0800e-04, -6.9378e-03,\n",
       "          2.2094e-03,  6.4928e-03, -6.3015e-03,  7.2173e-03,  2.0603e-03,\n",
       "         -5.6486e-03,  7.6678e-03, -3.2720e-03, -4.2450e-03,  9.8422e-05,\n",
       "         -2.7266e-03, -2.7446e-03, -3.9571e-03, -3.9647e-03, -3.7194e-03,\n",
       "          8.6729e-03, -4.8536e-03, -9.2814e-04,  6.0970e-03, -4.6863e-03,\n",
       "         -2.1743e-03,  4.8701e-04, -5.0771e-03, -4.3700e-03,  1.8904e-04,\n",
       "          5.5521e-03,  3.2376e-04,  2.2494e-04, -2.1889e-03,  4.0931e-03,\n",
       "          2.3359e-03, -7.4678e-04,  2.6087e-03,  2.0795e-05,  2.6863e-04,\n",
       "          1.6135e-03, -2.5755e-03, -1.5571e-03,  3.5897e-03, -1.1818e-03,\n",
       "          8.8204e-05, -6.1120e-03,  7.8345e-04, -7.3275e-03,  1.1097e-04,\n",
       "         -2.8710e-03,  3.6749e-04,  9.6675e-04, -3.0978e-03,  3.9919e-03,\n",
       "         -4.2742e-03, -6.6915e-04, -7.9774e-03,  9.8465e-04,  6.3180e-03,\n",
       "          4.0094e-03, -1.9362e-04, -6.6890e-04, -3.4064e-03,  5.2764e-03,\n",
       "         -2.3374e-03, -7.9600e-03,  3.4943e-03, -7.4167e-03, -5.1157e-03,\n",
       "         -2.2550e-03,  5.2235e-03,  8.6102e-03, -6.3123e-04,  8.2206e-03,\n",
       "          6.2466e-04, -3.9027e-03,  4.5436e-03, -3.3607e-04,  1.8866e-03,\n",
       "          2.5475e-03, -7.0074e-03,  1.7759e-04, -5.0073e-03,  1.0322e-03,\n",
       "          3.4849e-03,  2.3040e-03, -1.1198e-03, -6.9123e-04, -5.8994e-03,\n",
       "          9.4516e-04,  4.2518e-03,  1.6541e-03,  4.1693e-03, -4.9091e-03,\n",
       "         -2.3156e-03,  3.2428e-03,  2.3109e-03,  4.4165e-03,  6.0224e-03,\n",
       "          4.5391e-03, -5.6292e-03,  1.1618e-03,  4.3634e-03,  8.4239e-05,\n",
       "          1.4611e-04, -1.7120e-03,  3.7847e-04,  5.6896e-03,  1.0330e-03,\n",
       "          3.9485e-03, -5.9966e-03,  6.1295e-03, -2.1976e-03, -4.4752e-03,\n",
       "         -2.9604e-03, -4.1028e-03, -4.6416e-03, -7.5425e-03, -1.7814e-03,\n",
       "         -2.4125e-03, -4.1173e-03, -7.0795e-03,  7.1661e-03,  2.5044e-03,\n",
       "         -2.1123e-03, -1.7446e-03,  2.3415e-04,  9.4536e-03, -1.4480e-03,\n",
       "          4.8431e-03, -3.5222e-04, -4.8689e-03,  4.9230e-03, -7.9795e-03,\n",
       "          5.1331e-03, -1.1652e-03, -3.7472e-03,  1.0580e-03, -3.8726e-03,\n",
       "         -3.6122e-03, -4.0099e-03, -4.8452e-03, -4.3887e-03, -5.1636e-03,\n",
       "          9.6574e-04, -1.5923e-03, -3.1525e-03,  1.8068e-03, -2.9644e-03,\n",
       "          1.6177e-03,  1.0815e-03,  2.4147e-03, -7.7031e-03, -2.3417e-03,\n",
       "         -3.0327e-03, -2.2984e-03,  5.7216e-03, -3.4107e-04,  6.0371e-03,\n",
       "         -6.9572e-04, -2.7725e-03, -5.1870e-03, -3.7173e-03, -4.3594e-03,\n",
       "         -5.0242e-03,  7.6494e-03,  6.4585e-03,  3.3532e-03, -4.6558e-03,\n",
       "          2.2757e-03,  2.8224e-03,  1.0869e-03, -2.8627e-03,  2.9051e-03,\n",
       "         -4.1835e-03,  8.9287e-04,  1.7509e-03,  2.7368e-03,  9.1634e-04,\n",
       "          8.7029e-04,  2.2429e-03, -4.8417e-03,  4.8152e-03, -6.5898e-03,\n",
       "         -1.4689e-03, -1.4665e-04,  3.4781e-03,  2.0738e-03, -2.7930e-03,\n",
       "          2.6190e-04, -3.6321e-03,  3.5326e-03, -3.1643e-03, -4.8772e-03,\n",
       "         -6.2707e-03, -1.3104e-03, -6.6562e-03, -6.9539e-04,  5.2209e-03,\n",
       "          6.5594e-03, -1.9056e-03,  2.9095e-03, -1.6204e-04, -3.8190e-03,\n",
       "         -5.3922e-03,  1.4680e-03,  4.1773e-03, -2.3004e-03,  1.2640e-03,\n",
       "         -7.0524e-04,  2.4081e-03, -4.8366e-03, -3.1733e-03,  3.5904e-03,\n",
       "         -3.0485e-03, -4.5136e-03, -2.2478e-03,  5.9442e-03, -3.9337e-03,\n",
       "         -5.1271e-03,  1.0579e-03, -5.0807e-04,  3.9568e-03,  3.4453e-03,\n",
       "          3.9786e-03, -2.2282e-03, -2.0493e-03,  6.3467e-03,  8.1058e-04,\n",
       "          1.8746e-03, -4.8345e-03, -2.2566e-03, -2.0965e-04, -4.8770e-03,\n",
       "          6.8860e-03,  5.2792e-03,  7.8200e-03, -1.0877e-03,  3.6922e-03,\n",
       "         -2.5601e-03,  6.9307e-03, -4.5830e-03,  2.0831e-03,  5.4702e-03,\n",
       "          1.2558e-03, -5.7835e-03, -3.4397e-04,  3.9917e-04,  5.2956e-03,\n",
       "          2.7783e-03,  2.9312e-03,  5.0882e-03,  2.3284e-04, -1.0324e-03,\n",
       "          1.8711e-03, -4.1347e-03,  6.2246e-03,  3.7542e-03, -5.5583e-03,\n",
       "          1.9063e-03,  2.2522e-03, -5.6833e-03, -6.6809e-03, -2.7577e-03,\n",
       "         -5.9676e-03,  1.3730e-03, -2.0330e-04,  1.8456e-04,  6.0921e-03,\n",
       "         -2.7472e-03,  2.4899e-03,  4.0629e-04,  3.3967e-03, -5.5219e-04,\n",
       "          5.5086e-03,  6.6883e-03, -1.9591e-03,  1.3081e-03, -4.6587e-03,\n",
       "          5.0888e-03,  3.5128e-03, -2.1734e-03,  6.1127e-03, -4.9824e-03,\n",
       "          8.5897e-03,  9.2122e-03, -1.4565e-03,  2.9054e-03, -1.7808e-04,\n",
       "         -7.5676e-03,  3.2882e-03,  8.6213e-03,  1.5510e-04,  2.5268e-04,\n",
       "         -3.5024e-04,  4.1316e-03,  8.7838e-03,  8.2212e-03,  5.0308e-03,\n",
       "         -4.3253e-04, -1.9831e-03, -6.2530e-03,  1.0767e-03,  9.5499e-03,\n",
       "          1.2126e-03, -3.8218e-03, -4.5053e-03,  3.8669e-03,  2.0910e-03,\n",
       "          2.4109e-03, -2.7469e-03,  8.0635e-04, -4.8568e-03, -7.8889e-03,\n",
       "          2.2208e-03,  3.0920e-03,  8.2821e-05, -1.9855e-03, -7.7417e-06,\n",
       "          1.3757e-03,  7.0079e-03, -2.6944e-03, -2.9572e-03, -2.1427e-03,\n",
       "          2.6569e-03, -3.1975e-03, -2.5112e-03,  3.7616e-03,  4.2593e-03,\n",
       "         -1.1153e-03, -2.6821e-03, -2.5351e-03,  9.9221e-04, -3.5402e-04,\n",
       "         -7.2095e-04,  8.0411e-03], device='cuda:0'),\n",
       " 'vgg.20.weight': tensor([[[[-2.8120e-03, -1.1093e-03,  5.9314e-03],\n",
       "           [-4.1529e-03,  5.6830e-03, -7.1230e-04],\n",
       "           [ 4.9207e-03,  4.4088e-04, -2.2885e-03]],\n",
       " \n",
       "          [[ 5.5884e-03,  4.9816e-03, -6.3697e-03],\n",
       "           [ 6.2876e-03,  4.0860e-03,  6.8885e-05],\n",
       "           [ 3.5855e-03, -2.1289e-03, -4.8134e-03]],\n",
       " \n",
       "          [[-5.0189e-03,  6.4042e-03,  9.8612e-05],\n",
       "           [-1.6230e-03, -6.6877e-05, -5.3996e-03],\n",
       "           [ 6.1212e-04,  4.2362e-03,  8.0635e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.7677e-03, -4.0739e-03,  7.4500e-04],\n",
       "           [ 1.8583e-03,  4.3977e-03,  7.0445e-03],\n",
       "           [-4.8851e-03, -2.8590e-03, -6.0879e-04]],\n",
       " \n",
       "          [[ 4.0152e-03, -7.0301e-03,  3.3880e-03],\n",
       "           [ 3.4923e-03,  1.3799e-03, -5.0246e-03],\n",
       "           [ 4.1546e-03, -2.5760e-03,  1.8041e-03]],\n",
       " \n",
       "          [[-1.0075e-03, -7.0948e-03,  4.8038e-03],\n",
       "           [ 1.2157e-03, -6.5266e-03, -3.8011e-03],\n",
       "           [ 2.5320e-03, -1.2998e-03,  2.4437e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 2.7507e-03,  6.1304e-03,  5.4487e-03],\n",
       "           [-9.1180e-03, -8.5130e-04,  1.9382e-03],\n",
       "           [ 7.3830e-03, -2.4598e-03, -1.8041e-03]],\n",
       " \n",
       "          [[ 3.9383e-03,  1.9247e-03,  3.2356e-03],\n",
       "           [ 5.3412e-03,  2.9924e-03, -2.9584e-03],\n",
       "           [-2.0126e-03,  4.3216e-04, -1.9065e-03]],\n",
       " \n",
       "          [[ 1.3355e-03, -2.7885e-03,  8.6024e-03],\n",
       "           [ 3.4597e-03, -6.3643e-03,  8.1084e-03],\n",
       "           [-2.1619e-03,  6.3041e-03,  2.2565e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.3304e-03, -9.1668e-04,  5.6338e-03],\n",
       "           [ 2.6685e-03, -2.0384e-03,  5.0448e-03],\n",
       "           [ 3.1613e-03,  7.7547e-03, -2.4237e-03]],\n",
       " \n",
       "          [[-2.8632e-03,  2.1715e-03, -2.6705e-03],\n",
       "           [ 2.1104e-03,  2.9592e-05, -4.5289e-03],\n",
       "           [-1.4740e-03,  2.2397e-03, -7.0038e-03]],\n",
       " \n",
       "          [[ 1.1492e-03, -1.2195e-03,  4.9674e-04],\n",
       "           [-5.2011e-03,  9.6015e-03,  7.5745e-03],\n",
       "           [ 1.4511e-03,  2.9059e-03,  1.5372e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.1259e-04,  2.9313e-03, -4.9519e-04],\n",
       "           [-8.1641e-03,  2.0082e-03,  1.2489e-03],\n",
       "           [ 3.3986e-03,  7.8863e-03,  4.3632e-03]],\n",
       " \n",
       "          [[-4.7137e-03, -9.4122e-03, -5.3205e-04],\n",
       "           [-8.3105e-03, -7.9229e-04,  6.6652e-04],\n",
       "           [ 3.7539e-03, -4.6557e-03,  4.3778e-03]],\n",
       " \n",
       "          [[-6.5204e-03, -7.3481e-03, -5.6365e-03],\n",
       "           [ 5.3233e-03, -3.5551e-03, -2.2337e-03],\n",
       "           [-4.4162e-03,  2.0545e-03, -1.7207e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.6157e-03, -9.3164e-03,  3.4884e-03],\n",
       "           [-4.4935e-03,  1.8733e-03, -2.3451e-03],\n",
       "           [-1.8716e-03, -2.4109e-03, -2.8826e-03]],\n",
       " \n",
       "          [[-6.0738e-03,  3.6802e-03, -1.3328e-03],\n",
       "           [-1.8382e-03,  4.1071e-03, -4.7409e-03],\n",
       "           [-1.3147e-03,  8.0287e-03,  2.8397e-03]],\n",
       " \n",
       "          [[-3.4173e-03,  4.4750e-03, -1.9093e-03],\n",
       "           [ 6.0366e-04,  1.8673e-03,  1.1462e-03],\n",
       "           [-4.0039e-04, -1.3101e-03,  5.3757e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-8.3750e-03,  6.0557e-03, -7.2291e-03],\n",
       "           [-2.8176e-03, -2.9833e-03, -6.1053e-03],\n",
       "           [-1.5151e-03, -6.0039e-03, -1.2729e-03]],\n",
       " \n",
       "          [[ 1.4621e-03, -1.4547e-03, -2.4012e-03],\n",
       "           [-3.8377e-03, -4.1093e-03,  1.6000e-03],\n",
       "           [ 4.2585e-03, -7.0742e-03, -3.5008e-03]],\n",
       " \n",
       "          [[-5.3449e-03, -6.2947e-03, -9.0058e-04],\n",
       "           [ 6.2528e-03,  3.0381e-03, -1.2213e-03],\n",
       "           [ 4.5914e-03,  2.2868e-03, -1.3118e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.6223e-04, -3.3653e-05,  4.4064e-03],\n",
       "           [ 5.7486e-03,  2.4508e-03,  8.4428e-04],\n",
       "           [ 2.6919e-03, -3.1166e-03,  5.6332e-04]],\n",
       " \n",
       "          [[ 6.6260e-03, -7.3953e-03,  2.0630e-03],\n",
       "           [ 1.2698e-03, -2.9729e-03, -1.4345e-03],\n",
       "           [-2.7750e-03, -8.7249e-03, -2.8219e-03]],\n",
       " \n",
       "          [[-2.4335e-04,  4.6891e-03, -7.4412e-04],\n",
       "           [ 4.0181e-03,  5.1475e-03,  8.6378e-03],\n",
       "           [-1.4263e-03,  4.7412e-03,  9.5001e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 4.0491e-03, -3.4582e-03,  6.2875e-03],\n",
       "           [ 1.8295e-04, -1.0235e-02, -1.3509e-03],\n",
       "           [ 1.3803e-03,  3.5583e-03,  5.3290e-03]],\n",
       " \n",
       "          [[-4.1728e-03,  3.5981e-03, -7.6738e-03],\n",
       "           [ 8.5279e-03,  4.3137e-03, -4.8762e-03],\n",
       "           [ 7.4543e-04,  6.6280e-04, -7.8279e-04]],\n",
       " \n",
       "          [[ 4.2900e-04,  1.7344e-03,  1.0107e-02],\n",
       "           [-2.2284e-03,  2.8856e-03,  3.4635e-03],\n",
       "           [-3.9498e-03, -1.9188e-03, -2.0217e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-7.0478e-04, -1.5194e-03, -5.0299e-03],\n",
       "           [-6.7355e-03, -5.1724e-03, -2.5973e-03],\n",
       "           [-8.7550e-03, -4.7980e-04,  1.8652e-03]],\n",
       " \n",
       "          [[-1.2804e-03, -1.5452e-03, -8.3094e-03],\n",
       "           [ 2.7930e-03,  1.5667e-03, -1.1813e-03],\n",
       "           [-2.6554e-03, -2.6707e-03, -1.2193e-03]],\n",
       " \n",
       "          [[-1.2553e-03, -1.2922e-05, -2.2633e-03],\n",
       "           [-9.3791e-04, -5.1965e-03, -4.2805e-03],\n",
       "           [ 6.5311e-04,  1.1166e-03, -5.7687e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.9550e-03, -7.0673e-03, -2.4822e-03],\n",
       "           [-2.8314e-03, -2.3716e-04,  7.1978e-03],\n",
       "           [-2.6379e-03,  1.0073e-03, -2.1594e-03]],\n",
       " \n",
       "          [[ 4.3698e-03, -6.5617e-03,  1.9397e-03],\n",
       "           [ 1.3831e-03, -4.1295e-03,  5.6178e-03],\n",
       "           [-6.8551e-03,  5.9199e-03, -5.6949e-03]],\n",
       " \n",
       "          [[-1.5228e-03, -2.5291e-03,  1.5895e-03],\n",
       "           [-3.3866e-03,  2.6223e-03,  2.7194e-03],\n",
       "           [-2.8958e-03,  8.7480e-04,  1.8475e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.5115e-03,  6.1710e-03, -3.3258e-03],\n",
       "           [-4.8435e-03, -3.5992e-03,  4.9734e-03],\n",
       "           [-1.7768e-03, -4.9580e-03,  4.0849e-03]],\n",
       " \n",
       "          [[ 1.5898e-03, -2.7238e-03, -4.8662e-03],\n",
       "           [ 5.5002e-03, -3.8419e-03,  5.6648e-03],\n",
       "           [ 9.1600e-04,  2.9946e-03, -1.0659e-04]],\n",
       " \n",
       "          [[-1.2593e-03,  5.0163e-03,  7.1571e-04],\n",
       "           [ 3.7522e-03, -3.3741e-03,  4.7844e-03],\n",
       "           [ 5.1179e-03, -1.8999e-03,  5.2803e-03]]]], device='cuda:0'),\n",
       " 'vgg.20.bias': tensor([-4.7574e-04, -2.8124e-03, -6.1697e-03,  2.3715e-04,  3.4171e-03,\n",
       "         -5.5822e-04, -4.3341e-03, -1.7797e-03, -1.0751e-03,  8.0486e-03,\n",
       "          4.5712e-03, -5.5509e-03,  6.7666e-04,  1.6594e-03,  1.5554e-04,\n",
       "          5.4084e-03,  4.5359e-03,  2.4613e-03,  8.1975e-03, -1.4217e-03,\n",
       "         -7.5627e-03,  3.4009e-03,  1.8572e-03, -3.7461e-03, -3.5014e-04,\n",
       "         -6.2185e-03, -1.9075e-04,  5.5803e-03, -5.8628e-04,  8.1139e-03,\n",
       "         -3.1961e-04, -7.6294e-04,  3.1301e-03, -2.1815e-03,  4.2096e-03,\n",
       "         -3.1418e-03, -1.3124e-03,  4.3230e-03, -5.3727e-03,  3.7743e-03,\n",
       "          3.2709e-03,  3.7006e-03, -1.3548e-04,  5.2467e-03,  3.0848e-03,\n",
       "         -4.9783e-03, -4.0870e-03,  2.5092e-04,  1.3521e-03, -4.7011e-03,\n",
       "          8.1352e-03,  7.3939e-04, -2.8108e-03, -3.4266e-03,  1.9595e-03,\n",
       "         -3.0612e-03, -4.2344e-04, -8.3727e-03,  6.2818e-04,  2.2818e-03,\n",
       "         -5.1116e-03,  7.6306e-03,  3.4504e-03,  9.3569e-04, -1.2370e-03,\n",
       "          3.7158e-03, -2.6172e-03,  1.0577e-03,  5.2057e-03, -3.9532e-03,\n",
       "          1.1609e-03, -5.9603e-03,  1.0936e-03,  2.6302e-03,  3.5165e-03,\n",
       "          3.2798e-04,  8.1506e-04, -2.4535e-03, -2.5138e-03,  3.5392e-04,\n",
       "          4.3653e-03,  3.0824e-05,  1.4374e-03,  8.3738e-03, -2.2007e-03,\n",
       "          3.1782e-03, -2.7594e-03,  4.9181e-03, -3.1863e-03, -6.3779e-03,\n",
       "          7.4348e-03, -3.0936e-03,  2.9031e-03,  2.3954e-03,  1.5745e-03,\n",
       "          2.8004e-03,  8.2144e-03,  2.8900e-03, -5.1860e-03,  5.0167e-03,\n",
       "          1.5628e-03,  7.3652e-04,  7.5179e-04, -1.6840e-03, -5.8081e-03,\n",
       "          5.8713e-04,  4.1998e-03, -3.5484e-03, -2.2199e-03,  2.1689e-03,\n",
       "          5.7271e-03,  4.7707e-03,  7.3463e-03,  5.6105e-03, -1.0476e-03,\n",
       "         -3.4280e-03,  9.8980e-04, -4.8023e-03, -5.7302e-03, -7.5326e-03,\n",
       "          5.8204e-03,  5.4346e-03, -3.3001e-03, -7.5172e-03, -2.9492e-03,\n",
       "          2.4176e-03,  4.5487e-03, -1.5691e-04,  3.7868e-03,  3.4777e-03,\n",
       "          5.9081e-03,  3.3581e-04,  7.8903e-04,  7.2638e-04,  3.9108e-03,\n",
       "         -1.4977e-03, -2.2519e-03, -1.8118e-03, -6.9531e-03, -1.8138e-03,\n",
       "          3.2260e-03, -1.0678e-03,  3.8174e-03,  3.6558e-03, -2.0545e-03,\n",
       "         -1.6452e-06,  2.9452e-03, -1.6614e-03, -3.3229e-03, -9.8821e-04,\n",
       "         -3.6949e-03, -8.2859e-03,  2.2355e-03, -5.2398e-03,  2.5062e-03,\n",
       "         -1.9539e-03,  2.9166e-03,  7.3579e-03, -5.0960e-03,  4.1789e-03,\n",
       "          4.9613e-03,  2.8624e-03,  3.9574e-03, -5.8417e-03,  5.0730e-03,\n",
       "          2.1994e-03, -5.9196e-03,  3.8251e-03,  2.9749e-03,  1.6149e-03,\n",
       "          7.4881e-03,  1.9108e-03,  5.4986e-03,  6.7603e-04,  4.0241e-04,\n",
       "          2.6650e-03,  2.2027e-03,  4.2179e-03, -2.9827e-03,  9.7314e-03,\n",
       "         -8.7024e-04, -4.2177e-03, -1.7374e-03,  4.2175e-03,  1.6297e-03,\n",
       "         -1.1440e-03,  6.8317e-03,  6.3364e-03,  2.4124e-03, -6.7188e-04,\n",
       "          1.3128e-03,  1.6404e-03,  1.1779e-03,  2.3663e-03,  4.8853e-03,\n",
       "         -3.2017e-03,  3.2067e-03,  5.2320e-04, -3.2892e-03,  2.1643e-03,\n",
       "         -9.4376e-04, -5.3802e-03, -3.4288e-04,  2.8961e-03,  7.4720e-03,\n",
       "         -3.0894e-05, -7.3121e-03,  1.7721e-03,  7.6537e-03, -1.4983e-03,\n",
       "         -5.6031e-03, -1.2354e-03,  5.7482e-03,  5.0277e-03,  8.4301e-03,\n",
       "         -1.6410e-03, -7.8632e-03,  6.2498e-03,  3.0300e-03, -2.9265e-03,\n",
       "         -4.8194e-03, -2.1430e-03, -3.9696e-03,  5.8998e-03, -5.2752e-03,\n",
       "          6.9807e-03, -1.0822e-03,  5.0702e-03, -1.4688e-03,  4.8607e-03,\n",
       "          3.6967e-03, -5.7598e-03,  8.5664e-03, -2.7746e-03,  1.6350e-03,\n",
       "         -3.9336e-03,  1.5231e-03, -3.3875e-04, -1.6284e-03,  8.1273e-03,\n",
       "         -4.6594e-03, -1.5920e-03,  6.4962e-04,  3.0374e-03, -1.6806e-03,\n",
       "          9.4129e-03,  1.2067e-04, -4.9538e-03,  5.3943e-03,  2.4967e-03,\n",
       "          2.0442e-03, -3.4157e-03, -1.3161e-03, -8.4341e-03,  1.1862e-03,\n",
       "          6.4046e-03, -7.2668e-03, -1.2475e-03,  4.6804e-03, -1.0788e-03,\n",
       "          2.2591e-03,  3.8118e-03,  1.5660e-03, -1.5525e-03,  2.7524e-03,\n",
       "          2.8741e-03,  3.7386e-03,  4.0056e-03,  5.9584e-03, -1.9198e-03,\n",
       "         -6.0857e-03,  5.8996e-03,  5.5906e-03,  1.3128e-03,  6.0059e-04,\n",
       "         -6.4135e-03,  2.1960e-03, -7.1219e-04,  3.2532e-03, -1.1172e-03,\n",
       "         -5.6455e-03,  2.1538e-03, -2.2059e-03, -4.6740e-04, -2.8410e-03,\n",
       "         -2.3924e-03, -1.1823e-04, -4.8009e-03, -8.2415e-04, -3.4712e-03,\n",
       "         -4.8003e-03,  3.2434e-03, -2.5105e-03, -3.7695e-03,  2.8185e-03,\n",
       "          4.1485e-03,  1.7652e-03, -5.1682e-03, -8.0912e-03, -7.3730e-07,\n",
       "          3.3693e-03,  8.0651e-03,  1.7485e-04, -1.4276e-03,  1.4706e-03,\n",
       "          2.6843e-03, -5.5616e-04,  3.5481e-03,  7.8101e-03,  2.4708e-03,\n",
       "         -1.0560e-03, -2.4788e-03, -2.5369e-03,  8.8199e-04,  3.1025e-03,\n",
       "          8.2391e-05, -5.4507e-03, -7.1226e-03,  2.5351e-03,  2.6112e-03,\n",
       "         -1.0579e-03,  8.5037e-04,  3.0194e-03,  5.5955e-04,  9.6161e-03,\n",
       "          1.6354e-03,  3.1285e-03,  2.1997e-04,  1.7141e-03,  7.4370e-03,\n",
       "         -1.7843e-03,  2.5975e-03,  1.0309e-03,  9.2527e-03,  8.2504e-03,\n",
       "          2.4468e-05, -3.6194e-03, -5.2235e-03,  1.6516e-03,  2.3775e-03,\n",
       "         -2.1642e-03, -6.0482e-03,  7.0859e-03,  8.9640e-04, -2.6278e-04,\n",
       "          3.9112e-03,  5.9562e-03, -4.9100e-03,  2.5360e-03, -1.9604e-03,\n",
       "          5.1253e-03, -5.6833e-03,  6.7840e-03,  1.0061e-03,  3.3551e-03,\n",
       "         -4.5812e-03, -2.2791e-03,  2.8129e-04, -4.1746e-03,  6.1549e-04,\n",
       "          6.8235e-03,  8.3761e-03, -4.2843e-03,  3.3118e-03,  6.1644e-04,\n",
       "          5.6834e-03,  3.9563e-03,  1.2764e-04,  2.0312e-03, -1.8616e-03,\n",
       "         -2.0425e-03, -4.0071e-04, -1.8074e-03, -5.5848e-03, -3.6407e-03,\n",
       "         -1.9589e-03,  7.3600e-03,  1.0961e-03,  1.4382e-03,  2.7660e-03,\n",
       "          5.2347e-03, -6.4792e-03,  1.1804e-03,  4.6168e-03, -6.4834e-03,\n",
       "          3.9710e-03,  1.6727e-03, -3.6476e-03, -2.3799e-03, -3.3645e-03,\n",
       "         -2.0334e-03,  6.9348e-03,  7.3914e-05,  3.2459e-03, -2.4034e-03,\n",
       "         -2.1691e-03,  8.5939e-03,  2.6379e-03,  3.4898e-03, -1.7330e-03,\n",
       "         -5.8166e-03, -2.4434e-03, -5.2779e-03, -1.6153e-03,  4.9192e-03,\n",
       "         -4.0170e-03, -1.3392e-05,  3.4388e-03,  1.0230e-03,  1.7710e-03,\n",
       "          3.7950e-03,  1.8977e-03, -7.1282e-03,  2.7279e-03, -5.9137e-03,\n",
       "          2.4589e-03,  7.6958e-04,  2.5364e-04, -2.5312e-03, -9.3445e-03,\n",
       "         -3.3639e-04,  1.4794e-03,  8.5529e-03,  8.0304e-03, -4.4234e-04,\n",
       "         -1.2019e-04,  6.4975e-03,  6.8389e-03,  5.3580e-03,  7.8637e-03,\n",
       "          2.8420e-03,  4.2393e-03, -3.4962e-03, -3.7232e-03, -1.3023e-03,\n",
       "         -2.9068e-03,  3.8545e-03, -3.0597e-03, -5.4259e-03,  2.2019e-03,\n",
       "         -9.0161e-04, -2.1831e-03,  1.7499e-03,  1.7870e-03,  3.7332e-03,\n",
       "         -5.7451e-03,  3.8805e-03,  7.2771e-03,  5.0667e-03, -1.4246e-03,\n",
       "         -6.2752e-03, -8.6180e-04,  3.9644e-03, -6.7964e-03,  4.4302e-03,\n",
       "         -5.5542e-03,  2.6052e-03,  4.8263e-03,  1.9476e-03,  5.4451e-05,\n",
       "          8.4318e-03,  3.1265e-04,  7.0239e-03,  7.9656e-03,  5.8431e-03,\n",
       "          3.3524e-07,  5.5187e-03, -9.2229e-04, -5.0085e-03, -8.7703e-04,\n",
       "         -2.0299e-03,  3.2390e-03, -7.3674e-04, -3.8146e-03, -5.1479e-03,\n",
       "          3.3531e-04,  3.4244e-03, -6.2568e-04, -5.1462e-03,  8.1167e-03,\n",
       "         -6.1579e-03,  3.9695e-03,  5.4543e-03, -4.3395e-03, -1.7117e-04,\n",
       "         -3.3546e-03, -5.2503e-03, -2.0362e-04, -2.9862e-03,  7.3973e-03,\n",
       "         -5.5560e-03,  3.9129e-03, -3.3321e-03, -6.5644e-03, -2.7555e-03,\n",
       "          7.8588e-03,  1.6104e-03,  6.1311e-04, -5.9452e-03,  3.1109e-03,\n",
       "         -1.4313e-03, -6.7496e-03, -4.7583e-04, -4.6192e-03,  7.2082e-03,\n",
       "         -2.6152e-03, -5.9938e-03,  2.2901e-03, -3.4964e-04,  5.6675e-03,\n",
       "          3.7222e-03, -1.5098e-03], device='cuda:0'),\n",
       " 'vgg.22.weight': tensor([[[[-8.3174e-04,  9.4110e-03,  5.7861e-03],\n",
       "           [ 3.6606e-03, -1.3195e-03,  4.6466e-03],\n",
       "           [ 1.2001e-03, -3.0911e-03, -9.5075e-04]],\n",
       " \n",
       "          [[ 5.7889e-03, -4.5388e-03, -5.6099e-04],\n",
       "           [ 7.4297e-03, -3.1145e-03,  3.6840e-03],\n",
       "           [ 2.3873e-03,  1.6811e-03,  2.9722e-03]],\n",
       " \n",
       "          [[ 2.5827e-03, -2.4883e-03,  2.0874e-03],\n",
       "           [-3.9052e-03, -8.9982e-03,  5.3005e-03],\n",
       "           [-1.7420e-03, -1.6753e-04,  8.1774e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.3568e-03,  2.7975e-03, -3.4717e-03],\n",
       "           [ 5.2438e-03, -2.7651e-03, -1.6609e-03],\n",
       "           [-5.4937e-03, -3.1069e-04,  7.6751e-03]],\n",
       " \n",
       "          [[-3.0505e-03, -4.3482e-03,  2.6797e-03],\n",
       "           [-5.7892e-03,  1.0489e-03,  1.8540e-03],\n",
       "           [ 1.8031e-03,  2.3667e-03, -1.3799e-03]],\n",
       " \n",
       "          [[-1.2124e-03,  1.0938e-03, -9.2094e-04],\n",
       "           [ 1.8256e-03, -3.6277e-03,  5.7754e-03],\n",
       "           [ 1.5223e-03,  1.1317e-03, -8.1399e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 5.8059e-03,  1.1311e-04,  2.1526e-03],\n",
       "           [ 3.4462e-03,  5.2115e-03, -2.3057e-03],\n",
       "           [ 7.3144e-03,  4.4541e-03,  1.7194e-03]],\n",
       " \n",
       "          [[ 3.8826e-03,  1.2749e-03, -5.5342e-05],\n",
       "           [-9.9103e-04, -1.5844e-03, -3.0139e-03],\n",
       "           [ 1.3799e-03, -1.9953e-03,  6.0543e-03]],\n",
       " \n",
       "          [[-2.3688e-03,  3.0037e-03,  5.3205e-03],\n",
       "           [ 1.7145e-03,  3.0534e-03,  7.2675e-04],\n",
       "           [ 1.1303e-03, -4.1164e-03,  7.9881e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.2579e-03, -7.2182e-04, -2.8286e-03],\n",
       "           [ 6.9542e-03, -4.1524e-03,  2.0580e-03],\n",
       "           [ 3.6188e-03,  4.5003e-03, -4.4907e-04]],\n",
       " \n",
       "          [[ 7.4334e-03,  5.6103e-03, -6.1973e-03],\n",
       "           [-2.5400e-03,  2.5227e-03, -3.1323e-03],\n",
       "           [ 6.0834e-03, -5.0865e-03, -4.7844e-03]],\n",
       " \n",
       "          [[-3.8376e-03, -1.6334e-03, -3.0723e-03],\n",
       "           [-4.4729e-05, -3.7511e-03, -2.8654e-03],\n",
       "           [ 7.2952e-04, -8.0506e-03, -1.8189e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 4.5883e-03, -2.9372e-03, -3.2679e-04],\n",
       "           [-5.8798e-03, -3.7479e-03, -1.9558e-03],\n",
       "           [ 4.4285e-04, -4.0559e-03, -7.0076e-03]],\n",
       " \n",
       "          [[-4.9140e-03,  2.0059e-03, -6.1883e-03],\n",
       "           [ 1.2992e-03, -1.7316e-03,  1.0993e-03],\n",
       "           [-8.7135e-04,  6.7368e-04, -3.4459e-03]],\n",
       " \n",
       "          [[-4.7490e-04, -1.5973e-03, -5.7602e-03],\n",
       "           [ 4.1262e-03, -1.4618e-03, -6.0716e-03],\n",
       "           [-7.7847e-03,  3.4649e-03, -3.4343e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 5.1355e-03,  1.5610e-03, -2.4912e-04],\n",
       "           [-4.4676e-03, -1.2643e-03, -1.6484e-03],\n",
       "           [-2.4396e-03,  1.8735e-03,  6.8094e-03]],\n",
       " \n",
       "          [[ 4.3593e-03, -4.1751e-04, -6.5109e-03],\n",
       "           [-2.7402e-04, -3.9355e-03, -2.0269e-03],\n",
       "           [-2.1693e-03, -2.7641e-03,  7.2527e-04]],\n",
       " \n",
       "          [[-6.3122e-03,  3.2315e-03,  2.1936e-03],\n",
       "           [-8.0565e-03, -3.8544e-03,  2.6271e-03],\n",
       "           [-2.2882e-03,  9.1563e-03,  3.9459e-04]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-3.0315e-05, -5.9702e-04, -3.8766e-03],\n",
       "           [-3.1651e-03,  5.9554e-03, -9.5261e-03],\n",
       "           [-3.8503e-03, -4.3682e-03, -1.4414e-03]],\n",
       " \n",
       "          [[-1.2508e-03,  5.6128e-03,  2.2946e-03],\n",
       "           [ 1.8223e-03,  1.2944e-03, -4.6206e-03],\n",
       "           [ 4.5038e-03,  6.4978e-03, -5.1495e-03]],\n",
       " \n",
       "          [[ 6.0193e-04, -8.9232e-04, -7.0547e-03],\n",
       "           [ 7.6900e-04,  4.8724e-03,  4.1854e-04],\n",
       "           [-2.7731e-04, -4.4496e-03, -2.9950e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.0022e-03,  2.8474e-03, -1.6848e-03],\n",
       "           [-2.9827e-03, -6.2398e-03, -2.8820e-04],\n",
       "           [ 3.7810e-03, -6.6055e-05, -5.0751e-03]],\n",
       " \n",
       "          [[ 6.8329e-03, -3.3070e-03,  4.1159e-03],\n",
       "           [-3.2951e-03, -5.3281e-04, -9.3980e-03],\n",
       "           [-5.1720e-03,  3.9369e-03, -6.3415e-03]],\n",
       " \n",
       "          [[ 9.3598e-05,  1.6506e-03,  1.9347e-03],\n",
       "           [ 6.4390e-03, -4.4093e-03, -4.9086e-03],\n",
       "           [ 7.1914e-03, -5.1890e-03,  1.5294e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 8.3816e-04,  7.1113e-04, -7.8618e-03],\n",
       "           [ 5.8676e-03, -4.4325e-03, -3.2929e-03],\n",
       "           [ 8.2835e-03,  5.9118e-03, -2.6541e-03]],\n",
       " \n",
       "          [[-6.3753e-03, -7.3510e-03, -3.2128e-03],\n",
       "           [-5.5172e-03, -1.3718e-03, -2.8229e-05],\n",
       "           [ 2.6488e-03,  5.1844e-04,  5.8484e-04]],\n",
       " \n",
       "          [[-3.1966e-03, -1.4594e-05, -7.3780e-04],\n",
       "           [-9.0507e-03,  5.6154e-03, -8.2271e-03],\n",
       "           [ 4.5689e-03,  3.5003e-04,  4.6788e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.5898e-03, -6.1839e-03,  2.7962e-04],\n",
       "           [-3.2101e-03,  3.7391e-03,  8.1196e-03],\n",
       "           [-2.2044e-03,  6.9727e-03,  1.6422e-04]],\n",
       " \n",
       "          [[ 1.5735e-03,  4.8161e-03, -2.4689e-03],\n",
       "           [-7.6793e-03, -4.7719e-03,  7.2255e-03],\n",
       "           [-1.0149e-03,  1.2294e-03, -3.2588e-03]],\n",
       " \n",
       "          [[ 6.2328e-03, -5.9463e-04,  1.6246e-03],\n",
       "           [ 2.9478e-03,  8.8369e-04, -6.5378e-04],\n",
       "           [-6.6032e-04,  3.3093e-03, -4.1689e-04]]],\n",
       " \n",
       " \n",
       "         [[[-7.0885e-03, -5.9391e-03, -3.5328e-04],\n",
       "           [ 8.3560e-03, -4.9519e-03,  6.0791e-03],\n",
       "           [ 1.8169e-04, -9.0261e-04, -1.0186e-03]],\n",
       " \n",
       "          [[ 9.4848e-03, -3.9588e-04,  2.6584e-03],\n",
       "           [-4.0890e-03,  3.5025e-03,  8.8848e-04],\n",
       "           [-8.7541e-04, -4.1841e-03,  2.8700e-03]],\n",
       " \n",
       "          [[ 3.0794e-05,  2.8800e-03, -1.8159e-03],\n",
       "           [-4.9009e-03,  2.3558e-03, -6.2018e-03],\n",
       "           [ 4.1493e-03, -1.8679e-03, -8.6532e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.1023e-03, -2.5608e-03,  2.8607e-03],\n",
       "           [-6.3926e-04, -4.9554e-03,  3.0202e-03],\n",
       "           [-8.0214e-03,  3.2743e-03,  5.1287e-03]],\n",
       " \n",
       "          [[ 5.5605e-03,  1.1303e-03, -3.2527e-03],\n",
       "           [-3.0830e-03,  6.0300e-04, -4.3571e-03],\n",
       "           [-4.3875e-03,  1.9552e-03, -3.4774e-03]],\n",
       " \n",
       "          [[-2.5551e-03,  3.5157e-03, -3.5554e-05],\n",
       "           [-2.0118e-03,  6.6458e-03, -1.7761e-04],\n",
       "           [ 1.1757e-03, -1.7508e-03, -1.0836e-03]]]], device='cuda:0'),\n",
       " 'vgg.22.bias': tensor([-4.2551e-03, -3.8470e-04,  1.4613e-03,  4.1485e-03, -3.6201e-03,\n",
       "         -3.3941e-03, -3.4409e-03, -9.7880e-04, -4.4874e-03,  3.7593e-03,\n",
       "         -5.7978e-03, -5.3897e-04, -1.5461e-03,  8.7919e-04, -4.3127e-04,\n",
       "         -1.0090e-05, -5.3434e-03,  4.0513e-03,  1.9862e-03, -3.4818e-03,\n",
       "         -2.1552e-03,  7.1894e-04, -3.2497e-03,  5.1384e-03, -2.8480e-03,\n",
       "         -2.5810e-03,  2.7163e-03, -3.6871e-03,  1.2902e-03, -5.8055e-03,\n",
       "          1.3957e-03,  6.0491e-03, -3.7219e-03,  1.3596e-03, -3.2869e-03,\n",
       "          1.1841e-03,  2.8653e-03,  3.9838e-03, -3.5556e-04,  6.9012e-03,\n",
       "         -2.7949e-03, -6.4098e-03, -6.4506e-03, -6.4843e-03, -5.4341e-03,\n",
       "         -7.1115e-04,  3.2655e-06,  4.5218e-03, -2.3760e-03, -1.6474e-03,\n",
       "         -2.4017e-03, -2.5235e-03, -4.1361e-03,  1.0251e-03,  3.1765e-03,\n",
       "          1.7799e-03, -2.1906e-03,  6.4536e-03,  3.7736e-04,  3.7293e-03,\n",
       "         -1.9842e-03, -6.6669e-03, -9.2969e-05,  7.6983e-03,  3.8481e-03,\n",
       "          3.0623e-03,  2.5427e-03,  1.9706e-03,  4.6970e-03,  5.7775e-03,\n",
       "          3.9778e-04,  2.9259e-03, -4.2352e-03,  6.7087e-04, -6.5022e-03,\n",
       "          2.3115e-03, -5.7264e-03,  3.9655e-04,  2.7619e-03, -3.6370e-03,\n",
       "          4.6443e-03, -6.8968e-03,  7.1100e-03,  3.2825e-03, -5.2310e-03,\n",
       "          2.4940e-03,  2.9019e-03,  5.6025e-03, -5.2640e-03,  1.4969e-03,\n",
       "         -3.1508e-03, -2.0310e-03,  2.5653e-03, -4.9982e-04,  1.8531e-03,\n",
       "         -4.7965e-03,  6.7245e-03,  9.3671e-04, -6.3743e-03, -4.9899e-03,\n",
       "          3.1547e-03, -3.9338e-03,  3.5302e-03, -1.7947e-03,  1.3670e-03,\n",
       "          3.3398e-03, -9.2104e-04, -6.5810e-04,  7.2437e-04, -5.1810e-03,\n",
       "         -5.0562e-03, -5.3900e-03, -6.1061e-04,  7.1620e-04,  1.5479e-03,\n",
       "         -8.3009e-03, -4.9765e-03, -3.2608e-03,  2.9357e-03,  5.1956e-04,\n",
       "          1.8763e-04, -3.7585e-03,  6.0011e-03,  2.7288e-03, -2.6830e-03,\n",
       "          7.6768e-04,  8.1706e-04,  2.4521e-03, -2.4238e-03,  8.1523e-04,\n",
       "         -2.4125e-03,  3.2811e-03, -1.2844e-03,  4.5409e-03, -5.9874e-03,\n",
       "          2.7035e-03,  9.1079e-04, -2.7801e-04,  2.9010e-04,  1.3311e-03,\n",
       "         -5.6833e-03,  3.6635e-03, -1.8354e-03, -5.6035e-03,  1.5843e-03,\n",
       "          5.1836e-03,  1.7734e-03, -2.0267e-03, -3.3725e-03,  3.8131e-03,\n",
       "          1.4884e-03, -5.3388e-03,  6.2966e-03,  5.3060e-03, -1.7959e-03,\n",
       "         -4.0050e-03, -6.0057e-03,  3.3118e-05, -7.4288e-03,  4.1177e-03,\n",
       "         -2.7252e-03,  7.8209e-03, -5.7962e-03,  3.3042e-04,  1.2110e-03,\n",
       "         -4.0761e-03, -1.4287e-03, -5.6536e-03, -3.0942e-03, -3.7370e-04,\n",
       "         -2.1435e-03,  7.4433e-04, -4.1031e-03, -3.8698e-03,  6.5977e-04,\n",
       "         -5.6731e-03,  2.8032e-03,  1.4758e-03, -3.3666e-04, -1.8992e-03,\n",
       "          1.5036e-03,  2.1295e-03, -6.8415e-04, -9.3758e-04, -2.7350e-03,\n",
       "         -4.8488e-03,  1.0705e-04, -3.4481e-03, -5.2271e-03, -5.0247e-03,\n",
       "          1.1963e-03, -7.5602e-03,  2.0758e-03,  3.8627e-04,  5.3340e-03,\n",
       "          8.4646e-04,  5.3677e-04,  3.2053e-03,  6.7491e-03,  2.3303e-03,\n",
       "          3.3193e-04,  6.0167e-03,  5.2402e-03, -2.8754e-03,  5.1563e-03,\n",
       "          3.4693e-03, -5.8809e-03,  5.2234e-03,  1.8842e-03,  2.1933e-03,\n",
       "         -1.4684e-03, -2.3969e-03, -5.4151e-03, -5.1664e-05,  7.2763e-03,\n",
       "          2.4817e-03,  2.7983e-03,  2.6893e-04,  1.1008e-03, -5.4266e-03,\n",
       "          3.0641e-03, -5.9297e-03, -1.8856e-03,  1.5542e-03,  3.2365e-03,\n",
       "          2.9676e-03, -1.9212e-04, -4.0970e-03,  6.6035e-04, -3.4343e-03,\n",
       "         -2.1414e-03, -4.5937e-04, -3.0632e-03, -2.1633e-03, -4.6268e-04,\n",
       "          1.4230e-03, -4.4011e-03, -1.5981e-03,  2.5479e-03, -4.8510e-03,\n",
       "         -2.3519e-03,  1.9218e-03, -8.8892e-03,  1.3258e-03,  5.5106e-03,\n",
       "          1.0248e-03, -7.1352e-03,  3.9343e-03,  6.5568e-03, -2.3717e-03,\n",
       "          5.1873e-03,  1.7305e-03,  1.8833e-03,  8.1247e-03, -3.4573e-03,\n",
       "         -1.7579e-03, -8.0167e-03, -4.0045e-03, -5.4348e-04, -1.7831e-03,\n",
       "         -3.1191e-03,  9.5924e-04,  2.8665e-04,  2.9782e-03, -6.3336e-04,\n",
       "          2.5237e-04, -1.7905e-03,  1.5424e-03,  2.6401e-03,  5.1329e-03,\n",
       "          6.5915e-03, -7.1164e-03,  4.6359e-03, -5.7755e-05, -4.0267e-03,\n",
       "          9.0716e-04,  1.3996e-03, -3.8082e-03,  6.7608e-04,  6.6150e-03,\n",
       "          5.4597e-03, -7.1158e-03,  3.0099e-03, -1.5604e-03,  6.5599e-03,\n",
       "          2.3844e-03,  5.2509e-03, -3.2422e-03,  3.0571e-04, -1.8802e-03,\n",
       "          6.7330e-03, -5.4946e-03, -5.1503e-03, -7.0538e-03, -4.6764e-03,\n",
       "          5.3643e-03, -4.5406e-03, -1.4783e-03, -1.6638e-03, -6.6687e-03,\n",
       "         -4.5590e-03,  2.8419e-03, -1.4031e-03, -8.6070e-03,  5.0807e-04,\n",
       "          3.7017e-04, -1.4684e-03,  1.4853e-03,  5.2388e-03,  3.1544e-03,\n",
       "         -5.6590e-04, -6.0906e-04, -1.6154e-03, -4.2415e-03, -2.2631e-03,\n",
       "          1.1963e-03, -1.8611e-03,  1.2187e-03,  1.1951e-03,  1.4757e-03,\n",
       "          1.7871e-03,  4.1689e-03,  3.1476e-03,  7.8199e-04,  4.5846e-04,\n",
       "         -4.9463e-04, -1.3108e-04,  3.4645e-03, -4.6859e-03,  4.0947e-03,\n",
       "         -3.4262e-03,  5.0311e-05,  1.6286e-03,  2.3532e-03,  7.7049e-03,\n",
       "         -2.0619e-04,  7.0141e-03,  2.3730e-03,  2.7964e-03, -5.4225e-03,\n",
       "          2.9109e-03, -7.8508e-03,  1.7249e-04, -1.9109e-03, -5.2488e-04,\n",
       "         -1.2605e-03, -2.1055e-03,  6.4816e-03,  1.0284e-03, -7.4285e-03,\n",
       "          8.0101e-05, -2.4035e-03,  1.6240e-03, -1.8595e-03, -4.5886e-03,\n",
       "          4.9551e-03,  4.4770e-03, -4.7185e-03, -5.8196e-03,  5.3658e-03,\n",
       "         -4.9230e-03, -3.9586e-03, -2.1172e-03,  1.2512e-03,  2.6368e-03,\n",
       "         -4.7243e-03,  1.5188e-04,  1.4043e-03, -2.6266e-03, -1.7575e-03,\n",
       "         -5.4061e-03, -2.2004e-03,  2.5718e-03,  5.3085e-03, -3.4983e-03,\n",
       "         -1.5355e-03,  1.6080e-03,  5.3668e-03, -8.1924e-03, -4.8322e-03,\n",
       "          2.1889e-03,  8.0106e-03,  1.2742e-03,  2.2953e-04, -1.4330e-03,\n",
       "         -2.0572e-03,  4.4161e-03, -7.4790e-04, -2.8754e-03, -1.0498e-03,\n",
       "          2.0532e-03, -3.6180e-03,  7.2927e-03, -4.2063e-03,  4.9454e-03,\n",
       "         -9.1830e-04,  6.1961e-05, -1.0178e-03, -1.6634e-03, -1.5185e-03,\n",
       "         -5.0938e-03, -1.3139e-03, -4.8775e-03,  4.2487e-03,  1.6559e-03,\n",
       "          7.6219e-04,  6.0809e-03, -7.0767e-03,  7.8757e-03, -4.3362e-03,\n",
       "         -3.2963e-06,  6.8084e-04,  4.3204e-04, -2.8368e-03,  5.0453e-03,\n",
       "          1.3426e-03,  2.3992e-03, -4.1843e-03,  7.0859e-03,  4.6398e-03,\n",
       "         -8.0377e-03, -7.4751e-03, -3.1364e-03,  4.5244e-04, -6.0758e-03,\n",
       "          1.2084e-03,  7.4521e-03, -3.3031e-03, -2.8657e-03,  7.2306e-03,\n",
       "          2.7120e-03, -1.2589e-03,  2.3513e-03, -1.1223e-03,  2.6523e-03,\n",
       "          6.6113e-03,  6.5205e-03,  5.5917e-03,  3.9765e-03,  4.0932e-03,\n",
       "          1.5048e-04, -4.0964e-03, -6.5109e-03, -4.1992e-03, -7.0446e-03,\n",
       "          6.3739e-03,  3.7299e-03, -5.0205e-03, -4.7269e-03, -2.3173e-04,\n",
       "          5.5861e-03,  7.1977e-03, -7.0154e-03,  2.5314e-03, -6.1806e-03,\n",
       "          1.9468e-03, -1.8057e-03,  2.2958e-03,  1.7775e-03, -3.3107e-03,\n",
       "          4.4451e-03,  1.2542e-03, -1.4378e-03, -3.0461e-03, -8.4629e-03,\n",
       "          4.0023e-03,  3.5698e-03, -1.6837e-03,  7.0631e-03,  4.1855e-04,\n",
       "          8.7093e-03,  7.9728e-03, -4.8177e-03,  1.8778e-03, -3.7766e-03,\n",
       "         -2.2950e-03,  5.4674e-03, -2.9796e-03,  1.6411e-03,  7.3232e-04,\n",
       "          2.0539e-03, -5.5027e-03, -4.4708e-03, -3.9873e-03,  1.9595e-03,\n",
       "          1.3200e-03,  2.4643e-03,  1.8880e-03, -7.8711e-03, -1.6585e-03,\n",
       "          2.1637e-05, -8.5861e-03, -6.3369e-03, -2.9541e-03, -2.8307e-03,\n",
       "         -8.6475e-04,  4.8277e-03,  2.8085e-03, -7.7130e-04,  4.4607e-03,\n",
       "         -6.8752e-03,  3.4508e-03, -1.0724e-03,  4.9959e-03,  2.7851e-03,\n",
       "          4.2065e-03,  1.2158e-03, -3.9522e-03, -2.1684e-03, -9.7223e-04,\n",
       "          7.0042e-04,  4.6053e-03], device='cuda:0'),\n",
       " 'classifier.0.weight': tensor([[ 4.7786e-03, -1.2948e-04,  8.5411e-04,  ..., -6.1317e-04,\n",
       "          -3.1350e-04, -1.9619e-04],\n",
       "         [ 1.1364e-03, -2.9748e-03,  2.3519e-03,  ..., -4.0212e-04,\n",
       "          -7.0539e-05, -2.7005e-03],\n",
       "         [-2.0387e-03,  1.0400e-03, -1.6106e-03,  ...,  3.0395e-04,\n",
       "           1.1525e-03, -3.8164e-04],\n",
       "         ...,\n",
       "         [ 4.0791e-03,  1.0207e-03,  8.5008e-04,  ..., -3.5278e-03,\n",
       "          -1.5948e-03,  1.8492e-03],\n",
       "         [-8.2703e-04, -3.3061e-03, -4.3879e-03,  ..., -3.3644e-03,\n",
       "           2.2607e-03,  8.5137e-04],\n",
       "         [-3.1899e-03, -1.1787e-03,  9.1080e-04,  ...,  4.0991e-04,\n",
       "          -1.1761e-03,  1.7769e-03]], device='cuda:0'),\n",
       " 'classifier.0.bias': tensor([ 2.3676e-05, -1.6284e-03, -3.5833e-03,  ...,  2.9616e-03,\n",
       "          9.7786e-04, -3.3882e-04], device='cuda:0'),\n",
       " 'classifier.3.weight': tensor([[-2.1734e-03, -6.1056e-04,  2.0217e-03,  ...,  7.3630e-03,\n",
       "           7.8946e-03, -4.4019e-04],\n",
       "         [-2.5225e-03, -3.8680e-03, -5.3732e-03,  ...,  1.2826e-03,\n",
       "          -8.5782e-03, -1.0999e-03],\n",
       "         [ 2.5915e-03,  5.7658e-03, -1.6598e-03,  ..., -1.9754e-03,\n",
       "          -2.3690e-04, -2.3077e-03],\n",
       "         ...,\n",
       "         [-2.0987e-03, -3.5216e-03,  5.9354e-05,  ..., -4.0059e-03,\n",
       "           4.1788e-03, -2.9258e-03],\n",
       "         [-1.1153e-03, -6.9904e-03,  9.0505e-03,  ..., -4.9701e-03,\n",
       "           2.9352e-03,  2.3554e-03],\n",
       "         [-6.5952e-03, -1.8753e-03,  6.2147e-04,  ...,  4.0092e-03,\n",
       "          -7.2126e-03, -4.8035e-03]], device='cuda:0'),\n",
       " 'classifier.3.bias': tensor([ 0.0012,  0.0042, -0.0045,  ...,  0.0072,  0.0063, -0.0021],\n",
       "        device='cuda:0'),\n",
       " 'classifier.6.weight': tensor([[ 5.9038e-03,  4.9946e-03,  4.3764e-03,  ..., -5.2083e-04,\n",
       "           2.8542e-03,  2.6922e-03],\n",
       "         [ 6.0783e-03,  3.9203e-05,  1.9640e-03,  ..., -6.8108e-03,\n",
       "           2.2266e-03, -6.0610e-03],\n",
       "         [-2.2923e-04, -6.0170e-03, -5.1048e-03,  ..., -3.7681e-03,\n",
       "           4.2302e-03,  1.4043e-03],\n",
       "         ...,\n",
       "         [-4.8139e-03, -7.2482e-03,  3.2556e-03,  ...,  4.4471e-03,\n",
       "          -9.8447e-03,  3.6326e-03],\n",
       "         [-2.0755e-03, -7.9958e-03,  7.8360e-04,  ..., -3.8638e-04,\n",
       "           3.1960e-03,  3.2735e-03],\n",
       "         [ 3.1316e-03,  6.1663e-03, -4.8336e-03,  ...,  4.6223e-06,\n",
       "           7.6099e-03,  4.7713e-03]], device='cuda:0'),\n",
       " 'classifier.6.bias': tensor([ 0.0041,  0.0079,  0.0040, -0.0016,  0.0042, -0.0037,  0.0035,  0.0003,\n",
       "          0.0090,  0.0039], device='cuda:0')}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg.0.weight\n",
      "vgg.0.bias\n",
      "vgg.2.weight\n",
      "vgg.2.bias\n",
      "vgg.5.weight\n",
      "vgg.5.bias\n",
      "vgg.7.weight\n",
      "vgg.7.bias\n",
      "vgg.10.weight\n",
      "vgg.10.bias\n",
      "vgg.12.weight\n",
      "vgg.12.bias\n",
      "vgg.15.weight\n",
      "vgg.15.bias\n",
      "vgg.17.weight\n",
      "vgg.17.bias\n",
      "vgg.20.weight\n",
      "vgg.20.bias\n",
      "vgg.22.weight\n",
      "vgg.22.bias\n",
      "classifier.0.weight\n",
      "classifier.0.bias\n",
      "classifier.3.weight\n",
      "classifier.3.bias\n",
      "classifier.6.weight\n",
      "classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "for name1, param1 in params:\n",
    "    print(name1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(model, optimizer, criterion, current_epoch, train_loader, device=\"cpu\", print_interval=10):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    \n",
    "    train_correct = 0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        train_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        train_loss+= (loss.item() * len(data))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % print_interval == 0:\n",
    "            print(\n",
    "                'Train Epoch: {} [{}/{} ({:.3f}%)]\\tLoss: {:.7f}'.format(\n",
    "                    current_epoch, batch_idx * len(data), len(train_loader.dataset),100. * batch_idx / len(train_loader), loss.item()\n",
    "                    )\n",
    "                )\n",
    "    ## This is training, so reduction = mean, i.e. loss.item() already gives the mean of the batch\n",
    "    train_loss/=len(train_loader.dataset)\n",
    "    print('Train Set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        train_loss, train_correct, len(train_loader.dataset), 100. * train_correct / len(train_loader.dataset)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in testloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = model(X)\n",
    "        preds.append(np.argmax(y_pred.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.label = pd.Series(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label\n",
       "0    0      3\n",
       "1    1      0\n",
       "2    2      2\n",
       "3    3      6\n",
       "4    4      7\n",
       "5    5      7\n",
       "6    6      1\n",
       "7    7      9\n",
       "8    8      3\n",
       "9    9      4\n",
       "10  10      8\n",
       "11  11      8\n",
       "12  12      1\n",
       "13  13      7\n",
       "14  14      8\n",
       "15  15      1\n",
       "16  16      5\n",
       "17  17      1\n",
       "18  18      5\n",
       "19  19      9\n",
       "20  20      3\n",
       "21  21      7\n",
       "22  22      6\n",
       "23  23      0\n",
       "24  24      2\n",
       "25  25      0\n",
       "26  26      8\n",
       "27  27      7\n",
       "28  28      0\n",
       "29  29      0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.read_csv(\"1submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "label    157\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sub1 != sample_submission).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>190</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>211</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>4845</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4905</th>\n",
       "      <td>4905</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4940</th>\n",
       "      <td>4940</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>4948</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4951</th>\n",
       "      <td>4951</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label\n",
       "93      93      4\n",
       "100    100      5\n",
       "137    137      2\n",
       "190    190      5\n",
       "211    211      5\n",
       "...    ...    ...\n",
       "4845  4845      7\n",
       "4905  4905      6\n",
       "4940  4940      0\n",
       "4948  4948      5\n",
       "4951  4951      7\n",
       "\n",
       "[157 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1[sub1[\"label\"]!=sample_submission[\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX=143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7ffac2f80450>, id       143\n",
       " label      0\n",
       " Name: 143, dtype: int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_images[IDX].reshape(28,28)), sample_submission.iloc[IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0938, Accuracy: 9968/10240 (97%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.09378398158587516, 97.34375)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classifier (model, nn.NLLLoss(reduction=\"sum\"), device,  digloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "skorch.torch_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(dig_mnist_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGGNet(\n",
       "  (vgg): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): ReLU(inplace=True)\n",
       "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): ReLU(inplace=True)\n",
       "    (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (adjustor): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=18432, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "    (7): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    " torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-d25c50fea2d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msumma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'summa' is not defined"
     ]
    }
   ],
   "source": [
    "summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]             640\n",
      "              ReLU-2           [-1, 64, 32, 32]               0\n",
      "            Conv2d-3           [-1, 64, 32, 32]          36,928\n",
      "              ReLU-4           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-5           [-1, 64, 16, 16]               0\n",
      "            Conv2d-6          [-1, 128, 16, 16]          73,856\n",
      "              ReLU-7          [-1, 128, 16, 16]               0\n",
      "            Conv2d-8          [-1, 128, 16, 16]         147,584\n",
      "              ReLU-9          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-10            [-1, 128, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]         295,168\n",
      "             ReLU-12            [-1, 256, 8, 8]               0\n",
      "           Conv2d-13            [-1, 256, 8, 8]         590,080\n",
      "             ReLU-14            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-15            [-1, 256, 4, 4]               0\n",
      "           Conv2d-16            [-1, 512, 4, 4]       1,180,160\n",
      "             ReLU-17            [-1, 512, 4, 4]               0\n",
      "           Conv2d-18            [-1, 512, 4, 4]       2,359,808\n",
      "             ReLU-19            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-20            [-1, 512, 2, 2]               0\n",
      "           Conv2d-21            [-1, 512, 2, 2]       2,359,808\n",
      "             ReLU-22            [-1, 512, 2, 2]               0\n",
      "           Conv2d-23            [-1, 512, 2, 2]       2,359,808\n",
      "             ReLU-24            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-25            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-26            [-1, 512, 6, 6]               0\n",
      "           Linear-27                 [-1, 4096]      75,501,568\n",
      "             ReLU-28                 [-1, 4096]               0\n",
      "          Dropout-29                 [-1, 4096]               0\n",
      "           Linear-30                 [-1, 4096]      16,781,312\n",
      "             ReLU-31                 [-1, 4096]               0\n",
      "          Dropout-32                 [-1, 4096]               0\n",
      "           Linear-33                   [-1, 10]          40,970\n",
      "       LogSoftmax-34                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 101,727,690\n",
      "Trainable params: 101,727,690\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 4.38\n",
      "Params size (MB): 388.06\n",
      "Estimated Total Size (MB): 392.44\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,(1,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalAvgPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x.view(*(x.shape[:-2]),-1).mean(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GlobalAvgPool()\n",
    "gb2 = nn.AvgPool2d(112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"../princess.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "txf = transforms.Compose([transforms.RandomCrop(224),transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = txf(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4064, 0.2739, 0.1479])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2882, 0.5871],\n",
       "         [0.2448, 0.5053]],\n",
       "\n",
       "        [[0.2104, 0.3233],\n",
       "         [0.2347, 0.3271]],\n",
       "\n",
       "        [[0.1793, 0.0547],\n",
       "         [0.1918, 0.1658]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb2(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = transforms.Lambda (lambda image : torch.stack[img, img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "c5 = transforms.FiveCrop(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=200x200 at 0x7F503485AF90>,\n",
       " <PIL.Image.Image image mode=RGB size=200x200 at 0x7F5034698810>,\n",
       " <PIL.Image.Image image mode=RGB size=200x200 at 0x7F5034801B10>,\n",
       " <PIL.Image.Image image mode=RGB size=200x200 at 0x7F502E9AE810>,\n",
       " <PIL.Image.Image image mode=RGB size=200x200 at 0x7F5034801190>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c5(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            # true_dist = pred.data.clone()\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Learning Rate:  0.0001\n",
      "Train Epoch: 1 [0/49168 (0.000%)]\tLoss: 2.3017619\n",
      "Train Epoch: 1 [12800/49168 (25.974%)]\tLoss: 1.5358887\n",
      "Train Epoch: 1 [25600/49168 (51.948%)]\tLoss: 1.1347406\n",
      "Train Epoch: 1 [38400/49168 (77.922%)]\tLoss: 1.0622814\n",
      "Train Set: Average loss: 1.4052, Accuracy: 35626/49168 (72%)\n",
      "\n",
      "Test set: Average loss: 0.0087, Accuracy: 19656/21072 (93%)\n",
      "\n",
      "Time Taken: 28.530112266540527\n",
      "\n",
      "\n",
      "Epoch: 2 Learning Rate:  0.0000\n",
      "Train Epoch: 2 [0/49168 (0.000%)]\tLoss: 1.0517864\n",
      "Train Epoch: 2 [12800/49168 (25.974%)]\tLoss: 1.0047278\n",
      "Train Epoch: 2 [25600/49168 (51.948%)]\tLoss: 1.0073650\n",
      "Train Epoch: 2 [38400/49168 (77.922%)]\tLoss: 0.9896420\n",
      "Train Set: Average loss: 1.0186, Accuracy: 47582/49168 (97%)\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 20344/21072 (97%)\n",
      "\n",
      "Time Taken: 28.80072331428528\n",
      "\n",
      "\n",
      "Epoch: 3 Learning Rate:  0.0000\n",
      "Train Epoch: 3 [0/49168 (0.000%)]\tLoss: 0.9866614\n",
      "Train Epoch: 3 [12800/49168 (25.974%)]\tLoss: 1.0206035\n",
      "Train Epoch: 3 [25600/49168 (51.948%)]\tLoss: 0.9927338\n",
      "Train Epoch: 3 [38400/49168 (77.922%)]\tLoss: 1.0004082\n",
      "Train Set: Average loss: 1.0094, Accuracy: 47766/49168 (97%)\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 20375/21072 (97%)\n",
      "\n",
      "Time Taken: 29.242623329162598\n",
      "\n",
      "\n",
      "Epoch: 4 Learning Rate:  0.0000\n",
      "Train Epoch: 4 [0/49168 (0.000%)]\tLoss: 0.9839430\n",
      "Train Epoch: 4 [12800/49168 (25.974%)]\tLoss: 0.9950083\n",
      "Train Epoch: 4 [25600/49168 (51.948%)]\tLoss: 1.0408411\n",
      "Train Epoch: 4 [38400/49168 (77.922%)]\tLoss: 0.9816281\n",
      "Train Set: Average loss: 1.0082, Accuracy: 47779/49168 (97%)\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 20390/21072 (97%)\n",
      "\n",
      "Time Taken: 29.052703857421875\n",
      "\n",
      "\n",
      "Epoch: 5 Learning Rate:  0.0000\n",
      "Train Epoch: 5 [0/49168 (0.000%)]\tLoss: 1.0004267\n",
      "Train Epoch: 5 [12800/49168 (25.974%)]\tLoss: 1.0083802\n",
      "Train Epoch: 5 [25600/49168 (51.948%)]\tLoss: 0.9932789\n",
      "Train Epoch: 5 [38400/49168 (77.922%)]\tLoss: 1.0108668\n",
      "Train Set: Average loss: 1.0081, Accuracy: 47795/49168 (97%)\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 20391/21072 (97%)\n",
      "\n",
      "Time Taken: 29.101223945617676\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "PRINT_INTERVAL = 100\n",
    "\n",
    "\n",
    "model = VGGNet(VGG13, 1, 10).to(device)\n",
    "\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.000050)\n",
    "scheduler = StepLR(optimizer,step_size=EPOCHS//5, gamma=0.1)\n",
    "# early_stopping = EarlyStopping(track=\"max\",patience=15, verbose=True, delta=0.00001>)\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS+ 1):\n",
    "    curT = time.time()\n",
    "    print(\"Epoch: {} Learning Rate:  {:0.4f}\".format(epoch, scheduler.get_lr()[0]))\n",
    "    train_classifier(model, optimizer, LabelSmoothingLoss(10, 0.2), epoch, trainloader, device, print_interval=100)\n",
    "    val_loss, val_acc = test_classifier(model,LabelSmoothingLoss(10,0.2), device, validloader)\n",
    "    print(\"Time Taken: {}\\n\\n\".format(time.time()-curT))\n",
    "    scheduler.step()\n",
    "#     early_stopping(val_acc, model)\n",
    "    \n",
    "#     if early_stopping.early_stop:\n",
    "#         break\n",
    "\n",
    "torch.save(model.state_dict(), \"model_\"+str(EPOCHS)+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
