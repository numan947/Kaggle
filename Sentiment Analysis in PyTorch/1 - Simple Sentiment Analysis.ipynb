{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part of my study from : https://github.com/bentrevett/pytorch-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALL IMPORTS FOR A NEW NOTEBOOK\n",
    "\n",
    "import os, sys, random, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import itertools as it\n",
    "import scipy\n",
    "import glob\n",
    "import matplotlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.optim import Optimizer\n",
    "import torchvision.transforms.transforms as txf\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn import model_selection as ms\n",
    "\n",
    "import torch_utils\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "import time\n",
    "\n",
    "font = {'size'   : 20}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 947\n",
    "torch_utils.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize=\"spacy\")\n",
    "LABEL = data.LabelField(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import datasets\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 25000\n",
      "Number of test examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples: {}\".format(len(train_data)))\n",
    "print(\"Number of test examples: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['Action', '.', 'Comedy', '.', 'Suspense', '.', 'This', 'movie', 'has', 'it', 'all.<br', '/><br', '/>The', 'Plot', 'goes', 'that', '4', 'would', 'be', 'professional', 'thieves', 'are', 'invited', 'to', 'take', 'part', 'in', 'a', 'heist', 'in', 'a', 'small', 'town', 'in', 'Montana', '.', 'every', 'type', 'of', 'crime', 'movie', 'archetype', 'character', 'is', 'here', '.', 'Frank', ',', 'the', 'master', 'mind', '.', 'Carlos', ',', 'the', 'weapons', 'expert', '.', 'Max', ',', 'the', 'explosives', 'expert', '.', 'Nick', ',', 'the', 'safe', 'cracker', 'and', 'Ray', ',', 'the', 'car', 'man', '.', 'Unfortunately', 'for', 'Frank', ',', 'he', 'is', 'apprehended', 'by', '2', 'bumbling', 'detectives', '(', 'portrayed', 'very', 'well', 'by', 'Ed', \"O'Niel\", 'and', 'Daniel', 'Roebuck', ')', 'that', 'have', 'been', 'chasing', 'him', 'from', 'New', 'Jersey', 'write', 'after', 'he', 'sends', 'out', 'the', 'letters', 'to', 'the', 'other', '4.<br', '/><br', '/>Our', '4', 'characters', 'meet', 'up', 'at', 'the', 'train', 'station', 'and', 'from', 'the', 'beginning', 'none', 'of', 'them', 'like', 'or', 'trust', 'one', 'another', '.', 'Added', 'to', 'the', 'mix', 'is', 'the', 'fact', 'that', 'Frank', 'is', 'gone', 'and', 'they', 'are', 'not', 'sure', 'why', 'they', 'have', 'called', 'together.<br', '/><br', '/>Now', 'Frank', 'is', 'being', 'taken', 'back', 'to', 'New', 'Jersey', 'by', 'the', '2', 'detectives', 'but', 'soon', 'escapes', 'on', 'foot', 'and', 'tries', 'to', 'make', 'his', 'way', 'back', 'to', 'the', 'guys', 'who', 'are', 'having', 'all', 'sorts', 'of', 'problems', 'of', 'their', 'own.<br', '/><br', '/>Truly', 'a', 'great', 'film', 'loaded', 'with', 'laughs', 'and', 'great', 'acting', '.', 'Just', 'an', 'overall', 'good', 'movie', 'for', 'anyone', 'looking', 'for', 'a', 'laugh', 'or', 'something', 'a', 'little', 'different'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = train_data.split(random_state=random.seed(SEED), split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len 20000\n",
      "valid len 5000\n",
      "test len 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"train len {}\".format(len(train_data)))\n",
    "print(\"valid len {}\".format(len(valid_data)))\n",
    "print(\"test len {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25002, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab), len(LABEL.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 231625),\n",
       " (',', 219352),\n",
       " ('.', 189108),\n",
       " ('a', 125105),\n",
       " ('and', 125098),\n",
       " ('of', 115281),\n",
       " ('to', 106932),\n",
       " ('is', 87194),\n",
       " ('in', 70061),\n",
       " ('I', 61871),\n",
       " ('it', 60885),\n",
       " ('that', 56096),\n",
       " ('\"', 50728),\n",
       " (\"'s\", 49374),\n",
       " ('this', 48373),\n",
       " ('-', 42226),\n",
       " ('/><br', 40588),\n",
       " ('was', 39579),\n",
       " ('as', 34646),\n",
       " ('with', 34340)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.freqs.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'pos': 0, 'neg': 1})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_sizes=(BATCH_SIZE, BATCH_SIZE, BATCH_SIZE),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, txt):\n",
    "        e = self.embedding(txt)\n",
    "        out, hidden = self.rnn(e)\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_model_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2592105"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_model_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    rounded_pred = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_pred==y).float()\n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(batch.text).squeeze(1)\n",
    "        loss = criterion(preds, batch.label)\n",
    "        acc = binary_accuracy(preds, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss+=loss.item()\n",
    "        epoch_acc+=acc.item()\n",
    "        \n",
    "    return epoch_loss/len(iterator), epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "\n",
    "            preds = model(batch.text).squeeze(1)\n",
    "            loss = criterion(preds, batch.label)\n",
    "            acc = binary_accuracy(preds, batch.label)\n",
    "            \n",
    "            epoch_loss+=loss.item()\n",
    "            epoch_acc+=acc.item()\n",
    "        \n",
    "    return epoch_loss/len(iterator), epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1 TIME: 17.019481897354126 s\n",
      "EPOCH: 1 Train Loss0.693676843810767 Train ACC 49.555710862619804%\n",
      "EPOCH: 1 Valid Loss0.6931708115565626 Valid ACC 50.29667721518988%\n",
      "EPOCH: 2 TIME: 16.98063373565674 s\n",
      "EPOCH: 2 Train Loss0.6932437218035372 Train ACC 50.14976038338658%\n",
      "EPOCH: 2 Valid Loss0.6930699484257759 Valid ACC 51.04825949367089%\n",
      "EPOCH: 3 TIME: 17.080568313598633 s\n",
      "EPOCH: 3 Train Loss0.6932315735009532 Train ACC 50.07987220447284%\n",
      "EPOCH: 3 Valid Loss0.6935107330732708 Valid ACC 49.723101265822784%\n",
      "EPOCH: 4 TIME: 17.226268529891968 s\n",
      "EPOCH: 4 Train Loss0.6931580048018751 Train ACC 50.41932907348243%\n",
      "EPOCH: 4 Valid Loss0.6931160114988496 Valid ACC 50.51424050632911%\n",
      "EPOCH: 5 TIME: 17.0508713722229 s\n",
      "EPOCH: 5 Train Loss0.6931761535592734 Train ACC 50.35942492012779%\n",
      "EPOCH: 5 Valid Loss0.6934082115752788 Valid ACC 49.960443037974684%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    if valid_loss<best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"tut1-model.pt\")\n",
    "    \n",
    "    print(\"EPOCH: {} TIME: {} s\".format(epoch+1, time.time()-start_time))\n",
    "    print(\"EPOCH: {} Train Loss{} Train ACC {}%\".format(epoch+1, train_loss, 100.0*train_acc))\n",
    "    print(\"EPOCH: {} Valid Loss{} Valid ACC {}%\".format(epoch+1, valid_loss, 100.0*valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_utils.clear_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.689970259013993 55.19181585982632\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"tut1-model.pt\", map_location=device))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(test_loss, 100.0*test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
